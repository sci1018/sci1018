# Analyse de variance à un critère

Dans la leçon précédente, nous avons vu l'analyse de fréquences, particulièrement le test du $\chi^2$ d'ajustement et d'indépendance. Nous continuons ici avec l'analyse de données numériques continues, du même type que pour le test $t$. Dans la présente leçon, nous verrons un outil pour comparer plus de deux groupes, l'analyse de la variance.

## Leçon

### Comparaison de plusieurs groupes

Nous avons vu que le test $t$ permet de comparer deux groupes afin de déterminer s'ils proviennent de la même population. Dans certains cas, on s'intéresse à plus de deux groupes. Par exemple, on pourrait vouloir comparer la distance quotidienne parcourue par les chauffeurs de trois compagnies de transport différentes. Rappelons qu'à chaque fois que nous réalisons un test d'hypothèse statistique, nous avons une probabilité $\alpha$ de commettre une erreur de type I (c.-à-d., déclarer une différence lorsqu'il n'y en a pas, un faux positif). Avec trois groupes (A, B, C), il existe trois comparaisons possibles:

$$  A \: vs \: B \qquad A \: vs \: C \qquad B \: vs \: C$$

À noter que la comparaison $A \: vs \: B$ est identique à $B \: vs \: A$. La probabilité de trouver une différence entre les trois moyennes est supérieure à $\alpha$. Plus on fait de comparaisons avec un test $t$ (e.g., $A \: vs \: B$, $A \: vs \: C$), plus on risque de conclure à tort qu'il y a une différence entre les moyennes des groupes  (c.-à-d. l'erreur de type I augmente avec le nombre de comparaisons). Si les tests sont indépendants, on peut calculer la probabilité de commettre au moins une erreur de type I à l'aide de l'équation:

$$P = 1 - (1 - \alpha)^k$$ 

où $\alpha$ est le seuil de signification pour chaque comparaison et $k$ est le nombre de comparaisons effectuées. Pour un seuil fixé à $\alpha = 0.05$ :  

 - avec 3 comparaisons, la probabilité de commettre une erreur de type I est de 0.14;  
 - avec 10 comparaisons, la probabilité de commettre une erreur de type I est de 0.40;  
 - avec 20 comparaisons, la probabilité de commettre une erreur de type I est de 0.64.  

Toutefois, si les comparaisons ne sont pas indépendantes, la probabilité réelle de commettre une erreur de type I est inférieure ou égale à celle obtenue avec l'équation ci-haut. On comprend que l'augmentation du nombre de comparaisons risque d'entraîner des conclusions erronées.  

Une alternative à ce problème consiste à corriger le seuil $\alpha$ par le nombre de comparaisons que l'on veut effectuer. C'est ce qu'on appelle l'**ajustement de Bonferroni** (*Bonferroni adjustment*).



:::{.exemple section=6}
Dans une expérience où on étudie 5 traitements différents, nous avons cinq moyennes arithmétiques (5 groupes: A, B, C, D, E) et les comparaisons suivantes :

$$A \: vs \: B $$ 
$$A \: vs \: C \qquad B \: vs \: C   $$
$$A \: vs \: D \qquad B \: vs \: D \qquad C \: vs \: D $$
$$A \: vs \: E \qquad B \: vs \: E \qquad C \: vs \: E \qquad D \: vs \: E \: .$$
Puisqu'il y a 10 comparaisons, on devrait diviser le seuil $\alpha$ par 10 pour exécuter l'ajustement de Bonferroni. Si on utilise un seuil de 0.05, il faudra observer $P \leq 0.005$ pour déclarer une différence significative entre deux groupes ($\alpha/10 = 0.05/10 = 0.005$).
:::



On constate que l'ajustement de Bonferroni est une stratégie souvent trop conservatrice, qui augmente la probabilité de commettre une erreur de type II (un faux négatif). Une meilleure stratégie consiste à comparer tous les groupes simultanément. C'est d'ailleurs ce que permet de faire l'analyse de variance -- on compare tous les groupes en une seule étape.

### Analyse de variance (ANOVA)

L'**analyse de variance** (*analysis of variance*, ANOVA) est une approche statistique qui compare les moyennes de plusieurs groupes entre eux pour déterminer si au moins un des groupes diffère des autres. Le scénario typique de l'ANOVA est celui d'une expérience visant à comparer l'effet d'une **variable catégorique**  sur une **variable réponse**  d'intérêt. Une variable catégorique est une variable à partir de laquelle la variable réponse peut être classée dans une catégorie particulière. Par variable réponse, on entend une variable dépendante que l'on mesure et qui peut être influencée par la variable catégorique. On utilise aussi le terme **facteur** pour désigner une variable catégorique. En fait, les termes "variable catégorique", "facteur" et "critère" sont souvent interchangeables dans la littérature. Nous utiliserons le terme "facteur" pour les besoins du cours.

Des exemples de variables catégoriques incluent les classes d'âge (jeune, mature, vieux), les traitements pharmaceutiques (médicament 1, médicament 2, placebo), et la concentration d'engrais (très faible, modérée, élevée, très élevée). Dans le contexte de l'ANOVA, la variable réponse est une variable numérique continue qui varie selon les niveaux du facteur. Comme nous le verrons plus loin, l'ANOVA est l'extension du test $t$ pour des cas avec des variables catégoriques qui ont plus de 2 niveaux.

Étant donné que l'on s'intéresse aux moyennes, on pourrait se demander pourquoi appeler cette approche ANOVA. Lorsqu'on réalise une ANOVA, on détermine si la variabilité des données expliquée par le traitement est plus grande que la variabilité inexpliquée. Pour ce faire, nous calculons la **somme des carrés** (*sum of squares*). Le concept de la somme des carrés a été présenté lors de la leçon 1 *Statistiques descriptives*.

#### Décomposition de la variance

##### Sommes des carrés 

Pendant l'ANOVA, on décortique la variance totale des données en différentes composantes: une partie expliquée et une autre inexpliquée. Puisque les sommes des carrés sont additives, on peut écrire :

$$SST = SSA + SSE \: $$
où $SST$ correspond à la **somme des carrés totale**, $SSA$ correspond à la **somme des carrés du facteur $A$** (aussi appelée somme des carrés du traitement) et $SSE$ est la **somme des carrés des erreurs**. On peut diviser les sommes des carrés par les degrés de liberté appropriés pour obtenir le **carré moyen** (la variance) attribuable aux effets qui nous intéressent. Nous présentons dans les prochaines lignes le calcul de chacune des sommes des carrés discutées précédemment.

On calcule la somme des carrés totale ($SST$):

$$ SST = \sum_{i=1}^n (y_i - \bar{y})^2$$  

où $y_i$ est la $i^{\mathrm{i\grave{e}me}}$ observation et $\bar{y}$ représente la moyenne globale de toutes les observations (tous les groupes confondus). Cette somme des carrés compare chaque observation à la moyenne globale. Les degrés de liberté associés à $SST$ sont obtenus avec $df = N - 1$, où $N$ correspond au nombre total d'observations.

On calcule la somme des carrés des erreurs ($SSE$):

$$ SSE = \sum_{j=1}^k \sum_{i=1}^n (y_{ij} - \bar{y_j})^2$$  

où $y_{ij}$ correspond à la $i^{\mathrm{i\grave{e}me}}$ observation du groupe $j$ et $\bar{y_j}$ est la moyenne du groupe $j$. Cette somme des carrés compare chaque observation à la moyenne de son groupe respectif. On obtient les degrés de liberté avec $df = k(n - 1)$, où $k$ correspond au nombre de groupes et $n$ correspond au nombre d'observations dans chacun des groupes.

On calcule la somme des carrés du facteur $A$ (le traitement qui définit les différents groupes) ($SSA$):

$$SSA = \sum_{j=1}^k \sum_{i=1}^n (\bar{y}_{j} - \bar{y})^2 = n \sum_{j=1}^k (\bar{y}_{j} - \bar{y})^2$$
où $\bar{y}_{j}$ correspond à la moyenne du groupe $j$, $\bar{y}$ est la moyenne globale et $n$ correspond au nombre d'observations dans chacun des groupes. On peut aussi la calculer par soustraction à l'aide de $SSA = SST - SSE$. La somme des carrés du traitement compare la moyenne de chaque groupe à la moyenne globale. Les degrés de liberté s'obtiennent avec $df = k - 1$ où $k$ est le nombre de groupes dans le facteur $A$.



:::{.exemple section=6}
On veut déterminer si la concentration d'ozone en parties par million (ppm) diffère entre trois jardins d'une ville industrielle. Le jeu de données `jardins.txt` contient les observations suivantes :

```{r gardens, echo = TRUE, keep.source = TRUE}
##importation du jeu de données
ozone <- read.table("Module_6/data/jardins.txt", header = TRUE)
ozone
```

On peut visualiser les données à l'aide d'un diagramme de boîtes et moustaches (Figure \@ref(fig:ozone)).

```{r ozone, echo = TRUE, keep.source = TRUE, fig.align='center', fig = TRUE, fig.cap="Diagramme de boîtes et moustaches de la concentration d'ozone dans les trois jardins."}
##diagramme de boîtes et moustaches
boxplot(Ozone ~ Jardin, data = ozone,
        ylab = "Concentration d'ozone (ppm)",
        xlab = "Jardin", cex.lab = 1.2)
```

La somme des carrés des erreurs s'obtient ainsi :

$$ SSE = \hspace{1em} \sum_{j=1}^k \sum_{i=1}^n (y_{ij} - \bar{y_j})^2 \hspace{2em} \bar{y_A} = 16.34 \hspace{2em} \bar{y_B} = 18.20 \hspace{2em} \bar{y_C} = 18.08 $$
$$ SSE = \hspace{1em}\sum_{i=1}^n((y_{iA} - \bar{y_A})^2 + (y_{iB} - \bar{y_B})^2 + (y_{iC} - \bar{y_C})^2) $$

$$  SSE = (14.82 - 16.34)^2 + \ldots + (9.60 - 16.34)^2 +  $$

$$\hspace{1em} (20.46 - 18.20)^2 + \ldots + (11.15 - 18.20)^2 + $$
 
$$\hspace{1em} (10.03 - 18.08)^2 + \ldots + (28.65 - 18.08)^2  $$

$$ SSE = 2451.5    $$
On calcule la somme des carrés des traitements avec l'équation complète ou par soustraction:
$$ SSA = \sum_{j=1}^k \sum_{i=1}^n (\bar{y}_{j} - \bar{y})^2 = n \sum_{j=1}^k (\bar{y}_{j} - \bar{y})^2  \hspace{4em} n_A = n_B = n_C = 15  $$
$$SSA = 15 \cdot ((16.34 - 17.54)^2 + (18.20 - 17.54)^2 + (18.08 - 17.54)^2) $$     
$$SSA = 32.43$$  

On effectue ces calculs dans R :

```{r sst, echo = TRUE, keep.source = TRUE}
##SST
SST <- sum((ozone$Ozone - mean(ozone$Ozone))^2)
SST
##degrés de liberté de SST
df.tot <- nrow(ozone) - 1
df.tot

##SSE
##sous-jeu de données
ozoneA <- ozone[ozone$Jardin == "A", ]
ozoneB <- ozone[ozone$Jardin == "B", ]
ozoneC <- ozone[ozone$Jardin == "C", ]
##SSE de A
SSE.A <- sum((ozoneA$Ozone-mean(ozoneA$Ozone))^2)
##SSE de B
SSE.B <- sum((ozoneB$Ozone-mean(ozoneB$Ozone))^2)
##SSE de C
SSE.C <- sum((ozoneC$Ozone-mean(ozoneC$Ozone))^2)
SSE <- SSE.A + SSE.B + SSE.C
SSE
##degrés de liberté de SSE
df.erreur <- 3 * (15 - 1)
df.erreur

##SSA
SSA <- SST - SSE
SSA
##autre façon de la calculer
SSA.alt <- (15 * (mean(ozoneA$Ozone) - mean(ozone$Ozone))^2) +
  (15 * (mean(ozoneB$Ozone) - mean(ozone$Ozone))^2) +
  (15 * (mean(ozoneC$Ozone) - mean(ozone$Ozone))^2)
SSA.alt
##degrés de liberté du traitement
df.trait <- 3 - 1
df.trait
```
:::



##### Tableau de l'ANOVA 

Après avoir calculé les sommes des carrés des différents termes ainsi que leurs degrés de liberté respectifs, on peut les assembler dans un tableau d'ANOVA (Table \@ref(tab:aov)). Ce tableau constitue une partie importante des résultats de l'analyse et doit figurer dans les rapports ou au moins y être résumé par écrit.

```{r aov, echo = FALSE, keep.source = FALSE}
df <- data.frame(
  Col1 = c("Traitement", "Erreur", "Total"),
  Col2 = c("$SSA$", "$SSE$", "$SST$"),
  Col3 = c("$k-1$", "$k(n-1)$", "$N-1$"),
  Col4 = c("$SSA/df_A$", "$SSE/df_erreur$", " "),
  Col5 = c("$MSA/MSE$", " ", " ")
  )

colnames(df) <- c("Source", "Somme des carrés <br> ($SS$)", "Degrés de liberté <br> ($df$)", "Carré moyen <br> ($CM$)", "ratio $F$")

# Generate the table with custom styling for merged cells
kable(df,  
      row.names = FALSE, 
      caption = "Calcul des différents éléments du tableau d'ANOVA.",
      "html", booktabs = TRUE, escape = FALSE) %>% 
  kable_styling(full_width = F, position = "center")
``` 

Le carré moyen du traitement ($SSA/df_A$) estime la variance due au traitement, alors que le carré moyen des erreurs ($SSE/df_{erreur}$) estime la variance inexpliquée aussi appelée **variance résiduelle** (*residual variance*). La variance résiduelle est la meilleure estimation de la variance ($\sigma^2$) commune à tous les $k$ groupes comparés. C'est une des raisons pour lesquelles la méthode est appelée "analyse de variance" : on estime en même temps la variance commune à tous les groupes.

Le ratio $F$ consiste à comparer la variabilité expliquée et la variabilité inexpliquée. Si le ratio est nettement supérieur à 1, c'est parce que la variance expliquée par le traitement excède de beaucoup la variance résiduelle: il y a probablement un effet du traitement sur la variable réponse. Un ratio inférieur ou s'approchant de 1 suggère qu'il n'y a pas d'effet du traitement. L'interprétation du ratio $F$ dépend aussi de la taille de l'échantillon. Ce ratio de variances est comparé à une distribution théorique, celle du $F$.

#### La distribution du $F$

La distribution du $F$ est une distribution continue qui est définie par la fonction de densité :

$$   f(x \vert \nu_1, \nu_2) = \frac{\sqrt{\frac{(\nu_1 x)^{\nu_1}\nu_{2}^{\nu_2}}{(\nu_1 x + \nu_2)^{\nu_1 + \nu_2}}}}{x \mathrm{B} \left (\frac{\nu_1}{2}, \frac{\nu_2}{2} \right )} \: $$

où $\nu_1$ et $\nu_2$ sont les degrés de liberté et $B$ est la fonction beta qui implique des intégrales (voir `?beta` dans R). En ce qui concerne l'application de cette distribution à l'ANOVA, les degrés de liberté $\nu_1$ et $\nu_2$ sont ceux associés au numérateur et au dénominateur du ratio $F$, respectivement, c.-à-d., $df_A$ et $df_{erreur}$ tels que présentés dans le Tableau \@ref(tab:aov). La Figure \@ref(fig:F) présente la forme de la distribution du $F$ selon différents degrés de liberté. Comme d'habitude, nous comparons la statistique obtenue à partir des données de l'échantillon à celle de la distribution du $F$ selon les degrés de liberté et le seuil de signification spécifiés lorsque l'hypothèse nulle est vraie. Si la valeur du $F$ observée est plus grande que celle déterminée par la distribution du $F$, nous rejetterons l'hypothèse nulle.

```{r F, echo = FALSE, keep.source = FALSE, fig = TRUE, fig.align='center', fig.cap="Distribution du $F$ selon différentes valeurs de degrés de liberté."}
##form of F distribution
x <- seq(from = 0, to = 10, by = 0.1)

f1.1 <- df(x = x, df1 = 1, df2 = 1)
f1.2 <- df(x = x, df1 = 1, df2 = 2)
f1.10 <- df(x = x, df1 = 1, df2 = 10)
f2.10 <- df(x = x, df1 = 2, df2 = 10)
f2.50 <- df(x = x, df1 = 2, df2 = 50)
f3.10 <- df(x = x, df1 = 3, df2 = 10)
f3.50 <- df(x = x, df1 = 3, df2 = 50)

##plot density
plot(f1.1 ~ x, ylab = "Densité de probabilité", xlab = "Valeurs de x",
  ylim = c(0, 1), type = "n", main = expression(paste("Forme de la distribution du ", italic(F))))

lines(y = f1.2, x = x, col = "blue")
lines(y = f1.10, x = x, col = "green")
lines(y = f2.10, x = x, col = "orange")
lines(y = f2.50, x = x, col = "magenta")
lines(y = f3.10, x = x, col = "black")
lines(y = f3.50, x = x, col = "brown")

##add legend
legend(x = "topright", legend =
       c(expression(paste(nu[1], " = 1, ",nu[2], " =  2")),
         expression(paste(nu[1], " = 1, ",nu[2], " = 10")),
         expression(paste(nu[1], " = 2, ",nu[2], " = 10")),
         expression(paste(nu[1], " = 2, ",nu[2], " = 50")),
         expression(paste(nu[1], " = 3, ",nu[2], " = 10")),
         expression(paste(nu[1], " = 3, ",nu[2], " = 50"))),
       lty = 1,
       col = c("blue", "green", "orange", "magenta", "black", "brown"))
```

#### Hypothèses statistiques 

Comme nous l'avons vu dans les leçons précédentes, l'hypothèse nulle (bilatérale) avec le test $t$ de Student sur deux groupes indépendants implique l'égalité des moyennes des deux groupes :  

$H_0$: $\mu_{\mathrm{A}} = \mu_{\mathrm{B}}$ (non-différence)   
$H_a$: $\mu_{\mathrm{A}} \neq \mu_{\mathrm{B}}$ (différence)    

En ce qui a trait à l'ANOVA, l'hypothèse nulle a la même forme. Par exemple, pour un facteur qui compte quatre niveaux (p. ex., faible, modéré, élevé, très élevé), nous aurions l'hypothèse nulle suivante :  

$H_0$: $\mu_{\mathrm{A}} = \mu_{\mathrm{B}}$ = $\mu_{\mathrm{C}} = \mu_{\mathrm{D}}$ (non-différence)  
$H_a$: au moins une moyenne diffère des autres moyennes



:::{.exemple section=6}
Reprenons notre exemple sur la concentration d'ozone dans les trois jardins d'une ville industrielle. Nous pouvons émettre les hypothèses statistiques suivantes :  

$H_0$: $\mu_{\mathrm{jardin \: A}} = \mu_{\mathrm{jardin \: B}}$ = $\mu_{\mathrm{jardin \: C}}$ (non-différence)  
$H_a$: au moins une moyenne diffère des autres moyennes  
$\alpha = 0.05$    

Puisque nous avons déja calculé les sommes des carrés dans l'exemple 6.2, nous pouvons construire le tableau d'ANOVA qui nous permettra de tester l'hypothèse nulle (Table \@ref(tab:aov1)).

```{r aov1, echo = FALSE, keep.source = FALSE}
df <- data.frame(
  Col1 = c("Jardin", "Residuals" ),
  Col2 = c("32.43", "2451.45" ),
  Col3 = c("2", "42" ),
  Col4 = c("16.22", "58.37" ),
  Col5 = c("0.28", " " )
  )

colnames(df) <- c("Source", "Somme des carrés <br> ($SS$)", "Degrés de liberté <br> ($df$)", "Carré moyen <br> ($CM$)", "ratio $F$")

# Generate the table with custom styling for merged cells
kable(df,  
      row.names = FALSE, 
      caption = "Calcul des différents éléments du tableau d'ANOVA.",
      "html", booktabs = TRUE, escape = FALSE) %>% 
  kable_styling(full_width = F, position = "center")
``` 

On constate que le ratio $F$ est de 0.28 ($16.22/58.37$). Étant donné que $P(F_{2, 42} \geq 0.28) = 0.7588$^[Rappel: Ici, la valeur de $P$ correspond à la probabilité d'obtenir une valeur de $F$ supérieure ou égale à celle qu'on a observée (dans les données originales) lorsqu'on répète l'échantillonnage avec la même taille d'échantillon dans la même population et que l'hypothèse nulle est vraie. On peut écrire plus succinctement: $P = 0.7588$.], on ne rejette pas $H_0$ et on conclut que les moyennes des groupes ne diffèrent pas les unes des autres. La fonction `aov( )` permet de réaliser une ANOVA dans R lorsque chaque groupe contient le même nombre d'observations^[Dans les cas où le nombre d'observations varie d'un groupe à l'autre, il est préférable d'utiliser la fonction plus générale, `lm( )` qui permet de réaliser plusieurs types de modèles linéaires.]. 

On peut constater que la variable `Jardin` est une variable caractère (`chr`). Celle-ci doit être un facteur afin de réaliser l'ANOVA. La transformation est réalisée à l’aide de la commande suivante :

```{r aova, echo = TRUE, keep.source = TRUE, eval = TRUE}
ozone$Jardin <- as.factor(ozone$Jardin)
```

La commande ci-dessous permet de valider que la variable `Jardin` est maintenant un facteur (`factor`).

```{r aovb, echo = TRUE, keep.source = TRUE, eval = TRUE}
str(ozone)
```

On peut maintenant réaliser l'ANOVA et l'extraire à l'aide de la fonction `summary( )`. Cette dernière fonction est souvent utilisée pour obtenir un résumé des résultats d'une analyse statistique.

```{r echo = TRUE, keep.source = TRUE, eval = TRUE}
##exécuter l'ANOVA
aov1 <- aov(Ozone ~ Jardin, data = ozone)
##on extrait les résultats
summary(aov1)
```
:::



#### Suppositions 

L'analyse de variance est une extension du test $t$ de Student lorsqu'on souhaite comparer les moyennes entre plus de deux groupes. Il n'est donc pas surprenant que l'analyse de variance doive répondre aux mêmes conditions d'utilisation que le test $t$. Pour effectuer l'ANOVA, les erreurs doivent être indépendantes. L'échantillonnage aléatoire et l'utilisation d'un bon dispositif expérimental aident à respecter cette condition. L'ANOVA requiert également que les variances des groupes soient égales (homoscédasticité): $\sigma_1^2 = \sigma_2^2 = \sigma_3^2 \ldots \sigma_k^2$. Finalement, on suppose que chacun des groupes est issu d'une population normale (c.-à-d., résidus ou erreurs sont distribués normalement). Autrement dit, afin de pouvoir comparer des groupes dont la moyenne peut potentiellement différer d'un groupe à l'autre, il faut que ces groupes aient la même variance. Cette variance commune est estimée par le carré moyen de l'erreur (*residual mean square, error mean square*).

##### Résidus

À l'instar du test $t$, nous utilisons les résidus pour diagnostiquer des problèmes liés à la normalité et à l'homogénéité des variances. Les résidus sont obtenus en calculant la différence entre les valeurs observées $y_i$ et les valeurs qui sont prédites $\hat{y}_i$ par notre modèle d'ANOVA. Dans le cas de l'ANOVA à un critère, les valeurs prédites ($\hat{y}_i$) correspondent à la moyenne arithmétique de chaque groupe. Nous obtenons les résidus à l'aide de $y_i - \hat{y}_i$. Les fonctions `residuals( )` et `fitted( )` dans R permettent d'extraire les résidus et les valeurs prédites de plusieurs types d'analyses statistiques. Le prochain exemple illustre l'application directe de ces fonctions à l'objet qui contient le résultat de l'ANOVA.



:::{.exemple section=6}
On peut vérifier les suppositions de l'ANOVA que nous avons exécutée dans l'exemple précédent. On obtient les résidus en calculant la différence entre les valeurs observées et les valeurs prédites, $y_i - \hat{y}_i$. On commence par extraire les valeurs observées et les valeurs prédites :

```{r obs, echo = TRUE, keep.source = TRUE}
##valeurs observées
obs <- ozone$Ozone
obs[1:10]

##extraire les valeurs prédites
pred <- fitted(aov1)
pred[1:10]

##moyenne arithmétique de chaque groupe
tapply(X = ozone$Ozone, INDEX = ozone$Jardin, FUN = mean)
```

On remarque que les valeurs prédites par l'ANOVA à un critère correspondent à la moyenne arithmétique de chaque groupe, comme l'indique par la fonction `tapply( )`^[La fonction `tapply( )`] applique une fonction donnée (ici, `mean`) aux valeurs d'une variable `X` (`ozone\$Ozone`) regroupées selon les différentes catégories de `INDEX` (`ozone\$Jardin`).]. Les résidus s'obtiennent facilement à l'aide du calcul  $y_i - \hat{y}_i$ ou avec la fonction `residuals( )` :

```{r diag, echo = TRUE, keep.source = TRUE}
##résidus
obs[1:10] - pred[1:10]

##extraire résidus du modèle
res <- residuals(aov1)
res[1:10] #valeurs identiques au calcul obs - pred
```
:::



##### Normalité des résidus et homogénéité de la variance 

De la même façon qu'on utilise le graphique quantile-quantile lorsqu'on effectue un test $t$, on utilise ce même graphique pour diagnostiquer des déviations par rapport à la supposition de normalité. La fonction `qqnorm( )` permet d'obtenir ce graphique et la fonction `qqline( )` ajoute une droite théorique représentant une distribution normale.

Pour évaluer l'homogénéité des variances des différents groupes, on peut utiliser le diagramme de boîtes et moustaches (`boxplot( )`) des résidus en fonction de chaque groupe. Un autre graphique utile pour diagnostiquer des problèmes de variances hétérogènes est le graphique des résidus en fonction des valeurs prédites. Ce dernier devrait montrer un patron nul, c'est-à-dire des points distribués uniformément de part et d'autre de 0 sur l'axe des $y$ sans patron apparent (Figure \@ref(fig:homog)a). L'hétérogénéité des variances se traduit parfois par l'apparition d'un patron en forme d'entonnoir, indiquant que les variances augmentent avec les valeurs prédites (Figure \@ref(fig:homog)b). S'il y a des doutes par rapport au respect de ces conditions, plusieurs options sont possibles. Les transformations vues dans la leçon 4 de ce cours peuvent être utiles, ou encore des tests plus complexes qui ne nécessitent pas ces conditions.

```{r homog, keep.source = FALSE, echo = FALSE, fig = TRUE, fig.align='center', fig.cap="Graphique de résidus en fonction des valeurs prédites illustrant l'homogénéité des variances (a) et l'hétérogénéité des variances (b). Notez le patron en forme d'entonnoir en b qui est indiqué par une variance qui augmente avec les valeurs prédites."}
##homoscedasticity
set.seed(seed = 122)
y1 <- rnorm(n = 30, mean = 12, sd = 5)
y2 <- rnorm(n = 30, mean = 24, sd = 5)
y3 <- rnorm(n = 30, mean = 36, sd = 5)
y4 <- rnorm(n = 30, mean = 48, sd = 5)
combo.y <- data.frame(Y = c(y1, y2, y3, y4),
                      Group = c(rep("a", 30), rep("b", 30), rep("c", 30), rep("d", 30)))
aov2 <- aov(Y ~ Group, data = combo.y)

##combine into same graph
op <- par(mfrow = c(1, 2))
plot(residuals(aov2) ~ fitted(aov2), ylab = "Résidus",
     xlab = "Valeurs prédites (moyennes des groupes)", main = "Variances homogènes")
text(x = 12, y = 40, labels = "a")

##heteroscedasticity
set.seed(seed = 1)
y1 <- rnorm(n = 30, mean = 12, sd = 5)
y2 <- rnorm(n = 30, mean = 24, sd = 10)
y3 <- rnorm(n = 30, mean = 36, sd = 15)
y4 <- rnorm(n = 30, mean = 48, sd = 20)
combo.y <- data.frame(Y = c(y1, y2, y3, y4),
                      Group = c(rep("a", 30), rep("b", 30), rep("c", 30), rep("d", 30)))
aov3 <- aov(Y ~ Group, data = combo.y)
plot(residuals(aov3) ~ fitted(aov3), ylab = "Résidus",
     xlab = "Valeurs prédites (moyennes des groupes)", main = "Variances hétérogènes")
text(x = 12.5, y = 30, labels = "b")
```



:::{.exemple section=6}
Nous poursuivons l'exemple 6.4 en vérifiant si la condition de normalité est respectée. Pour vérifier la normalité, on extrait les résidus de l'ANOVA et on examine le graphique quantile-quantile. On constate que la condition de normalité est assez bien respectée, quoiqu'il y ait quelques valeurs aux extrémités des queues qui dévient de la normalité (Figure \@ref(fig:qqplot6)a). Le graphique des résidus en fonction des valeurs prédites suggère que les variances sont plutôt homogènes, bien que le groupe avec la plus grande moyenne ait une variabilité légèrement plus faible que les autres (Figure \@ref(fig:qqplot6)b).

```{r echo = FALSE, keep.source = FALSE, fig = FALSE, include = FALSE, eval = FALSE}
##graphique quantile-quantile
qqnorm(res, ylab = "Quantiles observés",
       xlab = "Quantiles théoriques",
       main = "Graphique quantile-quantile de normalité",
       cex.lab = 1.2)
##cex.lab indique que les étiquettes seront 1.2 fois plus grande
##que la normale
##ajout de droite théorique
qqline(res)

##résidus vs valeurs prédites
plot(res ~ pred, ylab = "Résidus", xlab = "Valeurs prédites",
     cex.lab = 1.2)
```


```{r qqplot6, echo = TRUE, keep.source = FALSE, fig = TRUE, fig.align='center', fig.cap="Graphique quantile-quantile des résidus de l'ANOVA sur les concentrations d'ozone (a) et résidus en fonction des valeurs prédites (b)."}
par(mfrow = c(1, 2))
##graphique quantile-quantile
qqnorm(res, ylab = "Quantiles observés",
       xlab = "Quantiles théoriques",
       main = "Graphique quantile-quantile",
       cex.lab = 1.2)
##cex.lab indique que les étiquettes seront 1.2 fois plus grande


##ajout de droite théorique
qqline(res)
text(y = 15, x = -2, labels = "a")

##résidus vs valeurs prédites
plot(res ~ pred, ylab = "Résidus", xlab = "Valeurs prédites",
     main = "Résidus vs valeurs prédites", cex.lab = 1.2)
text(y = 15, x = 16.5, labels = "b")
```
:::



Nous avons maintenant toutes les notions en main afin de réaliser l'ANOVA et de vérifier le respect des conditions. C'est ce que nous ferons dans le prochain exemple.



:::{.exemple section=6}
On fait une étude de santé publique sur la consommation de boissons sucrées par les jeunes de 19 à 25 ans dans cinq régions de l'Est du Québec. Pour ce faire, on fait un sondage détaillé auprès de six jeunes par région et on estime pour chacun sa consommation annuelle en litres. Les cinq régions sont:

  -  Chaudière-Appalaches (\texttt{CA});
  -  Côte-Nord (\texttt{CN});
  -  Saguenay Lac-Saint-Jean (\texttt{SLSJ}).
  -  Bas-Saint-Laurent (\texttt{BSL});
  -  Gaspésie-Iles–de-la-Madeleine (\texttt{GIM});

Les données sont incluses dans le jeu de données `consommation.txt`.

```{r import, keep.source = TRUE}
cons <- read.table("Module_6/data/consommation.txt", header = TRUE)

head(cons)
```

Nous avons les hypothèses statistiques suivantes :  
$H_0$: $\mu_{\mathrm{SLSJ}} = \mu_{\mathrm{GIM}} = \mu_{\mathrm{CA}} = \mu_{\mathrm{CN}} = \mu_{\mathrm{BSL}}$ (non-différence)  
$H_a$: au moins une moyenne diffère parmi toutes les moyennes  
$\alpha = 0.05$  

Avant de faire l'analyse, on peut visualiser rapidement les données et la variabilité de chaque groupe avec `boxplot( )` (Figure \@ref(fig:box2)).

```{r box2, keep.source = TRUE, echo = TRUE, fig = TRUE, fig.align='center', fig.cap="Diagramme de boîtes et moustaches de la consommation annuelle de volume de boissées sucrées par jeune dans 5 régions de l'Est du Québec."}
##boxplot de données brutes
boxplot(Volume ~ Region, data = cons,
        ylab = "Volume",
        xlab = "Régions")
```

On exécute l'ANOVA à un critère :

```{r aov2, keep.source = TRUE, echo = TRUE}
## Conversion en facteur de la variable Region
cons$Region <- as.factor(cons$Region) 
##ANOVA
m1 <- aov(Volume ~ Region, data = cons)
```

Avant de se lancer dans l'interprétation, il faut vérifier les suppositions de l'ANOVA, notamment celles concernant l'homoscédasticité et la normalité des résidus. On constate que la supposition d'homogénéité des variances est assez bien respectée et une seule observation se démarque des autres avec une valeur > 15 (Figure \@ref(fig:diag3)a}). Toutefois, il est important de noter que six observations par groupe est une taille d'échantillon faible pour vérifier cette supposition d'homoscédasticité. Le graphique quantile-quantile avec les résidus indique que la supposition de normalité est respectée pour ce jeu de données (Figure \@ref(fig:diag3)b).

```{r diag3, keep.source = TRUE, echo = TRUE, fig = TRUE, fig.align='center', fig.cap="Diagnostics de l'ANOVA."}
##on organise la fenêtre graphique
##pour avoir 1 rangée et deux colonnes
##de graphiques
par(mfrow = c(1, 2))
##homoscédasticité
plot(residuals(m1) ~ fitted(m1),
     ylab = "Résidus", xlab = "Valeurs prédites",
     main = "Résidus vs valeurs prédites",
     cex.lab = 1.2)
##normalité
qqnorm(residuals(m1), ylab = "Quantiles observés",
       xlab = "Quantiles théoriques",
       main = "Graphique quantile-quantile",
       cex.lab = 1.2)
qqline(residuals(m1))
```

On peut procéder à l'interprétation des résultats.

```{r int, echo = TRUE, keep.source = TRUE}
##on extrait les résultats
summary(m1)
```

On note dans `summary(m1)` que la dernière ligne du tableau `Signif. codes` donne les symboles qui décrivent le seuil de signification statistique du facteur `Region`. Ces caractères ne sont affichés qu'en présence de termes significatifs dans l'analyse. Ici, `Region` a les caractères $\mathtt{\ast\ast}$ sur sa ligne, indiquant que $P \leq 0.01$. Ces symboles n'ont d'autre fonction que d'attirer l'attention de l'analyste sur les termes significatifs dans l'analyse. Il est peu probable d'observer une valeur de $F$ de 4.3 dans une expérience avec des échantillons (groupes) qui ont la même taille que le jeu de données original tirés d'une population où $H_0$ est vraie. La valeur exacte du $P$ est de 0.0088 ($P(F_{4, 25} \geq 4.3015) = 0.0088$). On rejette l'hypothèse nulle et on conclut qu'il y a un effet de la région : au moins une moyenne d'une région diffère d'une autre. Toutefois, l'ANOVA ne nous permet pas d'identifier quelles régions diffèrent entre elles. Pour ce faire, on doit utiliser un autre type de test qui sera présenté dans la prochaine section.
:::



### Comparaison multiples

L'ANOVA permet de déterminer si la variance expliquée par le facteur à l'étude est supérieure à la variance résiduelle (c.-à-d., la variance inexpliquée). Ainsi, le tableau d'ANOVA nous permet de rejeter ou non $H_0$. Lorsqu'on rejette l'hypothèse nulle après avoir effectué un test $t$ pour comparer deux groupes indépendants, on sait qu'il existe une différence entre ces deux groupes. Dans une ANOVA qui a plus de deux groupes, le rejet de $H_0$ ne nous révèle pas où se trouvent les différences^[Le tableau d'ANOVA classique ne permet pas de décortiquer où se trouvent les différences entre les groupes. Néanmoins, il est possible d'utiliser des contrastes orthogonaux pour décomposer la somme des carrés du facteur à l'intérieur du tableau d'ANOVA. Ce concept est plus avancé et ne sera pas couvert dans le cours.]. Les comparaisons multiples permettent d'identifier les différences entre les moyennes des groupes.

Comme nous l'avons mentionné au début de ce texte, effectuer des comparaisons multiples augmente la probabilité de commettre une erreur de type I. L'ANOVA est conçue pour comparer tous les groupes simultanément afin d'évaluer l'effet global du traitement. Lorsque l'ANOVA entraîne le rejet de l'hypothèse nulle, il s'avère nécessaire d'exécuter des comparaisons multiples entre les groupes afin de trouver quelles sont les différences. Ces comparaisons effectuées après l'ANOVA augmentent aussi la probabilité de commettre une erreur de type I -- la probabilité de commettre ce type d'erreur est supérieure au seuil $\alpha$ que nous avons fixé. Puisque les comparaisons multiples sont effectués après l'ANOVA, on parle souvent de tests *a posteriori* ou *post hoc* (post hoc *tests*, a posteriori *tests*).

#### Erreurs associées aux comparaisons multiples

On peut commettre des erreurs à deux niveaux lorsqu'on fait des comparaisons multiples : une **erreur au niveau de la comparaison** (*comparison-wise error*) et une **erreur au niveau de l'expérience** (*experiment-wise error*). L'erreur au niveau de la comparaison se traduit par la déclaration d'un faux positif lors d'une comparaison spécifique entre deux groupes. La probabilité de commettre cette erreur pour une comparaison donnée est déterminée par $\alpha$. L'erreur au niveau de l'expérience, quant à elle, correspond à déclarer au moins un faux positif parmi toutes les comparaisons effectuées. Plus on a de groupes (et de comparaisons), plus notre erreur au niveau de l'expérience augmente. Le prochain exemple illustre les différences entre les deux niveaux d'erreur.



:::{.exemple section=6} 
Pour faciliter la compréhension de l'erreur liée à  la comparaison entre les groupes  et l'erreur liée à l'expérimentation, nous vous proposons l'exercice de simulation suivant. Nous simulons des données où l'hypothèse nulle est vraie, c'est-à-dire qu'il n'y a aucune différence entre les moyennes des groupes. On crée trois groupes de $n = 50$ tirés d'une population suivant une distribution normale avec $\mu = 5$ et $\sigma = 3$ (c.-à-d., N(5, 3)). En d'autres mots, nous simulons les données de trois groupes et ces données sont toutes tirées de la même population pour satisfaire $H_0$. Il y a trois comparaisons possibles: groupe 1 *vs* groupe 3, groupe 2 *vs* groupe 3 et groupe 1 *vs* groupe 2. Nous voulons savoir quelle est la probabilité de commettre une erreur liée à la comparaison et une erreur liée à l'expérience. On peut décrire l'algorithme de la simulation comme suit :
:::
1. on génère des données aléatoires pour chacun des groupes conformément à $H_0$ (`rnorm(n = 50, mean = 5, sd = 3)`);
2. on réalise les trois comparaisons (1 *vs* 3, 2 *vs* 3, 1 *vs* 2) à l'aide de trois tests $t$ (`t.test( )`);
3. on détermine pour chaque test $t$ effectué, si $P \leq \alpha$ (p. ex., $P \leq 0.05$);
4. on répète les étapes 1 à 3 un grand nombre de fois (p. ex., 1000 fois).
 
On peut réaliser ce genre d'exercice avec des boucles dans R. Le document *Les boucles avec R* couvre les concepts de base et donne des exemples pour construire des boucles qui permettront de réaliser des tâches répétitives.

```{r errors, keep.source = FALSE, echo = FALSE}
##illustrate the experiment-wise error vs comparison-wise error
##3 groups of n = 50 that DO NOT DIFFER AMONG EACH OTHER, all taken from the same population mu=5, sd=3
##create matrix to hold results
set.seed(seed = 221)
nsims <- 1000   #set number of simulations
out <- matrix(NA, nrow = nsims, ncol = 4)
colnames(out) <- c("1 vs 2", "1 vs 3", "2 vs 3", "Erreur liée à l'expérience")
##start loop
for (i in 1:nsims) {
  ##create 1st group -groups are all drawn from the same population (H0 is true)
group1 <- rnorm(n = 50, mean = 5, sd = 3)
##create 2nd group
group2 <- rnorm(n = 50, mean = 5, sd = 3)
##create 3rd group
group3 <- rnorm(n = 50, mean = 5, sd = 3)
##1vs2
comp1 <- t.test(group1, group2)
##1vs3
comp2 <- t.test(group1, group3)
##2vs3
comp3 <- t.test(group2, group3)
out[i, 1] <- ifelse(comp1$p.value<=0.05, "*", "NS")
out[i, 2] <- ifelse(comp2$p.value<=0.05, "*", "NS")
out[i, 3] <- ifelse(comp3$p.value<=0.05, "*", "NS")
out[i, 4] <- ifelse(any(c(comp1$p.value, comp2$p.value,comp3$p.value) <= 0.05), 1, 0)
}
```

À la fin de la simulation, nous pouvons constater le nombre de fois où nous avons rejeté $H_0$ par erreur. Ici, nous savons que $H_0$ est vraie puisque nous avons simulé des données qui respectent l'hypothèse nulle (aucune différence entre les moyennes des groupes). À chaque fois que nous avons rejeté $H_0$ dans cette simulation, nous avons commis une erreur.

Le tableau \@ref(tab:error) montre le résultat des 10 premières itérations de la simulation (les étapes 1 à 3 ci-dessus). Les trois premières colonnes correspondent aux trois comparaisons possibles. La valeur NS correspond à un résultat non significatif ($H_0$ non rejetée). Le symbole * indique le rejet de $H_0$ et, par conséquent, une erreur liée à la comparaison. La quatrième colonne correspond à l'erreur liée à l'expérience. Cette colonne prend la valeur de 1 lorsqu'au moins une comparaison a rejeté $H_0$ (une erreur liée à l'expérience) et la valeur de 0 lorsqu'aucune comparaison ne rejette $H_0$.

```{r error, keep.source = FALSE, echo = FALSE}
##comparison-wise error rate of comparison 1
Error_comp1 <- sum(ifelse(out[,1]=="*", 1, 0))/nsims
##comparison-wise error rate of comparison 2
Error_comp2 <- sum(ifelse(out[,2]=="*", 1, 0))/nsims
##comparison-wise error rate of comparison 3
Error_comp3 <- sum(ifelse(out[,3]=="*", 1, 0))/nsims

##experiment-wise error rate error among any comparison
Error_exp <- sum(ifelse(out[,4]=="1", 1, 0))/nsims

kable(out[1:10, ], 
      row.names = FALSE, 
      caption = "Premières itérations de la simulation illustrant les erreurs liée à la comparaison et à l'expérience.",
      "html", booktabs = TRUE, escape = FALSE) %>% 
  kable_styling(full_width = F, position = "center")
```
La première rangée du tableau \@ref(tab:error) correspond à la première itération, et on constate qu'aucune erreur de comparaison n'a été commise, et, par conséquent, aucune erreur liée à l'expérience. La huitième rangée du même tableau montre que les comparaisons 1 *vs* 3 et 2 *vs* 3 ont rejeté par erreur $H_0$ (erreurs liées à la comparaison) et qu'il y a donc une erreur au niveau de l'expérience. On remarquera qu'à l'intérieur de chaque colonne, la proportion du nombre d'erreurs de comparaison par rapport au nombre total d'itérations oscille autour de $\alpha = 0.05$, puisque c'est le seuil que nous avons utilisé dans les comparaisons multiples. Toutefois, en compilant le nombre total d'erreurs au niveau de l'expérience (la quatrième colonne), on obtient la probabilité de commettre une erreur au niveau de l'expérience. Ici, nous avons :

$$\frac{`r sum(ifelse(out[,4]=="1", 1, 0))` \: \mathrm{erreurs \: li\acute{e}es \: \grave{a} \: l^\prime exp\acute{e}rience}}{`r nrow(out)` \: \mathrm{it\acute{e}rations}} = `r Error_exp`$$

Bien que nous ayons fixé le seuil $\alpha$ à 0.05, la probabilité de commettre une erreur au niveau de l'expérience est supérieure à ce seuil (`r Error_exp`). Ce problème a motivé le développement de plusieurs types de comparaisons multiples afin de contrôler l'erreur au niveau de l'expérience.



#### Suppositions

Les tests de comparaisons multiples ont les mêmes suppositions de normalité et d'homoscédasticité que l'ANOVA. Les comparaisons multiples sont moins robustes face aux déviations de ces conditions, surtout à celles d'homoscédasticité, qui augmentent les erreurs de type I et II.

#### Structure générale 

Un grand nombre de tests de comparaisons multiples ont été développés pour différentes applications. En général, les tests de comparaisons multiples suivent le même principe:

1. on effectue l'ANOVA;
2. si on rejette $H_0$, on peut faire des comparaisons multiples. Si on ne rejette pas $H_0$, l'analyse est terminée. Ce choix de ne pas poursuivre avec des comparaisons multiples s'explique du fait que l'ANOVA est plus puissante que les comparaisons multiples;
3. on classe les moyennes des groupes par ordre croissant;
4. on calcule la différence entre la plus grande moyenne *vs* la plus petite;
5. comme pour un test $t$ (voir la leçon 4), on divise les différences par une erreur-type pour une statistique $q$, c-à-d un quantile de la distribution associée à l'hypothèse nulle: $q = (\bar{x}_{grande} - \bar{x}_{petite})/SE$ . Le calcul du quantile $q$ implique donc le carré moyen des erreurs, $MSE$ ($MSE$ étant une fonction de $SE$), mais dépend du test et de sa distribution;
6. on compare le $q_{obs}$ à un $q_{th\acute{e}orique}$, qui dépend du seuil $\alpha$, des $df$ du $MSE$ et du nombre de groupes comparés. Dans la plupart des cas, $\alpha$ représente l'erreur au niveau de l'expérience;
7. un $q_{obs} \geq q_{th\acute{e}orique}$ indique qu'il y a une différence entre la paire de moyennes comparées.
 
Habituellement, on commence en comparant la plus grande moyenne $\bar{x}_{k}$ des $k$ groupes (ordonnés en ordre croissant de 1 à $k$) aux autres (*vs* $\bar{x}_{1}$, *vs* $\bar{x}_{2}$, \ldots, *vs* $\bar{x}_{k - 1}$). Si, par exemple, on ne rejette plus $H_0$ à partir de la comparaison de $\bar{x}_{k}$ *vs* $\bar{x}_{2}$, il n'est pas nécessaire de vérifier les comparaisons pour les moyennes de 3 à $k-1$ parce que l'on sait déjà qu'on ne rejettera pas $H_0$. On passe ensuite à la comparaison de $\bar{x}_{k - 1}$ avec les moyennes de 1 à $k-2$. Encore une fois, nous pouvons arrêter les comparaisons avec les moyennes subséquentes, dès qu'on ne rejettera plus $H_0$ pour l'une des moyennes. On procède ainsi pour toutes les moyennes pour, enfin, terminer en comparant $\bar{x}_{2}$ *vs* $\bar{x}_{1}$. Par exemple, considérons les moyennes de cinq groupes organisées par ordre croissant:

$$ A \qquad C \qquad B \qquad E \qquad D $$
$$  3.1 \qquad 9.3 \qquad 10.5 \qquad 10.9 \qquad 11.8 $$

Si on compare la plus grande moyenne (groupe D) au groupe C et que l'on ne rejette pas $H_0$, on ne testera ni le groupe D vs le groupe B, ni le groupe D vs le groupe E. De plus, on ne testera pas le groupe E vs le groupe C, car les groupes D et C ne diffèrent pas l'un de l'autre, et la valeur de E est comprise entre celles de C et D.

#### Test de Tukey
 
Parmi les tests de comparaisons multiples, mentionnons le test de Dunnett (lorsqu'on veut comparer tous les groupes à un témoin), le test de Student-Newman-Keuls (SNK, Newman-Keuls) qui dépend du nombre de moyennes séparant les moyennes comparées, le test de Scheffé, et le test de Tukey (*Tukey test*, *Tukey's Honestly Significant Difference (HSD) test*). Le test de Tukey est d'ailleurs l'un des tests de comparaisons multiples les plus recommandés. La statistique $q$ s'obtient comme suit : 

$$ q_{obs} = \frac{\bar{x}_{groupe \: 1} - \bar{x}_{groupe \: 2}}{SE}$$ 

où $\bar{x}_{groupe \: 1}$ correspond à la moyenne du groupe 1, $\bar{x}_{groupe \: 2}$ à la moyenne du groupe 2 et $SE$ est l'erreur-type du test de Tukey. Cette dernière est donnée par $SE = \sqrt{\frac{MSE}{n}}$, où $MSE$ est le carré moyen des erreurs et $n$ est le nombre d'observations dans chaque groupe. Nous appliquons le test de Tukey dans le prochain exemple.



:::{.exemple section=6}
Dans l'exemple 6.6, nous avons rejeté l'hypothèse nulle à l'aide de l'ANOVA réalisée sur des données de consommation annuelle de boissons sucrées par des jeunes de 5 régions différentes. On peut appliquer le test de Tukey pour trouver où se trouvent les différences entre les moyennes des groupes. On peut commencer par calculer les moyennes des groupes et les ordonner :

```{r echo = TRUE, keep.source = TRUE}
##moyennes des groupes
moy <- tapply(X = cons$Volume, INDEX = cons$Region, FUN = mean)
##en ordre croissant et en arrondissant à deux décimales
round(sort(moy), digits = 2)
```

Nous pouvons calculer l'erreur-type du dénominateur nécessaire au calcul de la statistique, $SE = \sqrt{\frac{MSE}{n}}$ :

```{r echo = TRUE, keep.source = TRUE}
##sous-jeu de données
SLSJ <- cons[cons$Region == "SLSJ", ]
GIM <- cons[cons$Region == "GIM", ]
CA <- cons[cons$Region == "CA", ]
CN <- cons[cons$Region == "CN", ]
BSL <- cons[cons$Region == "BSL", ]
##SSE de SLSJ
SSE.SLSJ <- sum((SLSJ$Volume-mean(SLSJ$Volume))^2)
##SSE de GIM
SSE.GIM <- sum((GIM$Volume-mean(GIM$Volume))^2)
##SSE de CA
SSE.CA <- sum((CA$Volume-mean(CA$Volume))^2)
##SSE de CN
SSE.CN <- sum((CN$Volume-mean(CN$Volume))^2)
##SSE de BSL
SSE.BSL <- sum((BSL$Volume-mean(BSL$Volume))^2)
##SSE
SSE <- SSE.SLSJ + SSE.GIM + SSE.CA + SSE.CN + SSE.BSL
SSE
##degrés de liberté de SSE
df.erreur <- 5 * (6 - 1)
df.erreur
##carré moyen des erreurs
MSE <- SSE/df.erreur
MSE
##SE pour le Tukey
SE <- sqrt(MSE/6)
SE
```

Par la suite, on calcule le $q$ pour chaque comparaison multiple (tableau \@ref(tab:tuk)). Chaque valeur de $q$ est comparée à ce qu'on devrait obtenir si $H_0$ est vraie et la fonction `ptukey( )` nous fournit la probabilité cumulative en faveur de $H_0$ pour `nmeans` groupes et `df` degrés de liberté du terme d'erreur **de l'ANOVA**. À titre d'exemple, la probabilité de la comparison GIM vs BSL se calcule à l'aide de la commande suivante :

```{r ptukeyex, keep.source = FALSE, echo = TRUE}
ptukey(q=5.06, nmeans=5, df=25, lower.tail = FALSE)
```

Où $q$ est $q_{obs} = (\bar{x}_{GIM} - \bar{x}_{BSL})/{SE}$

Comme d'habitude, on rejette $H_0$ lorsqu'elle est peu probable (c-à-d, $P \leq \alpha$).

```{r qvals, keep.source = FALSE, echo = FALSE}
moys <- round(sort(moy), digits = 2)
SE.round <- round(SE, 2)

##Tukey test
out.tuk <- TukeyHSD(x = m1)
out <- as.data.frame(out.tuk$Region)
out$qobs <- out$diff/SE
out <- round(out, 3)
out$diff <- round(out$diff, 2)
```

```{r tuk, keep.source = FALSE, echo = FALSE}
data <- data.frame(
  Comparaison = c("GIM vs BSL", "GIM vs CA", 
                  "GIM vs CN", "GIM vs SLJS", 
                  " ", "SLSJ vs BSL", 
                  "SLSJ vs CA", "SLSJ vs CN", 
                  " ",  "CN vs BSL", 
                  "CN vs CA", " ", 
                  "CA vs BSL"),
  Difference = c(out["GIM-BSL", "diff"], out["GIM-CA", "diff"], 
                 out["GIM-CN", "diff"], -1 * out["SLSJ-GIM", "diff"], 
                 " ",  out["SLSJ-BSL", "diff"], 
                 out["SLSJ-CA", "diff"], out["SLSJ-CN", "diff"], 
                 " ",  out["CN-BSL", "diff"], 
                 out["CN-CA", "diff"], " ", 
                 out["CA-BSL", "diff"]),
  SE = c(SE.round, SE.round, 
         SE.round, SE.round, 
         " ", SE.round, 
         SE.round, SE.round, 
         " ", SE.round, 
         SE.round, " ", 
         SE.round),
  q_obs = c(out["GIM-BSL", "qobs"], out["GIM-CA", "qobs"], 
            "on ne teste pas", "on ne teste pas",
            " ", out["SLSJ-BSL", "qobs"], 
            "on ne teste pas", "on ne teste pas", 
            " ",  out["CN-BSL", "qobs"], 
            "on ne teste pas", " ", 
            "on ne teste pas"),
  P = c(out["GIM-BSL", "p adj"], out["GIM-CA", "p adj"], 
        " ", " ", 
        " ",  out["SLSJ-BSL", "p adj"], 
        " ", " ", 
        " ",  out["CN-BSL", "p adj"], 
        " ", " ", 
        " "),
  Conclusion = c("rejeter $H_0$", "ne pas rejeter $H_0$", 
                 " ", " ", 
                 " ",  "rejeter $H_0$", 
                 " ", " ", 
                 " ",  "ne pas rejeter $H_0$",
                 " ", " ", 
                 " ")
)

kable(data, 
      row.names = FALSE, 
      caption = "Comparaisons multiples de Tukey entre les groupe définis par les régions.",
      "html", booktabs = TRUE, escape = FALSE) %>% 
  kable_styling(full_width = F, position = "center")
```

On peut créer ce tableau rapidement à l'aide de la fonction `TukeyHSD( )` :

```{r tukeyHSD, keep.source = TRUE}
##test de Tukey
TukeyHSD(m1, which = "Region")
```

D'après la sortie R, on observe seulement deux différences significatives ($\alpha= 0.05$) : la consommation moyenne pour la région BSL est plus petite que celles des régions SLSJ et GIM. En conséquence, on ne peut pas conclure que les moyennes pour les régions CA et CN diffèrent avec celles des autres régions, ni que la moyenne pour la région SLSJ diffère de celle de la région GIM.
:::



#### Présentation des résultats

Il est possible de présenter les résultats des comparaisons multiples de différentes manières. L'une d'elles consiste à ordonner les groupes selon la valeur des moyennes et d'unir à l'aide d'un trait les groupes qui ne diffèrent pas entre eux. On peut aussi présenter les résultats graphiquement, typiquement en présentant les moyennes ± des barres d'erreur. Comme barre d'erreur, on peut utiliser l'erreur-type des moyennes de chaque groupe, la racine-carrée du carré moyen des erreurs ($\sqrt{MSE}$) ou des intervalles de confiance construits à partir de l'une ou l'autres des mesures de dispersion mentionnées. On emploie des lettres pour distinguer les groupes qui diffèrent entre eux sur le graphique. Le prochain exemple illustre ces deux méthodes avec les données de consommation annuelle de boissons sucrées par des jeunes selon différentes régions de l'Est du Québec. À noter que les comparaisons multiples indiquent parfois qu'un traitement appartient à deux groupes. Cette double appartenance indique que la comparaison multiple n'a pas permis de détecter une différence entre ces deux groupes.

Les tests de comparaisons multiples ne peuvent parfois trouver de groupes qui diffèrent entre eux, alors que l'ANOVA avait rejeté $H_0$. L'ANOVA est plus puissante que les tests de comparaisons multiples, ce qui explique, à l'occasion, l'absence d'une différence entre les paires de groupes. Puisque l'ANOVA est plus puissante que les comparaisons multiples, nous recommandons de ne pas procéder à des comparaisons multiples si l'ANOVA n'a pas réussi à rejeter $H_0$.



:::{.exemple section=6}
On peut représenter succinctement le résultat des comparaisons multiples sur les données de consommation de boissons sucrées selon la région :

```{r echo=FALSE}
data <- data.frame(
  BSL = 46.52,
  CA = 55.33,
  CN = 56.93,
  SLSJ = 61.05,
  GIM = 61.07
)

kable(data, 
      row.names = FALSE, 
      "html", booktabs = TRUE, escape = FALSE) %>% 
  kable_styling(full_width = F, position = "center")
```

La présentation des résultats à l'aide de traits facilite l'interprétation. On voit rapidement que CA et CN ont une double appartenance: ils appartiennent au groupe constitué de BSL, CA et CN ainsi qu'au groupe composé de CA, CN, SLSJ et GIM. Les groupes SLSJ et GIM ne diffèrent pas entre eux, mais sont différents du groupe BSL. En effet, le même trait relie les groupes SLSJ et GIM et ce même trait n'inclut pas le groupe BSL. Le graphique montre la même information (présence de deux groupes), mais à l'aide de lettres (Figure \@ref(fig:plotregion)). On remarque que les groupes CA et CN ont une double appartenance puisqu'ils sont identifiés avec deux lettres. On trouve le code complet pour obtenir le graphique ci-dessous : 

```{r plotregion, keep.source = TRUE, echo = TRUE, fig = TRUE, fig.align='center', fig.cap="Présentation graphique des résultats des comparaisons multiples avec le test de Tukey."}
##ordonner moyennes
moys <- sort(moy)
##calculer racine carrée de MSE
sqrt.MSE <- sqrt(MSE)

##calculer les limites des barres d'erreur
lim.sup <- moys + sqrt.MSE
lim.inf <- moys - sqrt.MSE

##créer graphique vide sans axe des x's
plot(x = 0, y = 0, type = "n",
     ylim = c(min(lim.inf), max(lim.sup+10)),
     xlim = c(0, 6), xlab = "Région",
     ylab = "Consommation annuelle (L)",
     main = "Moyennes ± racine-carrée de MSE",
     xaxt = "n", cex.lab = 1.2)
##ajouter axe des x's
axis(side = 1, at = c(1, 2, 3, 4, 5),
     labels = names(moys))
##ajouter moyennes
points(x = c(1, 2, 3, 4, 5),
       y = moys)
##ajouter barres d'erreurs
arrows(x0 = c(1, 2, 3, 4, 5),
       y0 = lim.inf,
       x1 = c(1, 2, 3, 4, 5),
       y1 = lim.sup, length = 0.05,
       angle = 90, code = 3)
##ajouter les lettres, lim.sup + 10
text(x = 1, y = 54.5, labels = "a")
text(x = 2, y = 63.3, labels = "ab")
text(x = 3, y = 64.9, labels = "ab")
text(x = 4, y = 69.0, labels = "b")
text(x = 5, y = 69.1, labels = "b")
```
:::



### Conclusion

Nous venons d'étudier le concept de comparaisons multiples ainsi que les problèmes qui y sont associés, notamment une augmentation de la probabilité de commettre une erreur de type I (déclarer un faux positif). Au lieu d'utiliser une série de tests $t$, nous avons vu que l'analyse de variance (ANOVA) permet de comparer tous les groupes simultanément en estimant la variance expliquée par le facteur (variable catégorique) d'intérêt et en la comparant à la variance résiduelle (inexpliquée). Le tableau d'ANOVA véhicule beaucoup d'information et il est important d'inclure ses détails dans la rédaction des résultats. Bien que l'ANOVA permette de déterminer si le facteur a un effet important sur la variable réponse, elle ne permet pas de déterminer où se trouvent les différences. Pour ce faire, nous avons recours à des tests de comparaisons multiples exécutés *a posteriori* qui contrôlent l'erreur au niveau de l'expérience. Pour terminer, nous avons fait quelques propositions concernant la présentation des résultats afin de faciliter l'interprétation d'une ANOVA.

## Les boucles avec R

### Les boucles

Les boucles dans R permettent de réaliser des tâches répétitives et ennuyeuses. Elles sont plus rapides que les tâches exécutées à la main et réduisent les occasions de commettre des erreurs. Par exemple, on peut utiliser une boucle pour effectuer une manipulation d'un jeu de données, telle que d'importer une série de fichiers stockés dans le même répertoire afin d'y extraire les données d'intérêt.

#### Structure

Il existe plusieurs façons de créer une boucle. Celle que nous verrons ici utilise la fonction `for( )` pour mettre en place la boucle.   Le contenu de la boucle sera inclus entre des accolades \{ \}. Comme premier exemple, nous allons générer 100 échantillons contenant chacun 30 observations qui proviennent d'une distribution normale N($\mu = 10$, $\sigma = 1$), puis nous calculerons la moyenne de chaque échantillon.

Premièrement, on crée un objet pour stocker les moyennes calculées :

```{r keep.source = TRUE}
##objet pour stocker résultats
output <- rep(x = NA, times = 100)
output
``` 

La boucle comme telle sera initiée par la commande :

```{r keep.source = TRUE}
##on crée la boucle
for(i in 1:100) {
  ##on génère l'échantillon
  simdata <- rnorm(n = 30, mean = 10, sd = 1)
  ##on remplace le NA par la moyenne
  output[i] <- mean(simdata)
}
```

Décortiquons le code présenté ci-dessus:

1. La commande `for( )` indique que la boucle sera effectuée de `i = 1` jusqu'à `i = 100`. À noter que la boucle nécessite un nom de variable quelconque, par exemple, `i`, `j`, `iter`, `sim`, ou tout autre nom de notre choix. Toutefois, la boucle doit se référer à cette même variable plus tard. Immédiatement après la commande `for( )`, on trouvera une accolade \{ qui indique le début du corps de la boucle. 
2. À la deuxième ligne, on crée un objet temporaire `simdata` qui contiendra 30 observations provenant d'une distribution normale ayant une moyenne de 10 et un écart-type de 1. 
3. La prochaine ligne calcule la moyenne des observations de l'objet `simdata` et stocke cette moyenne dans l'objet `output`. Ainsi, le premier `NA` sera remplacé par la première moyenne. 
4. La dernière ligne contient une accolade \} qui indique la fin de la première itération `(i = 1)`. 
5. À l'itération `i = 2`, l'objet `simdata` stockera 30 nouvelles observations, et cette moyenne sera stockée dans `output[i = 2]`. La boucle continue jusqu'à l'itération `i = 100`}`. 

Dans notre cas, la boucle a donné le résultat, qui sera différent sur votre machine puisque nous n'avons pas spécifié `set.seed( )` :

```{r keep.source = TRUE}
output
``` 

Nous avons 100 moyennes calculées à partir de 100 échantillons de 30 observations provenant d'une population N($\mu = 10$, $\sigma = 1$). 

On peut utiliser les boucles pour effectuer des manipulations plus complexes. D'ailleurs, les boucles sont utiles pour effectuer des tests de randomisation ou des simulations. Comme deuxième exemple, illustrons comment estimer la probabilité de commettre une erreur au niveau de l'expérience et au niveau des comparaisons telles que discutées dans le texte *Analyse de variance à un critère*. Dans l'exemple en question, nous avons considéré les probabilités de commettre des erreurs au niveau de l'expérience et au niveau des comparaisons avec trois groupes.

```{r multcomp, keep.source = TRUE}
##illustration des erreurs au niveau de l'expérience et 
##au niveau des comparaisons
##3 groupes de n = 50 qui ne diffèrent pas les uns des autres
##tous provenant d'une même population normale avec mu=5 et sd=3
##alpha = 0.05
#############################
##on crée une matrice pour stocker les résultats
set.seed(seed = 221)
nsims <- 1000   #nombre de simulations
out <- matrix(NA, nrow = nsims, ncol = 4)
colnames(out) <- c("1 vs 2", "1 vs 3", "2 vs 3", "Erreur liée à l'expérience")
##débuter boucle
for (i in 1:nsims) {
  ##on crée 1er groupe
  ##tous les groupes sont égaux (H0 est vraie)
  groupe1 <- rnorm(n = 50, mean = 5, sd = 3)
  ##on crée 2ième groupe
  groupe2 <- rnorm(n = 50, mean = 5, sd = 3)
  ##on crée 3ième groupe
  groupe3 <- rnorm(n = 50, mean = 5, sd = 3)
  ##1vs2
  comp1 <- t.test(groupe1, groupe2)
  ##1vs3
  comp2 <- t.test(groupe1, groupe3)
  ##2vs3
  comp3 <- t.test(groupe2, groupe3)
  out[i, 1] <- ifelse(comp1$p.value<=0.05, "*", "NS")
  out[i, 2] <- ifelse(comp2$p.value<=0.05, "*", "NS")
  out[i, 3] <- ifelse(comp3$p.value<=0.05, "*", "NS")
  out[i, 4] <- ifelse(any(c(comp1$p.value, 
                            comp2$p.value,
                            comp3$p.value) <= 0.05), 1, 0)
}
```

Le code ci-dessus commence en spécifiant une valeur initiale afin d'alimenter l'algorithme du générateur de nombres aléatoires, ce qui permet de reproduire les mêmes résultats sur tous les ordinateurs. La prochaine ligne crée l'objet `nsims` pour spécifier le nombre d'itérations désirées pour la boucle (ici, 1000 itérations). La création d'un objet pour spécifier les itérations permet de se référer à cet objet tout le long du code. Ainsi, si on désire modifier le nombre d'itérations, nous n'aurons qu'à modifier l'objet `nsims` et le reste du code demeurera inchangé. La ligne suivante crée la matrice `out` de 4 colonnes et `nsims` rangées. À noter qu'ici, les résultats des trois comparaisons (groupe 1 *vs* groupe 2, groupe 1 *vs* groupe 3 et groupe 2 *vs* groupe 3) seront sauvegardés dans les trois premières colonnes alors que la dernière colonne sera réservée pour déterminer l'erreur au niveau de l'expérience. 

La fonction `colnames` permet d'ajouter des étiquettes aux colonnes pour clairement identifier chaque colonne. La ligne débutant par `for(i in 1:nsims)` indique qu'on veut une boucle de `i = 1` jusqu'à `i = nsims`. Ensuite, nous avons trois lignes de codes pour générer les données de chaque groupe conforme à $H_0$, c'est-à-dire qu'il n'y a pas de différences entre les trois groupes (ils proviennent de la même population). Nous effectuons ensuite les comparaisons entre chaque groupe à l'aide d'un test $t$. Pour chacun des tests, si la valeur de $P \leq \alpha$, nous avons décidé d'ajouter un `*` dans la colonne, autrement nous avons inséré les caractères `NS`. À noter que si on rejette $H_0$ pour un test $t$ sur ces données, nous avons commis une erreur de type I puisque les données simulées sont réellement tirées de la même population (la boucle a été construite pour générer des données conformes à $H_0$). 

Pour une itération `i` donnée, à chaque fois que la colonne 1 contient `*`, c'est une erreur au niveau de la comparaison. Il en va de même avec les colonnes 2 et 3. La quatrième colonne de la matrice `out` prend la valeur de 1 si au moins une des colonnes à l'itération `i` a rejeté $H_0$ ce qui correspond à l'erreur au niveau de l'expérience, autrement la colonne prend la valeur de 0. Ces étapes sont répétées `i` fois.

Lorsque toutes les itérations de la boucle sont complétées, nous obtenons les résultats suivants :

```{r multcomp2, keep.source = TRUE}
##20 premières itérations
out[1:20, ]
##erreurs au niveau de la comparaison 1 vs 2
err.comp1 <- sum(out[, 1] == "*")/nsims
err.comp2 <- sum(out[, 2] == "*")/nsims
err.comp3 <- sum(out[, 3] == "*")/nsims
err.comp1
err.comp2
err.comp3
##erreur au niveau de l'expérience
err.exp <- sum(out[, 4] == "1")/nsims
``` 

Afin de déterminer la probabilité de commettre une erreur au niveau des comparaisons, on peut calculer la proportion du nombre de résultats significatifs ($P < \alpha$) par rapport au nombre total de simulations. On obtient les valeurs de `r err.comp1`, `r err.comp2` et `r err.comp3`, pour les comparaions 1 *vs* 2, 1 *vs* 3 et 2 *vs* 3, respectivement. Ces valeurs oscillent très près du seuil de signification car elles dépendent directement de cette valeur (ici, 0.05). L'erreur au niveau de l'expérience est de `r err.exp`. 

```{r multcomp0.1, keep.source = FALSE, echo = FALSE}
##illustration des erreurs d'expérience et de comparaison
##3 groupes de n = 50 qui ne diffèrent pas les uns des autres
##tous provenant d'une même population normale avec mu=5 et sd=3
##alpha = 0.10
#############################
##on crée une matrice pour stocker les résultats
set.seed(seed = 221)
nsims <- 1000   #nombre de simulations
out2 <- matrix(NA, nrow = nsims, ncol = 4)
colnames(out2) <- c("1 vs 2", "1 vs 3", "2 vs 3", "Erreur d'expérience")
##débuter boucle
for (i in 1:nsims) {
  ##on crée 1er groupe
  ##tous les groupes sont égaux (H0 est vraie)
  groupe1 <- rnorm(n = 50, mean = 5, sd = 3)
  ##on crée 2ième groupe
  groupe2 <- rnorm(n = 50, mean = 5, sd = 3)
  ##on crée 3ième groupe
  groupe3 <- rnorm(n = 50, mean = 5, sd = 3)
  ##1vs2
  comp1 <- t.test(groupe1, groupe2)
  ##1vs3
  comp2 <- t.test(groupe1, groupe3)
  ##2vs3
  comp3 <- t.test(groupe2, groupe3)
  out2[i, 1] <- ifelse(comp1$p.value<=0.10, "*", "NS")
  out2[i, 2] <- ifelse(comp2$p.value<=0.10, "*", "NS")
  out2[i, 3] <- ifelse(comp3$p.value<=0.10, "*", "NS")
  out2[i, 4] <- ifelse(any(c(comp1$p.value, 
                            comp2$p.value,
                            comp3$p.value) <= 0.10), 1, 0)
}
err.comp1b <- sum(out2[, 1] == "*")/nsims
err.comp2b <- sum(out2[, 2] == "*")/nsims
err.comp3b <- sum(out2[, 3] == "*")/nsims
err.expb <- sum(out2[, 4] == "1")/nsims
``` 

Si on avait utilisé un seuil de 0.10, nous aurions obtenu les valeurs `r err.comp1b`, `r err.comp2b` et `r err.comp3b` pour les comparaisons 1 *vs* 2, 1 *vs* 3 et 2 *vs* 3, respectivement. L'erreur au niveau de l'expérience dans ce cas serait de `r err.expb`, obtenu en divisant le nombre de lignes avec au moins un résultat significatif par le nombre total d'itérations. Les calculs pour les erreurs au niveau de l'expérience et au niveau des comparaisons ne sont pas montrés ici pour un seuil $\alpha = 0.10$. Nous vous suggérons de les faire comme exercice.

### Alternatives aux boucles

L'utilisation de boucles dans R permet beaucoup de flexibilité pour réaliser des tâches très variées. Les boucles peuvent être imbriquées les unes dans les autres. Nous avons illustré l'utilisation de `for( )`, bien qu'il est aussi possible de réaliser des boucles avec des fonctions comme `while( )` ou `break( )`. Pour de très gros jeux de données ou certains types de calculs, les boucles peuvent être lentes. Certaines fonctions peuvent aussi agir un peu comme des boucles. C'est le cas de la fonction `apply( )` que nous verrons dans la section qui suit.

#### `apply( )` et fonctions apparentées 

La fonction `apply( )` et ses fonctions apparentées telles que `lapply( )` et `tapply( )` (pour plus d'options, faites `help.search(apropos = "apply"`) permettent d'appliquer des calculs ou des manipulations à une matrice, à une liste ou à un jeu de données, entre autres. Les fonctions de la famille `apply( )` utilisent un processus qu'on appelle la vectorisation, c'est-à-dire que les calculs sont effectués simultanément sur des vecteurs au lieu d'une valeur à la fois comme avec la boucle. Les fonctions `apply( )` sont souvent beaucoup plus rapides que les boucles. On peut utiliser `tapply( )` pour calculer une statistique (`FUN`) d'une variable numérique `X = Ozone` pour différents groupes définis par une variable catégorique `INDEX = Jardin` dans le jeu de données `jardins.txt`.

```{r ex3, keep.source = TRUE, echo = TRUE}
##importer le jeu de données jardins.txt
ozone <- read.table("Module_6/data/jardins.txt", header = TRUE)
str(ozone)

##on calcule la moyenne de Ozone pour chacun des groupes
tapply(X = ozone$Ozone, INDEX = ozone$Jardin, FUN = mean)
##on calcule la SD de Ozone pour chacun des groupes
tapply(X = ozone$Ozone, INDEX = ozone$Jardin, FUN = sd)
##on calcule le n pour chacun des groupes
tapply(X = ozone$Ozone, INDEX = ozone$Jardin, FUN = length)
##on détermine si chaque groupe contient des valeurs numériques
tapply(X = ozone$Ozone, INDEX = ozone$Jardin, FUN = is.matrix)
``` 

La fonction `tapply( )` est destinée aux jeux de données. De façon plus générale, on peut appliquer une fonction (`FUN`) sur les rangées ou colonnes (`MARGIN`) d'une matrice (`X`) à l'aide de `apply( )` :

```{r ex.apply, keep.source = TRUE}
##on crée une matrice
mat.sim <- matrix(data = 1:24, nrow = 6, ncol = 4)
mat.sim

##on calcule la somme de chaque rangée
apply(X = mat.sim, MARGIN = 1, FUN = sum)
##on compare à rowSums - identique
rowSums(mat.sim)
##on calcule le produit de chaque rangée
apply(X = mat.sim, MARGIN = 1, FUN = prod)

##on calcule la somme de chaque colonne 
apply(X = mat.sim, MARGIN = 2, FUN = sum)
##on compare à colSums - identique
colSums(mat.sim)
##on calcule le produit de chaque colonne
apply(X = mat.sim, MARGIN = 2, FUN = prod)
``` 

On comprend que lorsque l'argument `MARGIN` prend la valeur de 1, les calculs sont effectués sur chacune des rangées. Si `MARGIN` a la valeur de 2, les calculs se réalisent sur chaque colonne.

## Autoévaluation

### Question 1 {-}

**a.** Donnez un avantage d’effectuer une ANOVA au lieu de plusieurs tests $t$ pour comparer les moyennes des groupes entre elles? 

<details>
<summary> Réponse</summary>
L'avantage principal est de réduire l'erreur de type I, puisqu'on teste tous les groupes simultanément. 
</details>

<br>

**b.** Distinguez entre "erreur au niveau de la comparaison" et "erreur au niveau de l'expérience". 

<details>
<summary> Réponse</summary>
L'erreur au niveau de la comparaison se produit lorsqu'on rejette faussement $H_0$ alors qu'elle est vraie pendant une comparaison entre deux groupes. L'erreur au niveau de l'expérience se produit lorsqu'au moins une comparaison a rejeté faussement $H_0$ alors qu'elle était vraie. Le test de Tukey maintient l'erreur liée à l'expérience au seuil $\alpha$ que nous avons fixé. 
</details>

<br>

### Question 2 {-}

**a.** Importez le fichier `Survie.txt` qui présente le temps de survie en heures d’animaux exposés à trois doses de poison (`faible`, `moyenne`, `elevee`). On désire savoir s'il existe des différences entre les moyennes des groupes définis par les doses de poison.

<details>
<summary> Réponse</summary>
```{r keep.source = TRUE, echo = TRUE, highlight = TRUE}
##on importe le jeu de données
poison <- read.table("Module_6/data/Survie.txt", header = TRUE)
head(poison)
``` 
</details>

<br>

**b.** Spécifiez l'hypothèse nulle que vous pourriez tester avec ces données.

<details>
<summary> Réponse</summary>
Les hypothèses statistiques testées sont :  
$H_0: \mu_\mathtt{faible} = \mu_\mathtt{moyenne} = \mu_\mathtt{elevee}$  
$H_a$: au moins une moyenne diffère des autres   
$\alpha = 0.05$  
</details>

<br>

**c.** À l’aide d’une ANOVA, déterminez si le temps de survie dépend de la dose de poison. Vérifiez toutes les suppositions de l’ANOVA et effectuez des transformations si nécessaire.

<details>
<summary> Réponse</summary>
Avant de faire l'ANOVA, observons la structure interne des données :

```{r keep.source = TRUE, echo = TRUE, highlight = TRUE}
str(poison)
``` 

On observe que la variable `Dose` est une variable caractère (`chr`). Or elle doit être un `facteur` (`factor`) pour être utilisée dans l'analyse. Nous devons donc la transformer :   

```{r keep.source = TRUE, echo = TRUE, highlight = TRUE}
poison$Dose <- as.factor(poison$Dose)
``` 

Remarquer que le changement a bel et bien été réalisé dans la structure des données :

```{r keep.source = TRUE, echo = TRUE, highlight = TRUE}
str(poison)
```

Nous pouvons maintenant réaliser l'ANOVA. 

```{r keep.source = TRUE, echo = TRUE, fig = TRUE}
m1 <- aov(Temps ~ Dose, data = poison)


## Vérifions que les suppositions sont respectées. 
par(mfrow = c(2, 2))
plot(m1)
``` 

On constate que les variances ne sont pas homogènes, puisque le graphique des résidus en fonction des valeurs prédites montre qu'un groupe varie moins que les autres. 

```{r keep.source = TRUE, echo = TRUE, fig = TRUE}
##on essaie une transformation log
poison$log.Temps <- log(poison$Temps)
m2 <- aov(log.Temps ~ Dose, data = poison)


## Vérifions que les suppositions sont respectées suite à cette transformation:
par(mfrow = c(2, 2))
plot(m2)
``` 


Les variances sont maintenant homogènes après cette transformation. Les résidus respectent aussi la condition de normalité. De plus, nous assumons que le dispositif expérimental assure la supposition d'indépendance des erreurs. Nous pouvons donc procéder avec l'interprétation de l'ANOVA.

</details>

<br>

**d.** Que pouvez-vous conclure de l’analyse? Incluez le tableau d'ANOVA dans votre présentation des résultats.

<details>
<summary> Réponse</summary>
```{r keep.source = TRUE, echo = TRUE}
summary(m2)
``` 
On conclut qu'il y a au moins une moyenne d'un groupe soumis à une dose de poison qui diffère des autres groupes.
</details>

<br>

**e.** Si vous avez rejeté l'hypothèse nulle de l'ANOVA, effectuez des comparaisons multiples. Présentez les résultats des comparaisons multiples à l'aide d'un graphique.

<details>
<summary> Réponse</summary>
```{r keep.source = TRUE}
TukeyHSD(m2)
``` 

Le test de Tukey indique que les groupes de dose `moyenne` et `faible` ne diffèrent pas l'un de l'autre, mais que le groupe à dose `elevee` diffère des deux autres groupes. On peut représenter le tout dans un graphique en suivant les étapes suivantes :

```{r tukey, echo = TRUE, keep.source = TRUE, fig = TRUE}
##moyennes des groupes
moy.orig <- tapply(X = poison$log.Temps, INDEX = poison$Dose, FUN = mean)

##on met les moyenne en ordre croissant
moy <- sort(moy.orig)

##extraire MSE
MSE <- 1.0527
##aussi possible d'extraire à partir du summary
#MSE <- summary(m2)[[1]][2, "Mean Sq"]

##calculer racine carrée de MSE
sqrt.MSE <- sqrt(MSE)

##calculer les limites des barres d'erreur
lim.sup <- moy + sqrt.MSE
lim.inf <- moy - sqrt.MSE

##créer graphique vide sans axe des x's
plot(x = 0, y = 0, type = "n", 
     ylim = c(min(lim.inf), max(lim.sup)+0.1),
     xlim = c(0, 4), xlab = "Doses de poison",
     ylab = "Log du temps de survie", 
     main = "Moyennes ± racine-carrée de MSE",
     xaxt = "n")
##ajouter axe des x's
axis(side = 1, at = c(1, 2, 3),
     labels = names(moy))
##ajouter moyennes
points(x = c(1, 2, 3), 
       y = moy)
##ajouter barres d'erreurs
arrows(x0 = c(1, 2, 3),
       y0 = lim.inf,
       x1 = c(1, 2, 3),
       y1 = lim.sup, length = 0.05,
       angle = 90, code = 3)
##ajouter les lettres, lim.sup + 0.05
text(x = 1, y = lim.sup[1] + 0.05, labels = "b")
text(x = 2, y = lim.sup[2] + 0.05, labels = "a")
text(x = 3, y = lim.sup[3] + 0.05, labels = "a")
``` 

Il est aussi approprié de présenter les résultats sur l'échelle originale de la variable. Ici, puisque nous avons utilisé la transformation logarithmique à base $e$ pour effectuer l'ANOVA, on peut faire la transformation inverse pour ramener les données à l'échelle originale (l'inverse de `log( )` est `exp( )`).

```{r backtransform, keep.source = TRUE, fig = TRUE}
##on transforme les moyennes 
orig.moy <- exp(moy)

##on transforme les bornes des barres d'erreurs
orig.lim.inf <- exp(lim.inf)
orig.lim.sup <- exp(lim.sup)

##créer graphique vide sans axe des x's
plot(x = 0, y = 0, type = "n", 
     ylim = c(min(orig.lim.inf), max(orig.lim.sup)+0.1),
     xlim = c(0, 4), xlab = "Doses de poison",
     ylab = "Temps de survie (h)", 
     main = "Moyennes ± racine-carrée de MSE",
     xaxt = "n")
##ajouter axe des x's
axis(side = 1, at = c(1, 2, 3),
     labels = names(orig.moy))
##ajouter moyennes
points(x = c(1, 2, 3), 
       y = orig.moy)
##ajouter barres d'erreurs
arrows(x0 = c(1, 2, 3),
       y0 = orig.lim.inf,
       x1 = c(1, 2, 3),
       y1 = orig.lim.sup, length = 0.05,
       angle = 90, code = 3)
##ajouter les lettres, lim.sup + 0.40
text(x = 1, y = orig.lim.sup[1] + 0.40, labels = "b")
text(x = 2, y = orig.lim.sup[2] + 0.40, labels = "a")
text(x = 3, y = orig.lim.sup[3] + 0.40, labels = "a")
``` 
</details>

<br>

