<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2.1 Théories | Statistiques avec R</title>
  <meta name="description" content="2.1 Théories | Statistiques avec R" />
  <meta name="generator" content="bookdown 0.39 and GitBook 2.6.7" />

  <meta property="og:title" content="2.1 Théories | Statistiques avec R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="2.1 Théories | Statistiques avec R" />
  <meta name="github-repo" content="sci1018/sci1018" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.1 Théories | Statistiques avec R" />
  
  <meta name="twitter:description" content="2.1 Théories | Statistiques avec R" />
  

<meta name="author" content="" />


<meta name="date" content="2024-08-06" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="intervalles-de-confiance-et-stratégies-déchantillonnage.html"/>
<link rel="next" href="les-graphiques-avec-r.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #204a87; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #204a87; font-weight: bold; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #ce5c00; font-weight: bold; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistiques avec R</a></li>

<li class="divider"></li>
<li><a href="index.html#section" id="toc-section"></a></li>
<li class="part"><span><b>I SCI 1018</b></span></li>
<li class="chapter" data-level="" data-path="à-propos-du-cours.html"><a href="à-propos-du-cours.html"><i class="fa fa-check"></i>À propos du cours</a>
<ul>
<li class="chapter" data-level="" data-path="à-propos-du-cours.html"><a href="à-propos-du-cours.html#présentation"><i class="fa fa-check"></i>Présentation</a>
<ul>
<li class="chapter" data-level="" data-path="à-propos-du-cours.html"><a href="à-propos-du-cours.html#pourquoi-suivre-ce-cours"><i class="fa fa-check"></i>Pourquoi suivre ce cours ?</a></li>
<li class="chapter" data-level="" data-path="à-propos-du-cours.html"><a href="à-propos-du-cours.html#objectifs"><i class="fa fa-check"></i>Objectifs</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="à-propos-du-cours.html"><a href="à-propos-du-cours.html#feuille-de-route"><i class="fa fa-check"></i>Feuille de route</a></li>
<li class="chapter" data-level="" data-path="à-propos-du-cours.html"><a href="à-propos-du-cours.html#crédits"><i class="fa fa-check"></i>Crédits</a></li>
<li class="chapter" data-level="" data-path="à-propos-du-cours.html"><a href="à-propos-du-cours.html#contact"><i class="fa fa-check"></i>Contact</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ressources.html"><a href="ressources.html"><i class="fa fa-check"></i>Ressources</a>
<ul>
<li class="chapter" data-level="" data-path="ressources.html"><a href="ressources.html#travaux-notés"><i class="fa fa-check"></i>Travaux notés</a></li>
<li class="chapter" data-level="" data-path="ressources.html"><a href="ressources.html#données"><i class="fa fa-check"></i>Données</a></li>
<li class="chapter" data-level="" data-path="ressources.html"><a href="ressources.html#ressources-r"><i class="fa fa-check"></i>Ressources R</a></li>
<li class="chapter" data-level="" data-path="ressources.html"><a href="ressources.html#références"><i class="fa fa-check"></i>Références</a></li>
</ul></li>
<li class="part"><span><b>II APPRENTISSAGE</b></span></li>
<li class="chapter" data-level="1" data-path="statistiques-descriptives.html"><a href="statistiques-descriptives.html"><i class="fa fa-check"></i><b>1</b> Statistiques descriptives</a>
<ul>
<li class="chapter" data-level="1.1" data-path="théories.html"><a href="théories.html"><i class="fa fa-check"></i><b>1.1</b> Théories</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="théories.html"><a href="théories.html#paramètre-vs-statistique"><i class="fa fa-check"></i><b>1.1.1</b> Paramètre vs statistique</a></li>
<li class="chapter" data-level="1.1.2" data-path="théories.html"><a href="théories.html#mesures-de-la-tendance-centrale"><i class="fa fa-check"></i><b>1.1.2</b> Mesures de la tendance centrale</a></li>
<li class="chapter" data-level="1.1.3" data-path="théories.html"><a href="théories.html#mesures-de-dispersion"><i class="fa fa-check"></i><b>1.1.3</b> Mesures de dispersion</a>
<ul>
<li class="chapter" data-level="1.1.3.1" data-path="théories.html"><a href="théories.html#somme-des-carrés-des-erreurs"><i class="fa fa-check"></i><b>1.1.3.1</b> Somme des carrés des erreurs</a></li>
<li class="chapter" data-level="1.1.3.2" data-path="théories.html"><a href="théories.html#carré-moyen-variance"><i class="fa fa-check"></i><b>1.1.3.2</b> Carré moyen (variance)</a></li>
<li class="chapter" data-level="1.1.3.3" data-path="théories.html"><a href="théories.html#précision-vs-exactitude"><i class="fa fa-check"></i><b>1.1.3.3</b> Précision vs exactitude</a></li>
<li class="chapter" data-level="1.1.3.4" data-path="théories.html"><a href="théories.html#autres-mesures-de-dispersion"><i class="fa fa-check"></i><b>1.1.3.4</b> Autres mesures de dispersion</a></li>
</ul></li>
<li class="chapter" data-level="1.1.4" data-path="théories.html"><a href="théories.html#variables-aléatoires"><i class="fa fa-check"></i><b>1.1.4</b> Variables aléatoires</a></li>
<li class="chapter" data-level="1.1.5" data-path="théories.html"><a href="théories.html#loi-des-grands-nombres-et-théorème-de-la-limite-centrale"><i class="fa fa-check"></i><b>1.1.5</b> Loi des grands nombres et théorème de la limite centrale</a></li>
<li class="chapter" data-level="1.1.6" data-path="théories.html"><a href="théories.html#distribution-normale"><i class="fa fa-check"></i><b>1.1.6</b> Distribution normale</a>
<ul>
<li class="chapter" data-level="1.1.6.1" data-path="théories.html"><a href="théories.html#caractéristiques-de-la-distribution-normale"><i class="fa fa-check"></i><b>1.1.6.1</b> Caractéristiques de la distribution normale</a></li>
<li class="chapter" data-level="1.1.6.2" data-path="théories.html"><a href="théories.html#distribution-normale-centrée-réduite"><i class="fa fa-check"></i><b>1.1.6.2</b> Distribution normale centrée réduite</a></li>
<li class="chapter" data-level="1.1.6.3" data-path="théories.html"><a href="théories.html#probabilités-cumulatives"><i class="fa fa-check"></i><b>1.1.6.3</b> Probabilités cumulatives</a></li>
<li class="chapter" data-level="1.1.6.4" data-path="théories.html"><a href="théories.html#applications-de-la-statistique-z-à-un-échantillon"><i class="fa fa-check"></i><b>1.1.6.4</b> Applications de la statistique z à un échantillon</a></li>
</ul></li>
<li class="chapter" data-level="1.1.7" data-path="théories.html"><a href="théories.html#conclusion"><i class="fa fa-check"></i><b>1.1.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="statistiques-de-base-avec-r.html"><a href="statistiques-de-base-avec-r.html"><i class="fa fa-check"></i><b>1.2</b> Statistiques de base avec R</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="statistiques-de-base-avec-r.html"><a href="statistiques-de-base-avec-r.html#fonctions-statistiques-de-base"><i class="fa fa-check"></i><b>1.2.1</b> Fonctions statistiques de base</a></li>
<li class="chapter" data-level="1.2.2" data-path="statistiques-de-base-avec-r.html"><a href="statistiques-de-base-avec-r.html#distribution-statistiques"><i class="fa fa-check"></i><b>1.2.2</b> Distribution statistiques</a>
<ul>
<li class="chapter" data-level="1.2.2.1" data-path="statistiques-de-base-avec-r.html"><a href="statistiques-de-base-avec-r.html#probabilité-cumulative"><i class="fa fa-check"></i><b>1.2.2.1</b> Probabilité cumulative</a></li>
<li class="chapter" data-level="1.2.2.2" data-path="statistiques-de-base-avec-r.html"><a href="statistiques-de-base-avec-r.html#fonction-de-quantile"><i class="fa fa-check"></i><b>1.2.2.2</b> Fonction de quantile</a></li>
<li class="chapter" data-level="1.2.2.3" data-path="statistiques-de-base-avec-r.html"><a href="statistiques-de-base-avec-r.html#nombres-aléatoires"><i class="fa fa-check"></i><b>1.2.2.3</b> Nombres aléatoires</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="exercices.html"><a href="exercices.html"><i class="fa fa-check"></i><b>1.3</b> Exercices</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="exercices.html"><a href="exercices.html#question-1"><i class="fa fa-check"></i><b>1.3.1</b> Question 1</a></li>
<li class="chapter" data-level="1.3.2" data-path="exercices.html"><a href="exercices.html#question-2"><i class="fa fa-check"></i><b>1.3.2</b> Question 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intervalles-de-confiance-et-stratégies-déchantillonnage.html"><a href="intervalles-de-confiance-et-stratégies-déchantillonnage.html"><i class="fa fa-check"></i><b>2</b> Intervalles de confiance et stratégies d’échantillonnage</a>
<ul>
<li class="chapter" data-level="2.1" data-path="théories-1.html"><a href="théories-1.html"><i class="fa fa-check"></i><b>2.1</b> Théories</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="théories-1.html"><a href="théories-1.html#problèmes-déchantillonnage"><i class="fa fa-check"></i><b>2.1.1</b> Problèmes d’échantillonnage</a>
<ul>
<li class="chapter" data-level="2.1.1.1" data-path="théories-1.html"><a href="théories-1.html#portion-de-la-population-non-représentée"><i class="fa fa-check"></i><b>2.1.1.1</b> Portion de la population non représentée</a></li>
<li class="chapter" data-level="2.1.1.2" data-path="théories-1.html"><a href="théories-1.html#erreurs-de-mesure-ou-de-saisie-des-données"><i class="fa fa-check"></i><b>2.1.1.2</b> Erreurs de mesure ou de saisie des données</a></li>
<li class="chapter" data-level="2.1.1.3" data-path="théories-1.html"><a href="théories-1.html#erreurs-liées-à-la-probabilité-de-détection"><i class="fa fa-check"></i><b>2.1.1.3</b> Erreurs liées à la probabilité de détection</a></li>
</ul></li>
<li class="chapter" data-level="2.1.2" data-path="théories-1.html"><a href="théories-1.html#échantillonnage-complètement-aléatoire"><i class="fa fa-check"></i><b>2.1.2</b> Échantillonnage complètement aléatoire</a></li>
<li class="chapter" data-level="2.1.3" data-path="théories-1.html"><a href="théories-1.html#intervalle-de-confiance"><i class="fa fa-check"></i><b>2.1.3</b> Intervalle de confiance</a>
<ul>
<li class="chapter" data-level="2.1.3.1" data-path="théories-1.html"><a href="théories-1.html#distribution-du-t-de-student"><i class="fa fa-check"></i><b>2.1.3.1</b> Distribution du <em>t</em> de Student</a></li>
<li class="chapter" data-level="2.1.3.2" data-path="théories-1.html"><a href="théories-1.html#rééchantillonnage"><i class="fa fa-check"></i><b>2.1.3.2</b> Rééchantillonnage</a></li>
</ul></li>
<li class="chapter" data-level="2.1.4" data-path="théories-1.html"><a href="théories-1.html#autres-stratégies-déchantillonnage"><i class="fa fa-check"></i><b>2.1.4</b> Autres stratégies d’échantillonnage</a>
<ul>
<li class="chapter" data-level="2.1.4.1" data-path="théories-1.html"><a href="théories-1.html#échantillonnage-stratifié"><i class="fa fa-check"></i><b>2.1.4.1</b> Échantillonnage stratifié</a></li>
<li class="chapter" data-level="2.1.4.2" data-path="théories-1.html"><a href="théories-1.html#échantillonnage-par-grappes-et-échantillonnage-systématique"><i class="fa fa-check"></i><b>2.1.4.2</b> Échantillonnage par grappes et échantillonnage systématique</a></li>
<li class="chapter" data-level="2.1.4.3" data-path="théories-1.html"><a href="théories-1.html#échantillonnage-multistade"><i class="fa fa-check"></i><b>2.1.4.3</b> Échantillonnage multistade</a></li>
<li class="chapter" data-level="2.1.4.4" data-path="théories-1.html"><a href="théories-1.html#échantillonnage-adaptatif"><i class="fa fa-check"></i><b>2.1.4.4</b> Échantillonnage adaptatif</a></li>
<li class="chapter" data-level="2.1.4.5" data-path="théories-1.html"><a href="théories-1.html#estimation-de-la-probabilité-de-détection"><i class="fa fa-check"></i><b>2.1.4.5</b> Estimation de la probabilité de détection</a></li>
</ul></li>
<li class="chapter" data-level="2.1.5" data-path="théories-1.html"><a href="théories-1.html#conclusion-1"><i class="fa fa-check"></i><b>2.1.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="les-graphiques-avec-r.html"><a href="les-graphiques-avec-r.html"><i class="fa fa-check"></i><b>2.2</b> Les graphiques avec R</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="les-graphiques-avec-r.html"><a href="les-graphiques-avec-r.html#graphiques-de-base"><i class="fa fa-check"></i><b>2.2.1</b> Graphiques de base</a></li>
<li class="chapter" data-level="2.2.2" data-path="les-graphiques-avec-r.html"><a href="les-graphiques-avec-r.html#histogramme"><i class="fa fa-check"></i><b>2.2.2</b> Histogramme</a></li>
<li class="chapter" data-level="2.2.3" data-path="les-graphiques-avec-r.html"><a href="les-graphiques-avec-r.html#diagramme-à-bâtons"><i class="fa fa-check"></i><b>2.2.3</b> Diagramme à bâtons</a></li>
<li class="chapter" data-level="2.2.4" data-path="les-graphiques-avec-r.html"><a href="les-graphiques-avec-r.html#diagramme-de-boîtes-et-moustaches"><i class="fa fa-check"></i><b>2.2.4</b> Diagramme de boîtes et moustaches</a></li>
<li class="chapter" data-level="2.2.5" data-path="les-graphiques-avec-r.html"><a href="les-graphiques-avec-r.html#graphiques-génériques"><i class="fa fa-check"></i><b>2.2.5</b> Graphiques génériques</a></li>
<li class="chapter" data-level="2.2.6" data-path="les-graphiques-avec-r.html"><a href="les-graphiques-avec-r.html#sauvegarder-des-graphiques"><i class="fa fa-check"></i><b>2.2.6</b> Sauvegarder des graphiques</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="exercices-1.html"><a href="exercices-1.html"><i class="fa fa-check"></i><b>2.3</b> Exercices</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="exercices-1.html"><a href="exercices-1.html#question-1-1"><i class="fa fa-check"></i><b>2.3.1</b> Question 1</a></li>
<li class="chapter" data-level="2.3.2" data-path="exercices-1.html"><a href="exercices-1.html#question-2-1"><i class="fa fa-check"></i><b>2.3.2</b> Question 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="tests-dhypothèse-sur-un-seul-groupe.html"><a href="tests-dhypothèse-sur-un-seul-groupe.html"><i class="fa fa-check"></i><b>3</b> Tests d’hypothèse sur un seul groupe</a>
<ul>
<li class="chapter" data-level="3.1" data-path="théories-2.html"><a href="théories-2.html"><i class="fa fa-check"></i><b>3.1</b> Théories</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="théories-2.html"><a href="théories-2.html#hypothèse"><i class="fa fa-check"></i><b>3.1.1</b> Hypothèse</a>
<ul>
<li class="chapter" data-level="3.1.1.1" data-path="théories-2.html"><a href="théories-2.html#hypothèse-scientifique"><i class="fa fa-check"></i><b>3.1.1.1</b> Hypothèse scientifique</a></li>
<li class="chapter" data-level="3.1.1.2" data-path="théories-2.html"><a href="théories-2.html#méthode-scientifique"><i class="fa fa-check"></i><b>3.1.1.2</b> Méthode scientifique</a></li>
<li class="chapter" data-level="3.1.1.3" data-path="théories-2.html"><a href="théories-2.html#inférence-bayésienne"><i class="fa fa-check"></i><b>3.1.1.3</b> Inférence bayésienne</a></li>
<li class="chapter" data-level="3.1.1.4" data-path="théories-2.html"><a href="théories-2.html#méthode-hypothético-déductive"><i class="fa fa-check"></i><b>3.1.1.4</b> Méthode hypothético-déductive</a></li>
</ul></li>
<li class="chapter" data-level="3.1.2" data-path="théories-2.html"><a href="théories-2.html#hypothèse-statistiques"><i class="fa fa-check"></i><b>3.1.2</b> Hypothèse statistiques</a></li>
<li class="chapter" data-level="3.1.3" data-path="théories-2.html"><a href="théories-2.html#erreurs-de-type-i-et-ii"><i class="fa fa-check"></i><b>3.1.3</b> Erreurs de type I et II</a>
<ul>
<li class="chapter" data-level="3.1.3.1" data-path="théories-2.html"><a href="théories-2.html#puissance"><i class="fa fa-check"></i><b>3.1.3.1</b> Puissance</a></li>
<li class="chapter" data-level="3.1.3.2" data-path="théories-2.html"><a href="théories-2.html#relation-entre-les-erreurs-de-type-i-et-ii"><i class="fa fa-check"></i><b>3.1.3.2</b> Relation entre les erreurs de type I et II</a></li>
</ul></li>
<li class="chapter" data-level="3.1.4" data-path="théories-2.html"><a href="théories-2.html#utilisation-de-tests-dhypothèse"><i class="fa fa-check"></i><b>3.1.4</b> Utilisation de tests d’hypothèse</a>
<ul>
<li class="chapter" data-level="3.1.4.1" data-path="théories-2.html"><a href="théories-2.html#conseils-sur-la-présentation-des-résultats-de-tests-dhypothèse"><i class="fa fa-check"></i><b>3.1.4.1</b> Conseils sur la présentation des résultats de tests d’hypothèse</a></li>
</ul></li>
<li class="chapter" data-level="3.1.5" data-path="théories-2.html"><a href="théories-2.html#estimation-de-paramètres"><i class="fa fa-check"></i><b>3.1.5</b> Estimation de paramètres</a></li>
<li class="chapter" data-level="3.1.6" data-path="théories-2.html"><a href="théories-2.html#tests-dhypothèse-sur-la-moyenne-dun-seul-groupe"><i class="fa fa-check"></i><b>3.1.6</b> Tests d’hypothèse sur la moyenne d’un seul groupe</a>
<ul>
<li class="chapter" data-level="3.1.6.1" data-path="théories-2.html"><a href="théories-2.html#test-bilatéral-et-test-unilatéral"><i class="fa fa-check"></i><b>3.1.6.1</b> Test bilatéral et test unilatéral</a></li>
<li class="chapter" data-level="3.1.6.2" data-path="théories-2.html"><a href="théories-2.html#suppositions"><i class="fa fa-check"></i><b>3.1.6.2</b> Suppositions</a></li>
</ul></li>
<li class="chapter" data-level="3.1.7" data-path="théories-2.html"><a href="théories-2.html#conclusion-2"><i class="fa fa-check"></i><b>3.1.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="les-packages-avec-r.html"><a href="les-packages-avec-r.html"><i class="fa fa-check"></i><b>3.2</b> Les packages avec R</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="les-packages-avec-r.html"><a href="les-packages-avec-r.html#activer-un-package"><i class="fa fa-check"></i><b>3.2.1</b> Activer un package</a></li>
<li class="chapter" data-level="3.2.2" data-path="les-packages-avec-r.html"><a href="les-packages-avec-r.html#installer-un-package"><i class="fa fa-check"></i><b>3.2.2</b> Installer un package</a></li>
<li class="chapter" data-level="3.2.3" data-path="les-packages-avec-r.html"><a href="les-packages-avec-r.html#mettre-à-jour-un-package"><i class="fa fa-check"></i><b>3.2.3</b> Mettre à jour un package</a></li>
<li class="chapter" data-level="3.2.4" data-path="les-packages-avec-r.html"><a href="les-packages-avec-r.html#désactiver-un-package"><i class="fa fa-check"></i><b>3.2.4</b> Désactiver un package</a></li>
<li class="chapter" data-level="3.2.5" data-path="les-packages-avec-r.html"><a href="les-packages-avec-r.html#désinstaller-un-package"><i class="fa fa-check"></i><b>3.2.5</b> Désinstaller un package</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="exercices-2.html"><a href="exercices-2.html"><i class="fa fa-check"></i><b>3.3</b> Exercices</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="exercices-2.html"><a href="exercices-2.html#question-1-2"><i class="fa fa-check"></i><b>3.3.1</b> Question 1</a></li>
<li class="chapter" data-level="3.3.2" data-path="exercices-2.html"><a href="exercices-2.html#question-2-2"><i class="fa fa-check"></i><b>3.3.2</b> Question 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="tests-dhypothèse-sur-deux-groupes.html"><a href="tests-dhypothèse-sur-deux-groupes.html"><i class="fa fa-check"></i><b>4</b> Tests d’hypothèse sur deux groupes</a>
<ul>
<li class="chapter" data-level="4.1" data-path="théories-3.html"><a href="théories-3.html"><i class="fa fa-check"></i><b>4.1</b> Théories</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="théories-3.html"><a href="théories-3.html#tests-dhypothèses-sur-la-moyenne-de-deux-groupes-indépendants"><i class="fa fa-check"></i><b>4.1.1</b> Tests d’hypothèses sur la moyenne de deux groupes indépendants</a>
<ul>
<li class="chapter" data-level="4.1.1.1" data-path="théories-3.html"><a href="théories-3.html#suppositions-1"><i class="fa fa-check"></i><b>4.1.1.1</b> Suppositions</a></li>
</ul></li>
<li class="chapter" data-level="4.1.2" data-path="théories-3.html"><a href="théories-3.html#tests-dhypothèse-pour-deux-groupes-appariés"><i class="fa fa-check"></i><b>4.1.2</b> Tests d’hypothèse pour deux groupes appariés</a></li>
<li class="chapter" data-level="4.1.3" data-path="théories-3.html"><a href="théories-3.html#transformations"><i class="fa fa-check"></i><b>4.1.3</b> Transformations</a>
<ul>
<li class="chapter" data-level="4.1.3.1" data-path="théories-3.html"><a href="théories-3.html#transformation-logarithmique"><i class="fa fa-check"></i><b>4.1.3.1</b> Transformation logarithmique</a></li>
<li class="chapter" data-level="4.1.3.2" data-path="théories-3.html"><a href="théories-3.html#transformation-racine-carrée"><i class="fa fa-check"></i><b>4.1.3.2</b> Transformation racine carrée</a></li>
<li class="chapter" data-level="4.1.3.3" data-path="théories-3.html"><a href="théories-3.html#transformation-arcsinus"><i class="fa fa-check"></i><b>4.1.3.3</b> Transformation arcsinus</a></li>
<li class="chapter" data-level="4.1.3.4" data-path="théories-3.html"><a href="théories-3.html#autres-transformations"><i class="fa fa-check"></i><b>4.1.3.4</b> Autres transformations</a></li>
</ul></li>
<li class="chapter" data-level="4.1.4" data-path="théories-3.html"><a href="théories-3.html#conclusion-3"><i class="fa fa-check"></i><b>4.1.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="laboratoire.html"><a href="laboratoire.html"><i class="fa fa-check"></i><b>4.2</b> Laboratoire</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="laboratoire.html"><a href="laboratoire.html#question-1-3"><i class="fa fa-check"></i><b>4.2.1</b> Question 1</a></li>
<li class="chapter" data-level="4.2.2" data-path="laboratoire.html"><a href="laboratoire.html#question-2-3"><i class="fa fa-check"></i><b>4.2.2</b> Question 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="analyse-de-fréquences-et-test-du-khi-carré-chi2.html"><a href="analyse-de-fréquences-et-test-du-khi-carré-chi2.html"><i class="fa fa-check"></i><b>5</b> Analyse de fréquences et test du khi carré (<span class="math inline">\(\chi^2\)</span>)</a>
<ul>
<li class="chapter" data-level="5.1" data-path="théories-4.html"><a href="théories-4.html"><i class="fa fa-check"></i><b>5.1</b> Théories</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="théories-4.html"><a href="théories-4.html#analyse-de-fréquences-le-test-du-khi-carré-chi2"><i class="fa fa-check"></i><b>5.1.1</b> Analyse de fréquences : le test du khi carré (<span class="math inline">\(\chi^2\)</span>)</a>
<ul>
<li class="chapter" data-level="5.1.1.1" data-path="théories-4.html"><a href="théories-4.html#la-distribution-du-khi-carré-chi2"><i class="fa fa-check"></i><b>5.1.1.1</b> La distribution du khi carré (<span class="math inline">\(\chi^2\)</span>)</a></li>
<li class="chapter" data-level="5.1.1.2" data-path="théories-4.html"><a href="théories-4.html#le-test-du-khi-carré-chi2"><i class="fa fa-check"></i><b>5.1.1.2</b> Le test du khi carré (<span class="math inline">\(\chi^2\)</span>)</a></li>
<li class="chapter" data-level="5.1.1.3" data-path="théories-4.html"><a href="théories-4.html#conditions-dutilisation"><i class="fa fa-check"></i><b>5.1.1.3</b> Conditions d’utilisation</a></li>
</ul></li>
<li class="chapter" data-level="5.1.2" data-path="théories-4.html"><a href="théories-4.html#tableau-de-contingence"><i class="fa fa-check"></i><b>5.1.2</b> Tableau de contingence</a>
<ul>
<li class="chapter" data-level="5.1.2.1" data-path="théories-4.html"><a href="théories-4.html#formulation-des-hypothèse-nulles"><i class="fa fa-check"></i><b>5.1.2.1</b> Formulation des hypothèse nulles</a></li>
<li class="chapter" data-level="5.1.2.2" data-path="théories-4.html"><a href="théories-4.html#fréquences-théoriques"><i class="fa fa-check"></i><b>5.1.2.2</b> Fréquences théoriques</a></li>
<li class="chapter" data-level="5.1.2.3" data-path="théories-4.html"><a href="théories-4.html#calcul-du-chi2-dindépendance"><i class="fa fa-check"></i><b>5.1.2.3</b> Calcul du <span class="math inline">\(\chi^2\)</span> d’indépendance</a></li>
</ul></li>
<li class="chapter" data-level="5.1.3" data-path="théories-4.html"><a href="théories-4.html#alternative-au-test-du-chi2"><i class="fa fa-check"></i><b>5.1.3</b> Alternative au test du <span class="math inline">\(\chi^2\)</span></a></li>
<li class="chapter" data-level="5.1.4" data-path="théories-4.html"><a href="théories-4.html#le-paradoxe-de-simpson"><i class="fa fa-check"></i><b>5.1.4</b> Le paradoxe de Simpson</a></li>
<li class="chapter" data-level="5.1.5" data-path="théories-4.html"><a href="théories-4.html#conclusion-4"><i class="fa fa-check"></i><b>5.1.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="exercices-3.html"><a href="exercices-3.html"><i class="fa fa-check"></i><b>5.2</b> Exercices</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="exercices-3.html"><a href="exercices-3.html#question-1-4"><i class="fa fa-check"></i><b>5.2.1</b> Question 1</a></li>
<li class="chapter" data-level="5.2.2" data-path="exercices-3.html"><a href="exercices-3.html#question-2-4"><i class="fa fa-check"></i><b>5.2.2</b> Question 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="analyse-de-variance-à-un-critère.html"><a href="analyse-de-variance-à-un-critère.html"><i class="fa fa-check"></i><b>6</b> Analyse de variance à un critère</a>
<ul>
<li class="chapter" data-level="6.1" data-path="théories-5.html"><a href="théories-5.html"><i class="fa fa-check"></i><b>6.1</b> Théories</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="théories-5.html"><a href="théories-5.html#comparaison-de-plusieurs-groupes"><i class="fa fa-check"></i><b>6.1.1</b> Comparaison de plusieurs groupes</a></li>
<li class="chapter" data-level="6.1.2" data-path="théories-5.html"><a href="théories-5.html#analyse-de-variance-anova"><i class="fa fa-check"></i><b>6.1.2</b> Analyse de variance (ANOVA)</a>
<ul>
<li class="chapter" data-level="6.1.2.1" data-path="théories-5.html"><a href="théories-5.html#décomposition-de-la-variance"><i class="fa fa-check"></i><b>6.1.2.1</b> Décomposition de la variance</a></li>
<li class="chapter" data-level="6.1.2.2" data-path="théories-5.html"><a href="théories-5.html#la-distribution-du-f"><i class="fa fa-check"></i><b>6.1.2.2</b> La distribution du <span class="math inline">\(F\)</span></a></li>
<li class="chapter" data-level="6.1.2.3" data-path="théories-5.html"><a href="théories-5.html#hypothèses-statistiques"><i class="fa fa-check"></i><b>6.1.2.3</b> Hypothèses statistiques</a></li>
<li class="chapter" data-level="6.1.2.4" data-path="théories-5.html"><a href="théories-5.html#suppositions-2"><i class="fa fa-check"></i><b>6.1.2.4</b> Suppositions</a></li>
</ul></li>
<li class="chapter" data-level="6.1.3" data-path="théories-5.html"><a href="théories-5.html#comparaison-multiples"><i class="fa fa-check"></i><b>6.1.3</b> Comparaison multiples</a>
<ul>
<li class="chapter" data-level="6.1.3.1" data-path="théories-5.html"><a href="théories-5.html#erreurs-associées-aux-comparaisons-multiples"><i class="fa fa-check"></i><b>6.1.3.1</b> Erreurs associées aux comparaisons multiples</a></li>
<li class="chapter" data-level="6.1.3.2" data-path="théories-5.html"><a href="théories-5.html#suppositions-3"><i class="fa fa-check"></i><b>6.1.3.2</b> Suppositions</a></li>
<li class="chapter" data-level="6.1.3.3" data-path="théories-5.html"><a href="théories-5.html#structure-générale"><i class="fa fa-check"></i><b>6.1.3.3</b> Structure générale</a></li>
<li class="chapter" data-level="6.1.3.4" data-path="théories-5.html"><a href="théories-5.html#test-de-tukey"><i class="fa fa-check"></i><b>6.1.3.4</b> Test de Tukey</a></li>
<li class="chapter" data-level="6.1.3.5" data-path="théories-5.html"><a href="théories-5.html#présentation-des-résultats"><i class="fa fa-check"></i><b>6.1.3.5</b> Présentation des résultats</a></li>
</ul></li>
<li class="chapter" data-level="6.1.4" data-path="théories-5.html"><a href="théories-5.html#conclusion-5"><i class="fa fa-check"></i><b>6.1.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="les-boucles-avec-r.html"><a href="les-boucles-avec-r.html"><i class="fa fa-check"></i><b>6.2</b> Les boucles avec R</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="les-boucles-avec-r.html"><a href="les-boucles-avec-r.html#les-boucles"><i class="fa fa-check"></i><b>6.2.1</b> Les boucles</a>
<ul>
<li class="chapter" data-level="6.2.1.1" data-path="les-boucles-avec-r.html"><a href="les-boucles-avec-r.html#structure"><i class="fa fa-check"></i><b>6.2.1.1</b> Structure</a></li>
</ul></li>
<li class="chapter" data-level="6.2.2" data-path="les-boucles-avec-r.html"><a href="les-boucles-avec-r.html#alternatives-aux-boucles"><i class="fa fa-check"></i><b>6.2.2</b> Alternatives aux boucles</a>
<ul>
<li class="chapter" data-level="6.2.2.1" data-path="les-boucles-avec-r.html"><a href="les-boucles-avec-r.html#apply-et-fonctions-apparentées"><i class="fa fa-check"></i><b>6.2.2.1</b> <code>apply( )</code> et fonctions apparentées</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="exercices-4.html"><a href="exercices-4.html"><i class="fa fa-check"></i><b>6.3</b> Exercices</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="exercices-4.html"><a href="exercices-4.html#question-1-5"><i class="fa fa-check"></i><b>6.3.1</b> Question 1</a></li>
<li class="chapter" data-level="6.3.2" data-path="exercices-4.html"><a href="exercices-4.html#question-2-5"><i class="fa fa-check"></i><b>6.3.2</b> Question 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="analyse-de-variance-à-deux-critères.html"><a href="analyse-de-variance-à-deux-critères.html"><i class="fa fa-check"></i><b>7</b> Analyse de variance à deux critères</a>
<ul>
<li class="chapter" data-level="7.1" data-path="théories-6.html"><a href="théories-6.html"><i class="fa fa-check"></i><b>7.1</b> Théories</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="théories-6.html"><a href="théories-6.html#anova-à-deux-critères"><i class="fa fa-check"></i><b>7.1.1</b> ANOVA à deux critères</a></li>
<li class="chapter" data-level="7.1.2" data-path="théories-6.html"><a href="théories-6.html#suppositions-et-dispositif-expérimental"><i class="fa fa-check"></i><b>7.1.2</b> Suppositions et dispositif expérimental</a></li>
<li class="chapter" data-level="7.1.3" data-path="théories-6.html"><a href="théories-6.html#hypothèses-statistiques-1"><i class="fa fa-check"></i><b>7.1.3</b> Hypothèses statistiques</a></li>
<li class="chapter" data-level="7.1.4" data-path="théories-6.html"><a href="théories-6.html#sommes-des-carrés-1"><i class="fa fa-check"></i><b>7.1.4</b> Sommes des carrés</a></li>
<li class="chapter" data-level="7.1.5" data-path="théories-6.html"><a href="théories-6.html#effets-additifs"><i class="fa fa-check"></i><b>7.1.5</b> Effets additifs</a></li>
<li class="chapter" data-level="7.1.6" data-path="théories-6.html"><a href="théories-6.html#conclusion-6"><i class="fa fa-check"></i><b>7.1.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="laboratoire-1.html"><a href="laboratoire-1.html"><i class="fa fa-check"></i><b>7.2</b> Laboratoire</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="laboratoire-1.html"><a href="laboratoire-1.html#question-1-6"><i class="fa fa-check"></i><b>7.2.1</b> Question 1</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="blocs-complets-aléatoires.html"><a href="blocs-complets-aléatoires.html"><i class="fa fa-check"></i><b>8</b> Blocs complets aléatoires</a>
<ul>
<li class="chapter" data-level="8.1" data-path="théories-7.html"><a href="théories-7.html"><i class="fa fa-check"></i><b>8.1</b> Théories</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="théories-7.html"><a href="théories-7.html#effets-fixes-et-effets-aléatoires"><i class="fa fa-check"></i><b>8.1.1</b> Effets fixes et effets aléatoires</a>
<ul>
<li class="chapter" data-level="8.1.1.1" data-path="théories-7.html"><a href="théories-7.html#anova-à-un-critère"><i class="fa fa-check"></i><b>8.1.1.1</b> ANOVA à un critère</a></li>
<li class="chapter" data-level="8.1.1.2" data-path="théories-7.html"><a href="théories-7.html#anova-à-deux-critères-1"><i class="fa fa-check"></i><b>8.1.1.2</b> ANOVA à deux critères</a></li>
</ul></li>
<li class="chapter" data-level="8.1.2" data-path="théories-7.html"><a href="théories-7.html#blocs-complets-aléatoires-1"><i class="fa fa-check"></i><b>8.1.2</b> Blocs complets aléatoires</a>
<ul>
<li class="chapter" data-level="8.1.2.1" data-path="théories-7.html"><a href="théories-7.html#révision-de-léchantillonnage"><i class="fa fa-check"></i><b>8.1.2.1</b> Révision de l’échantillonnage</a></li>
<li class="chapter" data-level="8.1.2.2" data-path="théories-7.html"><a href="théories-7.html#origine-du-dispositif-en-blocs-complets-aléatoires"><i class="fa fa-check"></i><b>8.1.2.2</b> Origine du dispositif en blocs complets aléatoires</a></li>
<li class="chapter" data-level="8.1.2.3" data-path="théories-7.html"><a href="théories-7.html#particularité-du-dispositif-en-blocs-complets-aléatoires"><i class="fa fa-check"></i><b>8.1.2.3</b> Particularité du dispositif en blocs complets aléatoires</a></li>
<li class="chapter" data-level="8.1.2.4" data-path="théories-7.html"><a href="théories-7.html#applications-moins-conventionnelles"><i class="fa fa-check"></i><b>8.1.2.4</b> Applications moins conventionnelles</a></li>
<li class="chapter" data-level="8.1.2.5" data-path="théories-7.html"><a href="théories-7.html#conditions-dapplication"><i class="fa fa-check"></i><b>8.1.2.5</b> Conditions d’application</a></li>
<li class="chapter" data-level="8.1.2.6" data-path="théories-7.html"><a href="théories-7.html#avantages-du-dispositif-en-blocs-complets-aléatoires"><i class="fa fa-check"></i><b>8.1.2.6</b> Avantages du dispositif en blocs complets aléatoires</a></li>
<li class="chapter" data-level="8.1.2.7" data-path="théories-7.html"><a href="théories-7.html#désavantages-du-dispositif-en-blocs-complets-aléatoires"><i class="fa fa-check"></i><b>8.1.2.7</b> Désavantages du dispositif en blocs complets aléatoires</a></li>
</ul></li>
<li class="chapter" data-level="8.1.3" data-path="théories-7.html"><a href="théories-7.html#conclusion-7"><i class="fa fa-check"></i><b>8.1.3</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="exercices-5.html"><a href="exercices-5.html"><i class="fa fa-check"></i><b>8.2</b> Exercices</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="exercices-5.html"><a href="exercices-5.html#question-1-7"><i class="fa fa-check"></i><b>8.2.1</b> Question 1</a></li>
<li class="chapter" data-level="8.2.2" data-path="exercices-5.html"><a href="exercices-5.html#question-2-6"><i class="fa fa-check"></i><b>8.2.2</b> Question 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="élaboration-et-optimisation-de-plans-déchantillonnage.html"><a href="élaboration-et-optimisation-de-plans-déchantillonnage.html"><i class="fa fa-check"></i><b>9</b> Élaboration et optimisation de plans d’échantillonnage</a>
<ul>
<li class="chapter" data-level="9.1" data-path="théories-8.html"><a href="théories-8.html"><i class="fa fa-check"></i><b>9.1</b> Théories</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="théories-8.html"><a href="théories-8.html#plans-déchantillonnage"><i class="fa fa-check"></i><b>9.1.1</b> Plans d’échantillonnage</a>
<ul>
<li class="chapter" data-level="9.1.1.1" data-path="théories-8.html"><a href="théories-8.html#expérience-vs-étude-dobservation"><i class="fa fa-check"></i><b>9.1.1.1</b> Expérience vs étude d’observation</a></li>
<li class="chapter" data-level="9.1.1.2" data-path="théories-8.html"><a href="théories-8.html#témoin"><i class="fa fa-check"></i><b>9.1.1.2</b> Témoin</a></li>
<li class="chapter" data-level="9.1.1.3" data-path="théories-8.html"><a href="théories-8.html#placébo"><i class="fa fa-check"></i><b>9.1.1.3</b> Placébo</a></li>
<li class="chapter" data-level="9.1.1.4" data-path="théories-8.html"><a href="théories-8.html#prise-de-données-en-aveugle"><i class="fa fa-check"></i><b>9.1.1.4</b> Prise de données en aveugle</a></li>
<li class="chapter" data-level="9.1.1.5" data-path="théories-8.html"><a href="théories-8.html#répétition-randomisation-et-répartition-spatiale"><i class="fa fa-check"></i><b>9.1.1.5</b> Répétition, randomisation et répartition spatiale</a></li>
</ul></li>
<li class="chapter" data-level="9.1.2" data-path="théories-8.html"><a href="théories-8.html#nos-meilleurs-alliés-dans-lélaboration-dun-plan-déchantillonnage"><i class="fa fa-check"></i><b>9.1.2</b> Nos meilleurs alliés dans l’élaboration d’un plan d’échantillonnage</a></li>
<li class="chapter" data-level="9.1.3" data-path="théories-8.html"><a href="théories-8.html#problèmes-associés-à-certains-plan-déchantillonnage"><i class="fa fa-check"></i><b>9.1.3</b> Problèmes associés à certains plan d’échantillonnage</a>
<ul>
<li class="chapter" data-level="9.1.3.1" data-path="théories-8.html"><a href="théories-8.html#labsence-de-réelles-répétitions-la-pseudoréplication"><i class="fa fa-check"></i><b>9.1.3.1</b> L’absence de réelles répétitions : la pseudoréplication</a></li>
<li class="chapter" data-level="9.1.3.2" data-path="théories-8.html"><a href="théories-8.html#contrôler-la-variabilité-temporelle"><i class="fa fa-check"></i><b>9.1.3.2</b> Contrôler la variabilité temporelle</a></li>
<li class="chapter" data-level="9.1.3.3" data-path="théories-8.html"><a href="théories-8.html#sources-de-confusion"><i class="fa fa-check"></i><b>9.1.3.3</b> Sources de confusion</a></li>
</ul></li>
<li class="chapter" data-level="9.1.4" data-path="théories-8.html"><a href="théories-8.html#conclusion-8"><i class="fa fa-check"></i><b>9.1.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="laboratoire-2.html"><a href="laboratoire-2.html"><i class="fa fa-check"></i><b>9.2</b> Laboratoire</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="laboratoire-2.html"><a href="laboratoire-2.html#instructions"><i class="fa fa-check"></i><b>9.2.1</b> Instructions</a></li>
<li class="chapter" data-level="9.2.2" data-path="laboratoire-2.html"><a href="laboratoire-2.html#suggestions-de-thèmes-à-étudier"><i class="fa fa-check"></i><b>9.2.2</b> Suggestions de thèmes à étudier</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistiques avec R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="théories-1" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Théories<a href="théories-1.html#théories-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="échantillonnage" class="section level6 unnumbered hasAnchor">
<h6>Échantillonnage<a href="théories-1.html#échantillonnage" class="anchor-section" aria-label="Anchor link to header"></a></h6>
<p>Il est peu pratique voire souvent impossible d’étudier la population au complet. On utilise plutôt un échantillon pour faire des inférences sur la population. L’échantillon est constitué d’<em>unités d’échantillonnage</em>. Par unité d’échantillonnage, on entend la plus petite unité indépendante d’une expérience ou d’une étude d’observation sur laquelle on prend une mesure. L’échantillonnage permet de récolter de l’information afin de répondre à des questions du genre :</p>
<ul>
<li>Quel est le nombre d’arbres par hectare affligés par l’agrile du frêne à Gatineau?</li>
<li>Combien y a-t-il de gisements d’or en Abitibi?</li>
<li>Combien d’heures un portable d’une certaine compagnie dure-t-il avant de tomber en panne?</li>
<li>Quelle partie de la population canadienne appuie la plus récente décision du gouvernement?</li>
</ul>
<hr />
<div class="exemple" section="2">
<p>On veut faire un sondage téléphonique pour déterminer le nombre d’heures passées par les téléspectateurs devant leur téléviseur par jour. Un bon nombre de décisions peuvent influencer le résultat — la région, le choix des répondants, la classe d’âge, la classe socio-économique, l’heure de l’appel. Que faire des biais potentiels associés à l’échantillonnage, comme les personnes sans téléphone, les personnes avec un numéro non affiché, les personnes ne voulant pas participer et les personnes possédant un afficheur?</p>
</div>
<hr />
<p>Plusieurs stratégies d’échantillonnage sont disponibles afin d’assembler un échantillon. Le choix de la stratégie d’échantillonnage dépend des caractéristiques de la population et des problèmes potentiels associés aux unités d’échantillonnage. Nous verrons plusieurs stratégies d’échantillonnage classiques dans les prochaines sections.</p>
<p>Peu importe la stratégie d’échantillonnage utilisée, l’échantillon doit être représentatif de la population afin de permettre une bonne estimation des paramètres qui nous intéressent. On fait face à un problème de représentativité si un groupe particulier d’unités d’échantillonnage parmi la population d’intérêt n’apparaît pas dans l’échantillon. Le paramètre estimé à partir d’un échantillon qui n’est pas représentatif de la population risque d’être biaisé.</p>
</div>
<div id="problèmes-déchantillonnage" class="section level3 hasAnchor" number="2.1.1">
<h3><span class="header-section-number">2.1.1</span> Problèmes d’échantillonnage<a href="théories-1.html#problèmes-déchantillonnage" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Lors de l’échantillonnage, on présume souvent que:
- la variable d’intérêt est mesurée sans erreur sur chaque observation, individu ou unité d’échantillonnage;
- les erreurs dans les estimations proviennent uniquement de la nature de l’échantillon (erreur d’échantillonnage).</p>
<p><strong>L’erreur d’échantillonnage</strong> se définit comme étant la variabilité aléatoire d’un échantillon qui est tiré d’une population donnée. Par exemple, disons que l’on inscrive l’âge de chaque élève d’une école secondaire sur des bouts de papier à raison d’une valeur par bout de papier. S’il y a 1000 élèves, nous aurons une valeur d’âge pour chaque bout de papier. Si on sélectionne aléatoirement 50 observations à partir des élèves présents à la cafétéria pendant l’heure du dîner, on obtiendra 50 bouts de papier sur lequel est inscrit l’âge d’un élève. On peut demander à un collègue d’échantillonner 50 observations à partir de la même population lors de la même période de dîner. Ce dernier obtiendra fort probablement un échantillon différent du premier. La variation qui existe entre ces deux échantillons de la même population est communément appelée l’erreur d’échantillonnage – elle reflète uniquement le fait que le processus d’échantillonnage amène une variabilité entre les échantillons. Toutefois, on peut avoir d’autres types d’erreurs plus sournoises qui peuvent biaiser nos estimations.</p>
<div id="portion-de-la-population-non-représentée" class="section level4 hasAnchor" number="2.1.1.1">
<h4><span class="header-section-number">2.1.1.1</span> Portion de la population non représentée<a href="théories-1.html#portion-de-la-population-non-représentée" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>L’impossibilité de sélectionner certains individus parmi la population amène des problèmes par rapport aux interprétations et aux conclusions que l’on peut tirer à propos de la population. Voici quelques exemples de ce problème:
- Certains sites sélectionnés en haute altitude ne peuvent être échantillonnés à cause de la température inclémente.
- Dans une étude sur la croissance des arbres, on ne peut pas mesurer la taille des grands arbres avec une échelle trop courte.
- Lors d’un sondage téléphonique, il est impossible de rejoindre les individus qui n’ont pas de téléphone et ceux qui ne veulent pas répondre au sondage.</p>
<p>Pour résoudre ce problème, on peut:
- utiliser de l’échantillonnage additionnel afin d’obtenir des observations provenant de la portion manquée de la population;
- choisir une nouvelle variable qui permet de mesurer toute la population et qui est fortement corrélée à la variable d’intérêt (p. ex., le diamètre du tronc plutôt que la hauteur pour les arbres);
- redéfinir la population afin de mieux refléter ce qui a été mesuré au lieu de s’intéresser à toute la population, on cible une partie particulière de cette population.</p>
</div>
<div id="erreurs-de-mesure-ou-de-saisie-des-données" class="section level4 hasAnchor" number="2.1.1.2">
<h4><span class="header-section-number">2.1.1.2</span> Erreurs de mesure ou de saisie des données<a href="théories-1.html#erreurs-de-mesure-ou-de-saisie-des-données" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Parfois, des problèmes peuvent se glisser dans la mesure ou dans la saisie des données. Pour éviter ce type de problème, le contrôle de la qualité du travail, tant en ce qui concerne la mesure des données que la saisie et la gestion de celles-ci, s’avère la meilleure solution. Le meilleur moyen pour détecter les erreurs de mesure ou de saisie des données est d’utiliser des méthodes graphiques, lesquelles permettent d’identifier rapidement des valeurs extrêmes, aberrantes ou erronées, c’est-à-dire, des observations qui divergent nettement des autres.</p>
</div>
<div id="erreurs-liées-à-la-probabilité-de-détection" class="section level4 hasAnchor" number="2.1.1.3">
<h4><span class="header-section-number">2.1.1.3</span> Erreurs liées à la probabilité de détection<a href="théories-1.html#erreurs-liées-à-la-probabilité-de-détection" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Certains organismes ou éléments d’intérêt sont difficiles à détecter lors d’un inventaire, malgré les efforts déployés pour standardiser le protocole. Par exemple, il est souvent impossible de détecter tous les éléments liés à un phénomène d’intérêt en raison de sa visibilité (p. ex., symptômes peu apparents pour une maladie), des conditions au moment de l’observation (p. ex., beaucoup de vent lors de l’écoute de chants d’oiseaux), de l’expérience de l’observateur (p. ex., jeune médecin analysant une radiographie), ou des conditions à l’endroit de l’observation (p. ex., couches géologiques empêchant la détection de gisements).</p>
<p>Le même problème se manifeste lorsqu’on étudie des populations humaines, par exemple lorsqu’on désire estimer la population de sans-abris au Canada. Le problème est similaire lorsqu’on s’intéresse à la présence d’un élément d’intérêt dans une série de sites. Ainsi, même si on ne détecte pas l’élément dans un site, cela ne signifie pas pour autant qu’il y est absente.</p>
<p>L’erreur associée à la détection imparfaite ne peut pas être contrôlée en standardisant le protocole. La meilleure méthode pour pallier le problème consiste à estimer explicitement la probabilité de détection avec des méthodes appropriées telles que les modèles de capture-marquage-recapture (CMR), les modèles d’échantillonnage de la distance (<em>distance sampling</em>) et les modèles d’occupation de site (<em>site occupancy analyses</em>).</p>
</div>
</div>
<div id="échantillonnage-complètement-aléatoire" class="section level3 hasAnchor" number="2.1.2">
<h3><span class="header-section-number">2.1.2</span> Échantillonnage complètement aléatoire<a href="théories-1.html#échantillonnage-complètement-aléatoire" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>L’échantillonnage complètement aléatoire</strong> est la stratégie d’échantillonnage la plus simple et celle qui offre le plus de flexibilité à l’étape des analyses. Avec cette approche, chaque unité d’échantillonnage a une chance égale d’être incluse dans l’échantillon et la sélection de chaque unité est le résultat d’un processus aléatoire. La sélection aléatoire peut être réalisée:</p>
<ol style="list-style-type: decimal">
<li>en écrivant les numéros de chaque unité d’échantillonnage sur des bouts de papier, de les mettre dans une urne, de bien mélanger, et de tirer un nombre donné de bouts papier au hasard;</li>
<li>en utilisant une table de nombres aléatoires dans un livre de statistiques;</li>
<li>en utilisant un générateur de nombres aléatoires dans R.</li>
</ol>
<p>Pour générer des nombres aléatoires avec R, on peut utiliser une distribution uniforme (continue). Cette distribution se définit par :</p>
<p><span class="math display">\[
  f(x \vert \text{min}, \text{max}) = \begin{cases}
    \frac{1}{(\text{max} - \text{min})}&amp; \text{si} \: \text{min} \leq x \leq \text{max}, \\
    0&amp; \text{autrement} \:.
  \end{cases}
\]</span></p>
<p>On remarque deux paramètres, soit le minimum de l’intervalle (min) et le maximum de l’intervalle (max). Cette distribution décrit des événements qui ont exactement la même probabilité de se produire pour un intervalle donnée (max <span class="math inline">\(-\)</span> min, Figure <a href="théories-1.html#fig:uniform">2.1</a>).</p>
<div class="figure"><span style="display:block;" id="fig:uniform"></span>
<img src="Cours_Stats_R_files/figure-html/uniform-1.png" alt="Distribution uniforme pour l'intervalle 0 et 10." width="672" />
<p class="caption">
Figure 2.1: Distribution uniforme pour l’intervalle 0 et 10.
</p>
</div>
<hr />
<div class="exemple" section="2">
<p>On veut déterminer la densité de probabilité associée à la valeur 3.46 dans un intervalle de 0 à 10 d’une distribution uniforme.</p>
<p><span class="math display">\[
f(3.46 \vert 0, 10) = \frac{1}{(\text{max} - \text{min})} = \frac{1}{(10 - 0)} = 0.1
\]</span></p>
<p>On peut aussi déterminer la densité associée aux valeurs 8, 6.15, ou 10 dans la même distribution:</p>
<p><span class="math display">\[
f(8 \vert 0, 10) = \frac{1}{(\text{max} - \text{min})} = \frac{1}{(10 - 0)} = 0.1 \\
f(6.15 \vert 0, 10) = \frac{1}{(\text{max} - \text{min})} = \frac{1}{(10 - 0)} = 0.1 \\
f(10 \vert 0, 10) = \frac{1}{(\text{max} - \text{min})} = \frac{1}{(10 - 0)} = 0.1
\]</span></p>
<p>On remarque que, peu importe la valeur, la densité de probabilité est de 0.1 tant et aussi longtemps que la valeur est dans l’intervalle 0 et 10. Ainsi, dès que les valeurs sont à l’extérieur de l’intervalle, la densité est de 0:</p>
<p><span class="math display">\[
f(100.2 \vert 0, 10) = 0 \\
f(-1.4 \vert 0, 10) = 0 \\
f(10.1 \vert 0, 10) = 0
\]</span></p>
</div>
<hr />
<p>Puisqu’elle assigne à tous les éléments une probabilité égale d’être sélectionnés, la distribution uniforme est souvent utilisée pour exécuter des sélections aléatoires. Si nous avons une population de 400 éléments (par exemple des arbres), et que nous voulons choisir un échantillon de 40 unités, nous pourrions procéder en assignant un numéro à chaque élément et en utilisant la distribution uniforme pour sélectionner aléatoirement les observations:</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="théories-1.html#cb49-1" tabindex="-1"></a><span class="do">##on &quot;numérote&quot; 400 éléments</span></span>
<span id="cb49-2"><a href="théories-1.html#cb49-2" tabindex="-1"></a>population <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">400</span></span>
<span id="cb49-3"><a href="théories-1.html#cb49-3" tabindex="-1"></a></span>
<span id="cb49-4"><a href="théories-1.html#cb49-4" tabindex="-1"></a><span class="do">##on utilise la distribution uniforme</span></span>
<span id="cb49-5"><a href="théories-1.html#cb49-5" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">runif</span>(<span class="at">n =</span> <span class="dv">60</span>, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> <span class="dv">400</span>), <span class="at">digits =</span> <span class="dv">0</span>)</span></code></pre></div>
<pre><code>##  [1] 222 306  49 391 338 285 365 391 357   9 207 163  35 131 239 290  13 190 177 103 385 267
## [23]   9  15 120 329 140 226 105 246 387  23 284 118 138 221  37 231 114 121  27  42 299 236
## [45] 205  81 170 301 336 367 332 247 359 313 107 283 299 132  85 235</code></pre>
<p>On note ici que nous avons demandé 60 valeurs aléatoires d’une distribution uniforme continue alors que nous en voulons 40, au cas où il y aurait des doublons dans les 40 premières valeurs. De plus, l’utilisation de la fonction <code>round( )</code> permet d’arrondir les valeurs à l’entier le plus près.</p>
<p>Encore plus simple, nous pourrions utiliser la fonction <code>sample( )</code> qui permet de sélectionner aléatoirement avec ou sans remise. La sélection sans remise consiste à retirer les observations qui ont déja été tirées afin de ne pouvoir les sélectionner à nouveau. La sélection avec remise implique de pouvoir sélectionner la même observation à plusieurs reprises pour constituer l’échantillon. Autrement dit, la même observation peut apparaître plusieurs fois dans l’échantillon.</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="théories-1.html#cb51-1" tabindex="-1"></a><span class="do">##on crée une série de 10 observations</span></span>
<span id="cb51-2"><a href="théories-1.html#cb51-2" tabindex="-1"></a>serie10 <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span></span>
<span id="cb51-3"><a href="théories-1.html#cb51-3" tabindex="-1"></a>serie10</span></code></pre></div>
<pre><code>##  [1]  1  2  3  4  5  6  7  8  9 10</code></pre>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="théories-1.html#cb53-1" tabindex="-1"></a><span class="do">##on sélectionne aléatoirement sans remise</span></span>
<span id="cb53-2"><a href="théories-1.html#cb53-2" tabindex="-1"></a><span class="fu">sample</span>(<span class="at">x =</span> serie10, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">replace =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>##  [1]  6  5  2  4 10  7  8  1  3  9</code></pre>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="théories-1.html#cb55-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="at">seed =</span> <span class="dv">3</span>)</span>
<span id="cb55-2"><a href="théories-1.html#cb55-2" tabindex="-1"></a><span class="do">##on sélectionne aléatoirement avec remise</span></span>
<span id="cb55-3"><a href="théories-1.html#cb55-3" tabindex="-1"></a><span class="fu">sample</span>(<span class="at">x =</span> serie10, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>##  [1]  5 10  7  4 10  8  8  4 10  7</code></pre>
<p>En observant le code attentivement, on remarque que la sélection avec remise (<code>replace = TRUE</code>) peut donner plusieurs fois la même valeur. Typiquement, pour sélectionner des observations et construire notre échantillon, nous utiliserons la sélection sans remise.</p>
<p>À noter qu’on peut également utiliser la <strong>randomisation</strong> afin d’attribuer des <strong>traitements</strong> particuliers à certaines unités ou encore randomiser la séquence des observations à effectuer <a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>. Par randomisation, on entend l’application d’un processus aléatoire sur l’attribution d’une condition aux unités d’échantillonnage. Par exemple, dans une expérience étudiant l’effet d’un nouveau médicament sur des patients, on pourrait sélectionner aléatoirement 50 patients afin de constituer deux groupes: un groupe de patients qui prendront le médicament et un autre groupe de patients qui ne le prendront pas. Ici, on pourrait randomiser le traitement, c’est-à-dire, déterminer aléatoirement le traitement que recevra chaque patient.</p>
<p>En contrepartie, la sélection avec remise est plutôt utilisée dans le contexte du , qui est une approche permettant d’obtenir des erreurs-types d’une statistique d’intérêt ou de construire des intervalles de confiance.</p>
</div>
<div id="intervalle-de-confiance" class="section level3 hasAnchor" number="2.1.3">
<h3><span class="header-section-number">2.1.3</span> Intervalle de confiance<a href="théories-1.html#intervalle-de-confiance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Le concept d’<strong>intervalle de confiance</strong> est une des notions les moins bien comprises dans les cours de statistiques. Proprement dit, c’est l’intervalle à l’intérieur duquel se trouvera le paramètre de la population (p. ex., <span class="math inline">\(\mu\)</span>) si l’on répète l’échantillonnage avec la même taille d’échantillon un grand nombre de fois. Avant de construire un intervalle de confiance, il faut choisir une probabilité d’erreur ou seuil (<span class="math inline">\(\alpha\)</span>). Par convention, <span class="math inline">\(\alpha\)</span> prend la valeur 0.01, 0.05 ou 0.1. Le niveau de confiance (coefficient de confiance) est <span class="math inline">\(1 - \alpha\)</span>. Par conséquent, si on utilise un <span class="math inline">\(\alpha = 0.05\)</span>, le niveau de confiance est 1 - 0.05 = 0.95 = 95 %. L’intervalle est un intervalle de confiance à 100(1 - <span class="math inline">\(\alpha\)</span>)% = 95 %.</p>
<p>À partir du théorème de la limite centrale vu à la leçon précédente <em>Statistiques descriptives</em>, on sait que la distribution des moyennes des échantillons approxime une distribution normale. Nous connaissons aussi certaines propriétées de la distribution normale centrée réduite, notamment, que 95 % des observations se trouvent à 1.96 <span class="math inline">\(\sigma\)</span> de la moyenne. Ainsi, on peut construire un intervalle de confiance autour de <span class="math inline">\(\mu\)</span>:</p>
<p><span class="math display">\[
\text{Si} \: n \ge 50, \\
\bar{x} \pm z_{\alpha/2} \cdot SE
\]</span>
où la première ligne signifie que cet intervalle est seulement valide pour des échantillons d’au moins 50 observations (voir l’explication plus bas). Dans la deuxième ligne, <span class="math inline">\(SE\)</span> correspond à l’erreur-type de la moyenne et <span class="math inline">\(z_{\alpha/2}\)</span> correspond à l’écart normal qui définit les deux bornes (négative et positive) d’un intervalle qui exclue une proportion <span class="math inline">\({\alpha/2}\)</span> des valeurs à gauche et une proportion <span class="math inline">\({\alpha/2}\)</span> des valeurs à droite de la distribution normale centrée réduite, c’est-à-dire qu’inversement, cet intervalle inclue <span class="math inline">\({100(1 - \alpha) \%}\)</span> des valeurs de cette distribution. Nous divisons donc par 2 le seuil d’erreur <span class="math inline">\({\alpha}\)</span> puisque l’intervalle de confiance a une borne à gauche et une autre à droite.
Donc, si <span class="math inline">\(\alpha = 0.05\)</span>, on a <span class="math inline">\(z_{\alpha/2} = z_{0.025} = 1.96\)</span>, et il y a 2.5 % de chance d’avoir une valeur à gauche de la borne <span class="math inline">\(1.96 \cdot SE\)</span> (aire sous la courbe de 0.025) et 2.5 % de chance d’avoir une valeur à droite de la borne <span class="math inline">\(1.96 \cdot SE\)</span> (aire sous la courbe de 0.025). Nous pouvons écrire:</p>
<p><span class="math display">\[
IC \: \text{à} \: 95\:\%: \\
P(\bar{x} - 1.96 \cdot SE \leq \mu \leq \bar{x} + 1.96 \cdot SE) = 0.95 \\
IC \: \text{à} \: 90\:\%: \\
P(\bar{x} - 1.64 \cdot SE \leq \mu \leq \bar{x} + 1.64 \cdot SE) = 0.90
\]</span>
On peut transposer les notions de la distribution normale dans R. La fonction <code>dnorm( )</code> correspond à la fonction de densité de probabilité de la distribution normale pour une moyenne et un écart-type donnés. Ainsi, pour obtenir la densité de probabilité associée à <span class="math inline">\(X = 3.5\)</span> dans une distribution normale avec une moyenne (<span class="math inline">\(\mu\)</span>) de 4.2 et un écart-type (<span class="math inline">\(\sigma\)</span>) de 10, nous procédons ainsi:</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="théories-1.html#cb57-1" tabindex="-1"></a><span class="fu">dnorm</span>(<span class="at">x =</span> <span class="fl">3.5</span>, <span class="at">mean =</span> <span class="fl">4.2</span>, <span class="at">sd =</span> <span class="dv">10</span>)</span></code></pre></div>
<pre><code>## [1] 0.03979661</code></pre>
<p>La fonction <code>qnorm( )</code> permet de trouver le quantile associé à une probabilité cumulative d’une distribution normale donnée pour un <span class="math inline">\(\mu\)</span> et <span class="math inline">\(\sigma\)</span> donnés. Pour déterminer l’écart-normal <span class="math inline">\(z_{0.05}\)</span>, on peut faire:</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="théories-1.html#cb59-1" tabindex="-1"></a><span class="do">##z pour 0.05</span></span>
<span id="cb59-2"><a href="théories-1.html#cb59-2" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="at">p =</span> <span class="fl">0.05</span>, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## [1] -1.644854</code></pre>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="théories-1.html#cb61-1" tabindex="-1"></a><span class="do">##la distribution est symétrique et on </span></span>
<span id="cb61-2"><a href="théories-1.html#cb61-2" tabindex="-1"></a><span class="do">##peut obtenir le quantile du côté droit</span></span>
<span id="cb61-3"><a href="théories-1.html#cb61-3" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="at">p =</span> <span class="fl">0.95</span>, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## [1] 1.644854</code></pre>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="théories-1.html#cb63-1" tabindex="-1"></a><span class="do">##z pour 0.025</span></span>
<span id="cb63-2"><a href="théories-1.html#cb63-2" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="at">p =</span> <span class="fl">0.025</span>, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## [1] -1.959964</code></pre>
<p>La probabilité cumulative <span class="math inline">\(P(X &lt; x)\)</span> associée à un quantile, <span class="math inline">\(\mu\)</span> et <span class="math inline">\(\sigma\)</span> s’obtient avec <code>pnorm( )</code>:</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="théories-1.html#cb65-1" tabindex="-1"></a><span class="do">##probabilité cumulative pour z = 0.025</span></span>
<span id="cb65-2"><a href="théories-1.html#cb65-2" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="at">q =</span> <span class="sc">-</span><span class="fl">1.96</span>, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## [1] 0.0249979</code></pre>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="théories-1.html#cb67-1" tabindex="-1"></a><span class="do">##probabilité cumulative pour z = 0.05</span></span>
<span id="cb67-2"><a href="théories-1.html#cb67-2" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="at">q =</span> <span class="sc">-</span><span class="fl">1.64</span>, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## [1] 0.05050258</code></pre>
<p>On connaît rarement la <span class="math inline">\(SE\)</span> réelle de la population (<span class="math inline">\(\sigma_{\bar{x}}\)</span>) et on doit l’estimer à partir de l’échantillon. L’estimation de ce paramètre est bonne lorsque <span class="math inline">\(n &gt; 50\)</span>. Toutefois, l’estimation de la <span class="math inline">\(SE\)</span> est moins bonne pour des échantillons avec moins de 50 observations. En réalité, avec de petits échantillons, l’intervalle de confiance basé sur le <span class="math inline">\(z\)</span> est trop étroit – il indique une précision plus grande qu’elle ne l’est en réalité. On doit donc corriger notre intervalle de confiance en utilisant la distribution du <span class="math inline">\(t\)</span> de Student.</p>
<div id="distribution-du-t-de-student" class="section level4 hasAnchor" number="2.1.3.1">
<h4><span class="header-section-number">2.1.3.1</span> Distribution du <em>t</em> de Student<a href="théories-1.html#distribution-du-t-de-student" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>La <strong>distribution du <span class="math inline">\(t\)</span> de Student</strong> vient du statisticien et maître brasseur de Guinness, William Sealy Gosset. Au début du siècle dernier, la brasserie Guiness a investi beaucoup de ressources afin de sélectionner les variétés de houblon et d’orge qui possédaient les meilleures caractéristiques. Pour ce faire, ils embauchèrent des chimistes et des statisticiens pour arriver à leurs fins en leur donnant le statut de brasseurs et en mettant à leur disposition des laboratoires et des champs pour effectuer des expériences. Étant lié à Guinness et pour ne pas divulguer des secrets de production, Gosset publia sa découverte de la distribution sous le nom de <em>Student</em>. Cette distribution ne possède qu’un paramètre, soit les degrés de liberté (<span class="math inline">\(n - 1\)</span>).</p>
<p>Avec R, nous pouvons déterminer la densité de probabilité, le quantile et la probabilité cumulative pour un degré de liberté donné avec les fonctions <code>dt( )</code>, <code>qt( )</code> et <code>pt( )</code>, respectivement. Bien que de forme très semblable à la distribution normale, la distribution du <span class="math inline">\(t\)</span> de Student a un plus grand nombre d’observations dans les extrémités que la distribution normale (Figure <a href="théories-1.html#fig:t">2.2</a>. Pour un <span class="math inline">\(n\)</span> et une probabilité cumulative donnés, les quantiles de la distribution du <span class="math inline">\(t\)</span> de Student sont plus grands que celui de la distribution normale centrée-réduite (Figure @ref{fig:qt}). Par conséquent, l’intervalle de confiance obtenu avec le <span class="math inline">\(t\)</span> est plus large qu’avec <span class="math inline">\(z\)</span> lorsque <span class="math inline">\(n &lt; 50\)</span>.</p>
<div class="figure"><span style="display:block;" id="fig:t"></span>
<img src="Cours_Stats_R_files/figure-html/t-1.png" alt="Comparaison de la distribution normale centrée réduite et de la distribution du $t$ de Student. On note qu'il y a un plus grand nombre de valeurs dans les extrémités de la distribution du $t$ que dans la distribution normale centrée réduite dès que $n &lt; 50$." width="672" />
<p class="caption">
Figure 2.2: Comparaison de la distribution normale centrée réduite et de la distribution du <span class="math inline">\(t\)</span> de Student. On note qu’il y a un plus grand nombre de valeurs dans les extrémités de la distribution du <span class="math inline">\(t\)</span> que dans la distribution normale centrée réduite dès que <span class="math inline">\(n &lt; 50\)</span>.
</p>
</div>
<div class="figure"><span style="display:block;" id="fig:qt"></span>
<img src="Cours_Stats_R_files/figure-html/qt-1.png" alt="Valeurs des quantiles de la distribution du $t$ de Student en fonction de la taille d'échantillon ($df = n - 1$) pour une probabilité cumulative de 0.95. La ligne horizontale pointillée correspond à l'écart-normal de la distribution normale centrée réduite pour la même probabilité cumulative." width="672" />
<p class="caption">
Figure 2.3: Valeurs des quantiles de la distribution du <span class="math inline">\(t\)</span> de Student en fonction de la taille d’échantillon (<span class="math inline">\(df = n - 1\)</span>) pour une probabilité cumulative de 0.95. La ligne horizontale pointillée correspond à l’écart-normal de la distribution normale centrée réduite pour la même probabilité cumulative.
</p>
</div>
<p>De façon plus générale, on peut construire un intervalle à (<span class="math inline">\(1 - \alpha\)</span>):</p>
<p><span class="math display">\[
P(\bar{x} - t_{\alpha/2, (n - 1)} \cdot SE \leq \mu \leq \bar{x} + t_{\alpha/2, (n - 1)} \cdot SE) = (1 - \alpha)
\]</span>
Pour un intervalle de confiance à 95 <span class="math inline">\(\%\)</span>, <span class="math inline">\((1 - \alpha) = 0.95\)</span>,</p>
<p><span class="math display">\[
P(\bar{x} - t_{0.05/2, (n - 1)} \cdot SE \leq \mu \leq \bar{x} + t_{0.05/2, (n - 1)} \cdot SE) = (1 - \alpha)
\]</span></p>
<hr />
<div class="exemple" section="2">
<p>Une inspectrice municipale mesure l’épaisseur de l’asphalte à 32 endroits où une compagnie privée a fait la chaussée dans Montréal. L’épaisseur moyenne de l’asphalte est de 20.1 cm et l’écart-type estimé à partir de l’échantillon est de 3.39 cm. Quel est l’intervalle de confiance à 95 % autour de la moyenne? On peut obtenir les quantiles nécessaires à la solution du problème comme suit:</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="théories-1.html#cb69-1" tabindex="-1"></a><span class="do">##détermination du quantile du t à alpha/2</span></span>
<span id="cb69-2"><a href="théories-1.html#cb69-2" tabindex="-1"></a>t.stat <span class="ot">&lt;-</span> <span class="fu">qt</span>(<span class="at">p =</span> <span class="fl">0.025</span>, <span class="at">df =</span> <span class="dv">31</span>)</span>
<span id="cb69-3"><a href="théories-1.html#cb69-3" tabindex="-1"></a>t.stat</span></code></pre></div>
<pre><code>## [1] -2.039513</code></pre>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="théories-1.html#cb71-1" tabindex="-1"></a><span class="do">##convertir le quantile en valeur positive </span></span>
<span id="cb71-2"><a href="théories-1.html#cb71-2" tabindex="-1"></a><span class="do">##pour procéder au calcul des bornes</span></span>
<span id="cb71-3"><a href="théories-1.html#cb71-3" tabindex="-1"></a>t.stat <span class="ot">&lt;-</span> t.stat <span class="sc">*</span>(<span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb71-4"><a href="théories-1.html#cb71-4" tabindex="-1"></a>t.stat</span></code></pre></div>
<pre><code>## [1] 2.039513</code></pre>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="théories-1.html#cb73-1" tabindex="-1"></a><span class="do">##calcul de la SE</span></span>
<span id="cb73-2"><a href="théories-1.html#cb73-2" tabindex="-1"></a>SE <span class="ot">&lt;-</span> <span class="fl">3.39</span><span class="sc">/</span><span class="fu">sqrt</span>(<span class="dv">32</span>)</span>
<span id="cb73-3"><a href="théories-1.html#cb73-3" tabindex="-1"></a>SE</span></code></pre></div>
<pre><code>## [1] 0.599273</code></pre>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="théories-1.html#cb75-1" tabindex="-1"></a><span class="do">##calcul de la borne inférieure</span></span>
<span id="cb75-2"><a href="théories-1.html#cb75-2" tabindex="-1"></a><span class="fl">20.1</span> <span class="sc">-</span> t.stat <span class="sc">*</span> SE</span></code></pre></div>
<pre><code>## [1] 18.87777</code></pre>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="théories-1.html#cb77-1" tabindex="-1"></a><span class="do">##calcul de la borne supérieure</span></span>
<span id="cb77-2"><a href="théories-1.html#cb77-2" tabindex="-1"></a><span class="fl">20.1</span> <span class="sc">+</span> t.stat <span class="sc">*</span> SE</span></code></pre></div>
<pre><code>## [1] 21.32223</code></pre>
<p>Nous pouvons donc écrire:</p>
<p><span class="math display">\[
\bar{x} = 20.1 \: \text{cm} \\
s = 3.39 \: \text{cm} \\
n = 32 \\
SE = s_{\bar{x}} = \frac{3.39}{\sqrt{32}} = 0.60 \: \text{cm} \\
    \\
IC \: \text{à} \: 95\:\%: \\
P(\bar{x} - t_{0.05/2, (n - 1)} \cdot SE \leq \mu \leq \bar{x} + t_{0.05/2, (n - 1)} \cdot SE) = 0.95\\
P(\bar{x} - t_{0.025, (32 - 1)} \cdot 0.60 \leq \mu \leq \bar{x} + t_{0.025, (32 - 1)} \cdot 0.60) = 0.95\\
P(18.88 \leq \mu \leq 21.32) = 0.95\\
IC \: \text{à} \: 95\%: (18.88, 21.32) \: .
\]</span>
On peut comparer les intervalles de confiance à 90 % et 99 % à partir du même échantillon:</p>
<p><span class="math display">\[
IC \: \text{à} \: 90\%: \\
P(\bar{x} - t_{0.10/2, (32 - 1)} \cdot SE \leq \mu \leq \bar{x} + t_{0.10/2, (32 - 1)} \cdot SE) = 0.90\\
IC \: \text{à} \: 99\%: \\
P(\bar{x} - t_{0.01/2, (32 - 1)} \cdot SE \leq \mu \leq \bar{x} + t_{0.01/2, (32 - 1)} \cdot SE) = 0.99\\
IC \: \text{à} \: 90\%: (19.08, 21.12) \\
IC \: \text{à} \: 95\%: (18.88, 21.32) \\
IC \: \text{à} \: 99\%: (18.45, 21.75) \: .
\]</span></p>
</div>
<hr />
<p>On remarque rapidement que la largeur de l’intervalle de confiance augmente avec le seuil de confiance. Dans notre exemple, il est le plus étroit à 90 % et le plus large à 99 %. Comme nous l’avons mentionné plus haut, la moyenne de population (<span class="math inline">\(\mu\)</span>) sera incluse dans l’intervalle de confiance (<span class="math inline">\(1 - \alpha\)</span>)% du temps lorsqu’on répète l’expérience un grand nombre de fois. L’intervalle de confiance implique le concept de rééchantillonnage (<em>resampling</em>), c’est-à-dire, la construction de plusieurs échantillons à partir de la même population, et c’est ce que nous verrons dans la prochaine section.</p>
</div>
<div id="rééchantillonnage" class="section level4 hasAnchor" number="2.1.3.2">
<h4><span class="header-section-number">2.1.3.2</span> Rééchantillonnage<a href="théories-1.html#rééchantillonnage" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Les statistiques classiques impliquent souvent un échantillonnage répété dans leur interprétation. Tout comme l’intervalle de confiance, la probabilité d’un test statistique représente ce que l’on devrait observer en moyenne lorsqu’il n’y a pas d’effet dans la population. Ici, “en moyenne” indique ce qu’on obtiendrait si on répétait l’expérience un grand nombre de fois avec une série d’échantillons de taille égale à celle de notre échantillon original, tous provenant de la même population. L’exemple suivant illustre ce principe à l’aide d’une population de 200 000 semis dans une plantation.</p>
<hr />
<div class="exemple" section="2">
<p>Imaginons qu’une compagnie d’exploitation forestière coupe la forêt sur un site de 20 hectares (ha). La compagnie a replanté le site à raison d’un semis d’épinette noire par m<span class="math inline">\(^2\)</span>, ce qui équivaut à un total de 200 000 semis. Deux ans après avoir planté les semis, on veut connaître la croissance moyenne des semis sur le site. Le total de 200 000 semis du site de 20 ha constitue la population d’intérêt.</p>
<p>Chacun des semis de la population croît à sa propre vitesse (Figure <a href="théories-1.html#fig:semis">2.4</a>a), mais on ne peut connaître sa croissance sans la mesurer. On embauche un technicien pour sélectionner aléatoirement 25 semis à mesurer afin d’estimer la hauteur moyenne des semis dans cette même population (Figure <a href="théories-1.html#fig:semis">2.4</a>b).</p>
<div class="figure"><span style="display:block;" id="fig:semis"></span>
<img src="Cours_Stats_R_files/figure-html/semis-1.png" alt="Distribution de la population complète de semis dans une plantation où $\mu = 74.99$ et $\sigma = 14.99$ (a) et d'un échantillon aléatoire de 25 observations tiré de cette population (b)." width="672" />
<p class="caption">
Figure 2.4: Distribution de la population complète de semis dans une plantation où <span class="math inline">\(\mu = 74.99\)</span> et <span class="math inline">\(\sigma = 14.99\)</span> (a) et d’un échantillon aléatoire de 25 observations tiré de cette population (b).
</p>
</div>
<p>On peut calculer l’intervalle de confiance à 95 % à partir de notre échantillon, ce qui donne:
<span class="math display">\[
\bar{x} = 78.45 \: \text{cm} \\
s = 14.4 \: \text{cm} \\
n = 25 \\
SE = \frac{14.44}{\sqrt{25}} =  2.88 \: \text{cm} \\
  \\
IC \: \text{à} \: 95\:\%: \\
P(\bar{x} - t_{0.05/2, (25 - 1)} \cdot SE \leq \mu \leq \bar{x} + t_{0.05/2, (25 - 1)} \cdot SE) = 0.95\\
P(78.45 - 2.06 \cdot 2.88 \leq \mu \leq 78.45 + 2.06 \cdot 2.88 = 0.95\\
IC \: \text{à} \: 95\%: (72.5, 84.39)
\]</span>
L’intervalle de confiance obtenu à partir de l’échantillon de 25 observations est <span class="math inline">\((72.5, 84.39)\)</span>. À noter que <code>qt( )</code> permet d’obtenir le quantile du <span class="math inline">\(t\)</span> associé à la probabilité cumulative correspondant à <span class="math inline">\(\alpha/2\)</span>. On constate que la vraie moyenne de la population (<span class="math inline">\(\mu = 74.99\)</span>) est contenue dans l’intervalle que l’on a construit. En d’autres mots, l’intervalle de confiance inclut ou n’inclut pas la vraie moyenne.</p>
<p>On pourrait demander à 19 autres techniciens de sélectionner aléatoirement 25 semis, de les mesurer, puis de construire un intervalle de confiance à 95 % à partir de leur échantillon. On devrait s’attendre à ce que 19 des 20 intervalles de confiance (<span class="math inline">\(19/20 = 0.95\)</span>) ainsi construits incluent réellement la moyenne de la population (<span class="math inline">\(\mu\)</span>).</p>
</div>
<hr />
<p>On peut aussi utiliser le concept de rééchantillonnage pour illustrer l’erreur-type de la moyenne. Dans la leçon 1, nous avons indiqué que la moyenne d’un échantillon provenait d’une distribution de moyennes d’échantillons. On pourrait demander à 1000 techniciens d’obtenir un échantillon aléatoire de 25 semis et de mesurer la hauteur de chaque arbre. Si chaque technicien calcule la moyenne de son échantillon, nous obtiendrons une distribution de moyennes d’échantillons (Figure <a href="théories-1.html#fig:SE">2.5</a>. Rappelons-nous que l’erreur-type de la moyenne est une estimation de la variation entre les moyennes d’échantillons de même taille provenant de la même population. L’écart-type calculé à partir des valeurs des moyennes nous donnera l’erreur-type de la moyenne.</p>
<div class="figure"><span style="display:block;" id="fig:SE"></span>
<img src="Cours_Stats_R_files/figure-html/SE-1.png" alt="Distribution des 1000 moyennes d'échantillons de 25 semis tirés de la population de 200 000 semis." width="672" />
<p class="caption">
Figure 2.5: Distribution des 1000 moyennes d’échantillons de 25 semis tirés de la population de 200 000 semis.
</p>
</div>
</div>
</div>
<div id="autres-stratégies-déchantillonnage" class="section level3 hasAnchor" number="2.1.4">
<h3><span class="header-section-number">2.1.4</span> Autres stratégies d’échantillonnage<a href="théories-1.html#autres-stratégies-déchantillonnage" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="échantillonnage-stratifié" class="section level4 hasAnchor" number="2.1.4.1">
<h4><span class="header-section-number">2.1.4.1</span> Échantillonnage stratifié<a href="théories-1.html#échantillonnage-stratifié" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>En plus de l’échantillonnage complètement aléatoire, d’autres approches permettent également de construire un échantillon à partir d’une population. L’<strong>échantillonnage stratifié</strong> s’applique lorsque la population d’intérêt est divisée en régions ou <strong>strates</strong>. On entend par “strate” une tranche ou une partie de la population. Par exemple, si on s’intéresse à la masse des ours noirs dans l’est du Québec, on pourrait échantillonner des ours dans différents types d’habitats de cette région: urbain, aire de conservation, aire de coupe forestière. Si la masse des ours est sujette à différer d’un type d’habitat à l’autre, il serait inapproprié de procéder à un échantillonnage complètement aléatoire. Effectivement, certains types d’habitats risqueraient d’être sous-représentés et on supposerait erronément que le type d’habitat n’est pas une source de variation de la masse d’ours noir.</p>
<p>L’échantillonnage stratifié consiste à partitionner la population afin que les unités à l’intérieur d’une même strate soient le plus similaires possible. Même si les strates diffèrent les unes des autres, l’échantillon stratifié sera représentatif de la population. On peut stratifier une région par une variable connue (habitat, élévation, type de sol) ou par sous-unité géographique. On peut également stratifier l’échantillonnage par espèce, sexe ou classe d’âge. La sélection des unités d’échantillonnage dans chacune des strates doit être indépendante de la sélection dans les autres strates. L’échantillonnage aléatoire est encore important ici. Lorsque chaque unité est sélectionnée aléatoirement à l’intérieur de chaque strate, on parle d’échantillonnage stratifié aléatoire. L’estimation de la moyenne sera la plus précise si les unités sont le plus semblables possible à l’intérieur de chaque strate.</p>
<p>L’échantillonnage coûte cher en ressources (temps, argent, personnel). C’est pourquoi il est préférable de penser à la stratégie d’échantillonnage avant de débuter la collecte des données. Considérez la notation suivante:</p>
<ul>
<li><span class="math inline">\(L\)</span>: nombre de strates;</li>
<li><span class="math inline">\(n\)</span>: taille de l’échantillon;</li>
<li><span class="math inline">\(n_{h}\)</span>: nombre d’échantillons dans la strate <span class="math inline">\(h\)</span>;</li>
<li><span class="math inline">\(N_{h}\)</span>: taille de la strate <span class="math inline">\(h\)</span>;</li>
<li><span class="math inline">\(N\)</span>: taille de population.</li>
</ul>
<p>Afin d’optimiser l’effort et les coûts, on peut répartir l’effort d’échantillonnage en fonction de la taille des strates.</p>
<ul>
<li>Si les <span class="math inline">\(L\)</span> strates sont de taille égale, on peut attribuer <span class="math inline">\(n_{h}\)</span> égal partout (<span class="math inline">\(n_{h} = n/L\)</span>). Par exemple, si <span class="math inline">\(n = 30 \: \text{et} \: L = 3\)</span>, nous aurons donc <span class="math inline">\(n_{h} = 30/3 = 10\)</span>.</li>
<li>Si les strates sont de taille inégale, on peut attribuer un effort proportionnel à la taille de chaque strate (<span class="math inline">\(N_h\)</span>) par rapport à la somme de l’ensemble des strates (<span class="math inline">\(N\)</span>) afin d’obtenir une fraction constante partout qui équivaut à (<span class="math inline">\(n/N\)</span>). Si la strate <span class="math inline">\(h\)</span> contient <span class="math inline">\(N_h\)</span> unités, l’effort sera <span class="math inline">\(n_h = \frac{n \cdot N_h}{N}\)</span>. Par exemple, si <span class="math inline">\(n = 30, N_h = 200 \: \text{et} \: N = 1000\)</span>, nous obtiendrons <span class="math inline">\(n_{h} = \frac{n \cdot N_h}{N} = \frac{30 \cdot 200}{1000} = 6\)</span>.</li>
<li>On peut aussi opter de répartir l’effort d’échantillonnage pour obtenir la moyenne avec la plus faible variance pour une taille d’échantillon <span class="math inline">\(n\)</span> donnée – c’est ce qu’on appelle l’allocation optimale. Cette dernière option requiert une estimation de la variance à partir de données préléminaires ou d’anciens échantillons. Elle permet également d’y incorporer le coût en ressources (e.g., argent, temps). On attribue de plus gros échantillons aux plus grandes strates ou aux strates les plus variables et des plus petits échantillons aux strates plus petites ou qui sont plus coûteuses à échantillonner. Ceci permet d’optimiser l’allocation des ressources dévouées à l’échantillonnage.</li>
</ul>
</div>
<div id="échantillonnage-par-grappes-et-échantillonnage-systématique" class="section level4 hasAnchor" number="2.1.4.2">
<h4><span class="header-section-number">2.1.4.2</span> Échantillonnage par grappes et échantillonnage systématique<a href="théories-1.html#échantillonnage-par-grappes-et-échantillonnage-systématique" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Dans l’<strong>échantillonnage par grappes</strong>, la population est divisée en groupes (grappes) d’unités secondaires près les unes des autres et les grappes sont sélectionnées aléatoirement. Par grappes, on entend un groupe composés d’unités spatiales adjacentes, comme des quadrats ou des transects contigus. La figure <a href="théories-1.html#fig:cluster">2.6</a> montre cinq grappes de quatre quadrat. Ces grappes sont sélectionnées aléatoirement dans l’aire d’étude, mais les unités qui composent la grappe ne le sont pas. Ce genre de dispositif ne peut pas être analysé comme si les données étaient complètement indépendantes les unes des autres. Par conséquent, des analyses moins conventionnelles sont nécessaires pour estimer les paramètres d’intérêt.</p>
<div class="figure" style="text-align: left"><span style="display:block;" id="fig:cluster"></span>
<a href="images/Target3.png" target="_blank"><img src="Module_2/images/grappes2.png" alt="Exemple de grappes de quadrats pour l'échantillonnage par grappes." width="354" /></a>
<p class="caption">
Figure 2.6: Exemple de grappes de quadrats pour l’échantillonnage par grappes.
</p>
</div>
<p>L’<strong>échantillonnage systématique</strong> est une variation de l’échantillonnage par grappe où on dispose systématiquement les unités d’échantillonnage parmi la population. Le point de départ de la grille est sélectionné aléatoirement, mais les unités d’échantillonnage ne le sont pas (Figure <a href="théories-1.html#fig:systematic">2.7</a>).</p>
<div class="figure" style="text-align: left"><span style="display:block;" id="fig:systematic"></span>
<a href="images/Target3.png" target="_blank"><img src="Module_2/images/systematic.png" alt="Exemple d'échantillonnage systématique avec deux grappes (grilles) de quadrats." width="362" /></a>
<p class="caption">
Figure 2.7: Exemple d’échantillonnage systématique avec deux grappes (grilles) de quadrats.
</p>
</div>
<p>Avec l’échantillonnage par grappes ou l’échantillonnage systématique, on peut obtenir des estimés avec une faible variance si les grappes sont semblables entre elles. Idéalement, toute la variabilité de la population devrait être observée dans chaque grappe afin d’obtenir un échantillon représentatif de la population. Ce dernier point contraste avec l’échantillonnage stratifié qui minimisait la variance à l’intérieur des strates. Il y a toutefois quelques mises en garde:</p>
<ul>
<li>l’échantillonnage systématique avec une seule grappe permet d’estimer une moyenne, mais la variance ne se calcule pas comme pour un échantillon aléatoire;</li>
<li>la forme et la taille des grappes influencent l’efficacité;</li>
<li>en présence de forte hétérogénéité spatiale caractérisée par des patrons périodiques, l’échantillonnage systématique est déconseillé. Par exemple, échantillonner dans un milieu vallonné, où les unités d’échantillonnage tombent toujours dans une vallée sur toute l’aire d’étude ne capture que les caractéristiques des observations sur l’ensemble du milieu vallonné.</li>
</ul>
</div>
<div id="échantillonnage-multistade" class="section level4 hasAnchor" number="2.1.4.3">
<h4><span class="header-section-number">2.1.4.3</span> Échantillonnage multistade<a href="théories-1.html#échantillonnage-multistade" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Il existe d’autres stratégies d’échantillonnage, telles que l’<strong>échantillonnage multistade</strong> qui consiste à sélectionner aléatoirement des unités secondaires à l’intérieur d’unités primaires. Pour illustrer cette stratégie, considérons une étude qui vise à caractériser des planches de bois destinées à la construction. Pour ce faire, on pourrait sélectionner 10 camions parmi ceux qui arrivent à l’entrepôt d’un centre de rénovation et choisir aléatoirement 15 planches dans chaque camion. Cette stratégie se distingue de l’échantillonnage par grappes par une sélection aléatoire des unités secondaires dans les grappes.</p>
<p>Tout comme l’échantillonnage par grappes, l’échantillonnage multistade est logistiquement plus facile à réaliser que l’échantillonnage complètement aléatoire. Toutefois, les calculs des moyennes et des variances sont plus complexes que pour l’échantillonnage complètement aléatoire. Il est possible d’ajouter d’autres niveaux d’échantillonnage. Par exemple, dans une étude sur les insectes en forêt tropicale, on pourrait sélectionner aléatoirement des parcelles de 20 x 20 m dans l’aire d’étude dans lesquelles on sélectionnerait 5 quadrats de 1 x 1 m, pour ensuite établir 1 microquadrat de 0.25 x 0.25 m dans chaque quadrat afin de compter le nombre d’espèces de mousses.</p>
</div>
<div id="échantillonnage-adaptatif" class="section level4 hasAnchor" number="2.1.4.4">
<h4><span class="header-section-number">2.1.4.4</span> Échantillonnage adaptatif<a href="théories-1.html#échantillonnage-adaptatif" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>L’<strong>échantillonnage adaptatif</strong> est une classe de stratégies d’échantillonnage qui regroupe plusieurs méthodes où la sélection des unités est modifée au cours de l’échantillonnage en fonction des observations qui s’accumulent. On peut l’utiliser pour des espèces rares ou difficiles à observer où les individus sont regroupés spatialement (bancs de poissons, colonie d’insectes), ou encore pour échantillonner des dépôts géologiques (gisements d’or dont on ne connait pas initialement la localisation exacte). Toutefois, les méthodes de calcul des moyennes et de variance sont particulièrement complexes avec cette méthode d’échantillonnage, ce qui fait qu’elle est encore peu utilisée. En effet, peu de techniques d’analyses dans le moment permettent de traiter des données provenant de cette stratégie d’échantillonnage.</p>
</div>
<div id="estimation-de-la-probabilité-de-détection" class="section level4 hasAnchor" number="2.1.4.5">
<h4><span class="header-section-number">2.1.4.5</span> Estimation de la probabilité de détection<a href="théories-1.html#estimation-de-la-probabilité-de-détection" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Certaines stratégies d’échantillonnage permettent d’estimer la probabilité de détection d’organismes ou d’éléments étudiés qui sont difficiles à détecter lorsque présents sur un site lors d’un inventaire. Les facteurs tels que la coloration, le comportement, le type d’habitat, la méthode d’échantillonnage, les conditions météorologiques, le temps de la journée, l’abondance et la période de l’année peuvent tous influencer la détection. Dans le meilleur des cas, ce genre de problème amène des sous-estimation de l’abondance ou des patrons d’occurrence. Dans le pire des cas, les problèmes de détection entraînent des conclusions erronées lorsqu’on compare différents traitements entre eux. Ces approches sont particulièrement appliquées en écologie animale et constituent une branche importante des statistiques. La littérature à ce sujet croît à une vitesse fulgurante.</p>
<p>Parmi les stratégies qui estiment la probabilité de détection, on en compte trois principales, notamment l’échantillonnage de la distance, les méthodes de capture-marquage-recapture et les analyses d’occupation de sites.</p>
<div id="échantillonnage-de-la-distance" class="section level5 hasAnchor" number="2.1.4.5.1">
<h5><span class="header-section-number">2.1.4.5.1</span> Échantillonnage de la distance<a href="théories-1.html#échantillonnage-de-la-distance" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Pour estimer l’abondance, on peut utiliser l’<strong>échantillonnage de la distance</strong> (<em>distance sampling</em>), lequel consiste à établir des parcelles d’échantillonnage circulaires <a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> ou des transects <a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> disposés aléatoirement sur l’aire d’étude et dans lesquels on mesure la distance entre l’observateur et les individus détectés. Ceci permet de construire une fonction de détection et d’estimer l’abondance.</p>
</div>
<div id="méthode-de-capture-marquage-recapture" class="section level5 hasAnchor" number="2.1.4.5.2">
<h5><span class="header-section-number">2.1.4.5.2</span> Méthode de capture-marquage-recapture<a href="théories-1.html#méthode-de-capture-marquage-recapture" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Les méthodes de <strong>capture-marquage-recapture</strong> (CMR) consistent à capturer, marquer et recapturer des individus sur un ou plusieurs sites pendant plusieurs visites successives. On peut ainsi estimer la probabilité de capture et l’abondance des individus sur le site, laquelle est corrigée pour la détection imparfaite. Les méthodes de CMR sont également utilisées pour estimer des paramètres vitaux (<em>vital rates</em>), tels que la probabilité de survie, d’immigration et de transition d’un état à un autre, par exemple d’un état non reproducteur à reproducteur.</p>
</div>
<div id="analyses-dorccupation-de-sites" class="section level5 hasAnchor" number="2.1.4.5.3">
<h5><span class="header-section-number">2.1.4.5.3</span> Analyses d’orccupation de sites<a href="théories-1.html#analyses-dorccupation-de-sites" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Les <strong>analyses d’occupation de sites</strong> (<em>site occupancy analyses</em>) constituent une famille de méthodes généralement utilisée dans le domaine de la conservation de la biodiversité et permettant d’estimer la détection d’une espèce animale ou végétale sur une série de sites au cours de plusieurs visites successives, et ainsi d’obtenir une meilleure estimation de la probabilité de présence de l’espèce d’intérêt. Des modifications du modèle de base permettent d’estimer les probabilités d’extinction et de colonisation ou encore de co-occurrence entre deux espèces.</p>
<p>Parmi toutes les stratégies d’échantillonnage présentées, nous allons utiliser l’échantillonnage complètement aléatoire et l’échantillonnage stratifié aléatoire. À noter que les exemples vus dans le cours supposent que la détection des individus est parfaite.</p>
</div>
</div>
</div>
<div id="conclusion-1" class="section level3 hasAnchor" number="2.1.5">
<h3><span class="header-section-number">2.1.5</span> Conclusion<a href="théories-1.html#conclusion-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Dans ce texte, nous avons introduit le concept d’intervalle de confiance en nous appuyant sur le rééchantillonnage. Selon la taille d’échantillon, nous avons utilisé la distribution normale ou la distribution du <em>t</em> de Student pour construire les intervalles de confiance. Parmi les différentes stratégies d’échantillonnage présentées, nous verrons le plus souvent l’échantillonnage complètement aléatoire et l’échantillonnage stratifié aléatoire.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="5">
<li id="fn5"><p>Plusieurs fonctions de R utilisent des générateurs de nombres aléatoires dans R, notamment <code>rnorm()</code> et <code>sample()</code>. Les algorithmes aléatoires nécessitent une valeur initiale appelée <em>seed</em> afin de démarrer le processus aléatoire. Par défaut, ces valeurs proviennent de l’horloge interne de l’ordinateur (année, mois, jour, heure, minute, seconde, microseconde). Ainsi, si on effectue la fonction <code>rnorm( )</code> ou<code>sample(,~replace = FALSE)</code> plusieurs fois, on obtiendra un résultat différent à chaque fois. On peut aussi procurer une valeur initiale <em>seed</em> afin d’obtenir le même résultat à chaque fois à l’aide de la fonction . L’argument <em>seed</em> de cette fonction prend un entier comme valeur.<a href="théories-1.html#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>Une parcelle d’échantillonnage est tout simplement un cercle dans lequel on échantillonne les éléments d’intérêt sur le terrain comme des oiseaux ou des grenouilles.<a href="théories-1.html#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>Un transect est un corridor de largeur et longueur définie qui est disposé dans un site afin d’échantillonner les éléments d’intérêt comme des herbivores.<a href="théories-1.html#fnref7" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="intervalles-de-confiance-et-stratégies-déchantillonnage.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="les-graphiques-avec-r.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
},
"info": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
