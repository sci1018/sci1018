<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.1 Leçon | Statistiques avec R</title>
  <meta name="description" content="1.1 Leçon | Statistiques avec R" />
  <meta name="generator" content="bookdown 0.39 and GitBook 2.6.7" />

  <meta property="og:title" content="1.1 Leçon | Statistiques avec R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="1.1 Leçon | Statistiques avec R" />
  <meta name="github-repo" content="sci1018/sci1018" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.1 Leçon | Statistiques avec R" />
  
  <meta name="twitter:description" content="1.1 Leçon | Statistiques avec R" />
  

<meta name="author" content="" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="statistiques-descriptives.html"/>
<link rel="next" href="statistiques-de-base-avec-r.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #204a87; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #204a87; font-weight: bold; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #ce5c00; font-weight: bold; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">TÉLUQ - SCI 1018</a></li>

<li class="divider"></li>
<li><a href="index.html#section" id="toc-section"></a></li>
<li class="part"><span><b>I SCI 1018</b></span></li>
<li class="chapter" data-level="" data-path="à-propos-du-cours.html"><a href="à-propos-du-cours.html"><i class="fa fa-check"></i>À propos du cours</a>
<ul>
<li class="chapter" data-level="" data-path="à-propos-du-cours.html"><a href="à-propos-du-cours.html#présentation"><i class="fa fa-check"></i>Présentation</a></li>
<li class="chapter" data-level="" data-path="à-propos-du-cours.html"><a href="à-propos-du-cours.html#feuille-de-route"><i class="fa fa-check"></i>Feuille de route</a></li>
<li class="chapter" data-level="" data-path="à-propos-du-cours.html"><a href="à-propos-du-cours.html#crédits"><i class="fa fa-check"></i>Crédits</a></li>
<li class="chapter" data-level="" data-path="à-propos-du-cours.html"><a href="à-propos-du-cours.html#contact"><i class="fa fa-check"></i>Contact</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ressources.html"><a href="ressources.html"><i class="fa fa-check"></i>Ressources</a>
<ul>
<li class="chapter" data-level="" data-path="ressources.html"><a href="ressources.html#travaux-notés"><i class="fa fa-check"></i>Travaux notés</a></li>
<li class="chapter" data-level="" data-path="ressources.html"><a href="ressources.html#données"><i class="fa fa-check"></i>Données</a></li>
<li class="chapter" data-level="" data-path="ressources.html"><a href="ressources.html#ressources-r"><i class="fa fa-check"></i>Ressources R</a></li>
<li class="chapter" data-level="" data-path="ressources.html"><a href="ressources.html#références"><i class="fa fa-check"></i>Références</a></li>
</ul></li>
<li class="part"><span><b>II GUIDE R</b></span></li>
<li class="chapter" data-level="" data-path="installation-de-r.html"><a href="installation-de-r.html"><i class="fa fa-check"></i>Installation de R</a>
<ul>
<li class="chapter" data-level="" data-path="installation-de-r.html"><a href="installation-de-r.html#où-se-procurer"><i class="fa fa-check"></i>Où se procurer ?</a></li>
<li class="chapter" data-level="" data-path="pour-débuter-avec-r.html"><a href="pour-débuter-avec-r.html"><i class="fa fa-check"></i>Pour débuter avec R</a></li>
<li class="chapter" data-level="" data-path="choisir-son-éditeur.html"><a href="choisir-son-éditeur.html"><i class="fa fa-check"></i>Choisir son éditeur</a></li>
</ul></li>
<li class="part"><span><b>III APPRENTISSAGE</b></span></li>
<li class="chapter" data-level="" data-path="programmation-avec-r.html"><a href="programmation-avec-r.html"><i class="fa fa-check"></i>Programmation avec R</a>
<ul>
<li class="chapter" data-level="" data-path="notions-générales.html"><a href="notions-générales.html"><i class="fa fa-check"></i>Notions générales</a></li>
<li class="chapter" data-level="" data-path="exercices.html"><a href="exercices.html"><i class="fa fa-check"></i>Exercices</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="statistiques-descriptives.html"><a href="statistiques-descriptives.html"><i class="fa fa-check"></i><b>1</b> Statistiques descriptives</a>
<ul>
<li class="chapter" data-level="1.1" data-path="leçon.html"><a href="leçon.html"><i class="fa fa-check"></i><b>1.1</b> Leçon</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="leçon.html"><a href="leçon.html#paramètre-vs-statistique"><i class="fa fa-check"></i><b>1.1.1</b> Paramètre vs statistique</a></li>
<li class="chapter" data-level="1.1.2" data-path="leçon.html"><a href="leçon.html#mesures-de-la-tendance-centrale"><i class="fa fa-check"></i><b>1.1.2</b> Mesures de la tendance centrale</a></li>
<li class="chapter" data-level="1.1.3" data-path="leçon.html"><a href="leçon.html#mesures-de-dispersion"><i class="fa fa-check"></i><b>1.1.3</b> Mesures de dispersion</a></li>
<li class="chapter" data-level="1.1.4" data-path="leçon.html"><a href="leçon.html#variables-aléatoires"><i class="fa fa-check"></i><b>1.1.4</b> Variables aléatoires</a></li>
<li class="chapter" data-level="1.1.5" data-path="leçon.html"><a href="leçon.html#loi-des-grands-nombres-et-théorème-de-la-limite-centrale"><i class="fa fa-check"></i><b>1.1.5</b> Loi des grands nombres et théorème de la limite centrale</a></li>
<li class="chapter" data-level="1.1.6" data-path="leçon.html"><a href="leçon.html#distribution-normale"><i class="fa fa-check"></i><b>1.1.6</b> Distribution normale</a></li>
<li class="chapter" data-level="1.1.7" data-path="leçon.html"><a href="leçon.html#conclusion"><i class="fa fa-check"></i><b>1.1.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="statistiques-de-base-avec-r.html"><a href="statistiques-de-base-avec-r.html"><i class="fa fa-check"></i><b>1.2</b> Statistiques de base avec R</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="statistiques-de-base-avec-r.html"><a href="statistiques-de-base-avec-r.html#fonctions-statistiques-de-base"><i class="fa fa-check"></i><b>1.2.1</b> Fonctions statistiques de base</a></li>
<li class="chapter" data-level="1.2.2" data-path="statistiques-de-base-avec-r.html"><a href="statistiques-de-base-avec-r.html#distribution-statistiques"><i class="fa fa-check"></i><b>1.2.2</b> Distribution statistiques</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="autoévaluation.html"><a href="autoévaluation.html"><i class="fa fa-check"></i><b>1.3</b> Autoévaluation</a>
<ul>
<li class="chapter" data-level="" data-path="autoévaluation.html"><a href="autoévaluation.html#question-1-1"><i class="fa fa-check"></i>Question 1</a></li>
<li class="chapter" data-level="" data-path="autoévaluation.html"><a href="autoévaluation.html#question-2-1"><i class="fa fa-check"></i>Question 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intervalles-de-confiance-et-stratégies-déchantillonnage.html"><a href="intervalles-de-confiance-et-stratégies-déchantillonnage.html"><i class="fa fa-check"></i><b>2</b> Intervalles de confiance et stratégies d’échantillonnage</a>
<ul>
<li class="chapter" data-level="2.1" data-path="leçon-1.html"><a href="leçon-1.html"><i class="fa fa-check"></i><b>2.1</b> Leçon</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="leçon-1.html"><a href="leçon-1.html#problèmes-déchantillonnage"><i class="fa fa-check"></i><b>2.1.1</b> Problèmes d’échantillonnage</a></li>
<li class="chapter" data-level="2.1.2" data-path="leçon-1.html"><a href="leçon-1.html#échantillonnage-complètement-aléatoire"><i class="fa fa-check"></i><b>2.1.2</b> Échantillonnage complètement aléatoire</a></li>
<li class="chapter" data-level="2.1.3" data-path="leçon-1.html"><a href="leçon-1.html#intervalle-de-confiance"><i class="fa fa-check"></i><b>2.1.3</b> Intervalle de confiance</a></li>
<li class="chapter" data-level="2.1.4" data-path="leçon-1.html"><a href="leçon-1.html#autres-stratégies-déchantillonnage"><i class="fa fa-check"></i><b>2.1.4</b> Autres stratégies d’échantillonnage</a></li>
<li class="chapter" data-level="2.1.5" data-path="leçon-1.html"><a href="leçon-1.html#conclusion-1"><i class="fa fa-check"></i><b>2.1.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="les-graphiques-avec-r.html"><a href="les-graphiques-avec-r.html"><i class="fa fa-check"></i><b>2.2</b> Les graphiques avec R</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="les-graphiques-avec-r.html"><a href="les-graphiques-avec-r.html#graphiques-de-base"><i class="fa fa-check"></i><b>2.2.1</b> Graphiques de base</a></li>
<li class="chapter" data-level="2.2.2" data-path="les-graphiques-avec-r.html"><a href="les-graphiques-avec-r.html#histogramme"><i class="fa fa-check"></i><b>2.2.2</b> Histogramme</a></li>
<li class="chapter" data-level="2.2.3" data-path="les-graphiques-avec-r.html"><a href="les-graphiques-avec-r.html#diagramme-à-bâtons"><i class="fa fa-check"></i><b>2.2.3</b> Diagramme à bâtons</a></li>
<li class="chapter" data-level="2.2.4" data-path="les-graphiques-avec-r.html"><a href="les-graphiques-avec-r.html#diagramme-de-boîtes-et-moustaches"><i class="fa fa-check"></i><b>2.2.4</b> Diagramme de boîtes et moustaches</a></li>
<li class="chapter" data-level="2.2.5" data-path="les-graphiques-avec-r.html"><a href="les-graphiques-avec-r.html#graphiques-génériques"><i class="fa fa-check"></i><b>2.2.5</b> Graphiques génériques</a></li>
<li class="chapter" data-level="2.2.6" data-path="les-graphiques-avec-r.html"><a href="les-graphiques-avec-r.html#sauvegarder-des-graphiques"><i class="fa fa-check"></i><b>2.2.6</b> Sauvegarder des graphiques</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="autoévaluation-1.html"><a href="autoévaluation-1.html"><i class="fa fa-check"></i><b>2.3</b> Autoévaluation</a>
<ul>
<li class="chapter" data-level="" data-path="autoévaluation-1.html"><a href="autoévaluation-1.html#question-1-2"><i class="fa fa-check"></i>Question 1</a></li>
<li class="chapter" data-level="" data-path="autoévaluation-1.html"><a href="autoévaluation-1.html#question-2-2"><i class="fa fa-check"></i>Question 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="tests-dhypothèse-sur-un-seul-groupe.html"><a href="tests-dhypothèse-sur-un-seul-groupe.html"><i class="fa fa-check"></i><b>3</b> Tests d’hypothèse sur un seul groupe</a>
<ul>
<li class="chapter" data-level="3.1" data-path="leçon-2.html"><a href="leçon-2.html"><i class="fa fa-check"></i><b>3.1</b> Leçon</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="leçon-2.html"><a href="leçon-2.html#hypothèse"><i class="fa fa-check"></i><b>3.1.1</b> Hypothèse</a></li>
<li class="chapter" data-level="3.1.2" data-path="leçon-2.html"><a href="leçon-2.html#hypothèse-statistiques"><i class="fa fa-check"></i><b>3.1.2</b> Hypothèse statistiques</a></li>
<li class="chapter" data-level="3.1.3" data-path="leçon-2.html"><a href="leçon-2.html#erreurs-de-type-i-et-ii"><i class="fa fa-check"></i><b>3.1.3</b> Erreurs de type I et II</a></li>
<li class="chapter" data-level="3.1.4" data-path="leçon-2.html"><a href="leçon-2.html#utilisation-de-tests-dhypothèse"><i class="fa fa-check"></i><b>3.1.4</b> Utilisation de tests d’hypothèse</a></li>
<li class="chapter" data-level="3.1.5" data-path="leçon-2.html"><a href="leçon-2.html#estimation-de-paramètres"><i class="fa fa-check"></i><b>3.1.5</b> Estimation de paramètres</a></li>
<li class="chapter" data-level="3.1.6" data-path="leçon-2.html"><a href="leçon-2.html#tests-dhypothèse-sur-la-moyenne-dun-seul-groupe"><i class="fa fa-check"></i><b>3.1.6</b> Tests d’hypothèse sur la moyenne d’un seul groupe</a></li>
<li class="chapter" data-level="3.1.7" data-path="leçon-2.html"><a href="leçon-2.html#conclusion-2"><i class="fa fa-check"></i><b>3.1.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="les-packages-avec-r.html"><a href="les-packages-avec-r.html"><i class="fa fa-check"></i><b>3.2</b> Les packages avec R</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="les-packages-avec-r.html"><a href="les-packages-avec-r.html#activer-un-package"><i class="fa fa-check"></i><b>3.2.1</b> Activer un package</a></li>
<li class="chapter" data-level="3.2.2" data-path="les-packages-avec-r.html"><a href="les-packages-avec-r.html#installer-un-package"><i class="fa fa-check"></i><b>3.2.2</b> Installer un package</a></li>
<li class="chapter" data-level="3.2.3" data-path="les-packages-avec-r.html"><a href="les-packages-avec-r.html#mettre-à-jour-un-package"><i class="fa fa-check"></i><b>3.2.3</b> Mettre à jour un package</a></li>
<li class="chapter" data-level="3.2.4" data-path="les-packages-avec-r.html"><a href="les-packages-avec-r.html#désactiver-un-package"><i class="fa fa-check"></i><b>3.2.4</b> Désactiver un package</a></li>
<li class="chapter" data-level="3.2.5" data-path="les-packages-avec-r.html"><a href="les-packages-avec-r.html#désinstaller-un-package"><i class="fa fa-check"></i><b>3.2.5</b> Désinstaller un package</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="autoévaluation-2.html"><a href="autoévaluation-2.html"><i class="fa fa-check"></i><b>3.3</b> Autoévaluation</a>
<ul>
<li class="chapter" data-level="" data-path="autoévaluation-2.html"><a href="autoévaluation-2.html#question-1-3"><i class="fa fa-check"></i>Question 1</a></li>
<li class="chapter" data-level="" data-path="autoévaluation-2.html"><a href="autoévaluation-2.html#question-2-3"><i class="fa fa-check"></i>Question 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="tests-dhypothèse-sur-deux-groupes.html"><a href="tests-dhypothèse-sur-deux-groupes.html"><i class="fa fa-check"></i><b>4</b> Tests d’hypothèse sur deux groupes</a>
<ul>
<li class="chapter" data-level="4.1" data-path="leçon-3.html"><a href="leçon-3.html"><i class="fa fa-check"></i><b>4.1</b> Leçon</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="leçon-3.html"><a href="leçon-3.html#tests-dhypothèses-sur-la-moyenne-de-deux-groupes-indépendants"><i class="fa fa-check"></i><b>4.1.1</b> Tests d’hypothèses sur la moyenne de deux groupes indépendants</a></li>
<li class="chapter" data-level="4.1.2" data-path="leçon-3.html"><a href="leçon-3.html#tests-dhypothèse-pour-deux-groupes-appariés"><i class="fa fa-check"></i><b>4.1.2</b> Tests d’hypothèse pour deux groupes appariés</a></li>
<li class="chapter" data-level="4.1.3" data-path="leçon-3.html"><a href="leçon-3.html#transformations"><i class="fa fa-check"></i><b>4.1.3</b> Transformations</a></li>
<li class="chapter" data-level="4.1.4" data-path="leçon-3.html"><a href="leçon-3.html#conclusion-3"><i class="fa fa-check"></i><b>4.1.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="laboratoire.html"><a href="laboratoire.html"><i class="fa fa-check"></i><b>4.2</b> Laboratoire</a>
<ul>
<li class="chapter" data-level="" data-path="laboratoire.html"><a href="laboratoire.html#question-1-4"><i class="fa fa-check"></i>Question 1</a></li>
<li class="chapter" data-level="" data-path="laboratoire.html"><a href="laboratoire.html#question-2-4"><i class="fa fa-check"></i>Question 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="analyse-de-fréquences-et-test-du-khi-carré-chi2.html"><a href="analyse-de-fréquences-et-test-du-khi-carré-chi2.html"><i class="fa fa-check"></i><b>5</b> Analyse de fréquences et test du khi carré (<span class="math inline">\(\chi^2\)</span>)</a>
<ul>
<li class="chapter" data-level="5.1" data-path="leçon-4.html"><a href="leçon-4.html"><i class="fa fa-check"></i><b>5.1</b> Leçon</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="leçon-4.html"><a href="leçon-4.html#analyse-de-fréquences-le-test-du-khi-carré-chi2"><i class="fa fa-check"></i><b>5.1.1</b> Analyse de fréquences : le test du khi carré (<span class="math inline">\(\chi^2\)</span>)</a></li>
<li class="chapter" data-level="5.1.2" data-path="leçon-4.html"><a href="leçon-4.html#tableau-de-contingence"><i class="fa fa-check"></i><b>5.1.2</b> Tableau de contingence</a></li>
<li class="chapter" data-level="5.1.3" data-path="leçon-4.html"><a href="leçon-4.html#alternative-au-test-du-chi2"><i class="fa fa-check"></i><b>5.1.3</b> Alternative au test du <span class="math inline">\(\chi^2\)</span></a></li>
<li class="chapter" data-level="5.1.4" data-path="leçon-4.html"><a href="leçon-4.html#le-paradoxe-de-simpson"><i class="fa fa-check"></i><b>5.1.4</b> Le paradoxe de Simpson</a></li>
<li class="chapter" data-level="5.1.5" data-path="leçon-4.html"><a href="leçon-4.html#conclusion-4"><i class="fa fa-check"></i><b>5.1.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="autoévaluation-3.html"><a href="autoévaluation-3.html"><i class="fa fa-check"></i><b>5.2</b> Autoévaluation</a>
<ul>
<li class="chapter" data-level="" data-path="autoévaluation-3.html"><a href="autoévaluation-3.html#question-1-5"><i class="fa fa-check"></i>Question 1</a></li>
<li class="chapter" data-level="" data-path="autoévaluation-3.html"><a href="autoévaluation-3.html#question-2-5"><i class="fa fa-check"></i>Question 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="analyse-de-variance-à-un-critère.html"><a href="analyse-de-variance-à-un-critère.html"><i class="fa fa-check"></i><b>6</b> Analyse de variance à un critère</a>
<ul>
<li class="chapter" data-level="6.1" data-path="leçon-5.html"><a href="leçon-5.html"><i class="fa fa-check"></i><b>6.1</b> Leçon</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="leçon-5.html"><a href="leçon-5.html#comparaison-de-plusieurs-groupes"><i class="fa fa-check"></i><b>6.1.1</b> Comparaison de plusieurs groupes</a></li>
<li class="chapter" data-level="6.1.2" data-path="leçon-5.html"><a href="leçon-5.html#analyse-de-variance-anova"><i class="fa fa-check"></i><b>6.1.2</b> Analyse de variance (ANOVA)</a></li>
<li class="chapter" data-level="6.1.3" data-path="leçon-5.html"><a href="leçon-5.html#comparaison-multiples"><i class="fa fa-check"></i><b>6.1.3</b> Comparaison multiples</a></li>
<li class="chapter" data-level="6.1.4" data-path="leçon-5.html"><a href="leçon-5.html#conclusion-5"><i class="fa fa-check"></i><b>6.1.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="les-boucles-avec-r.html"><a href="les-boucles-avec-r.html"><i class="fa fa-check"></i><b>6.2</b> Les boucles avec R</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="les-boucles-avec-r.html"><a href="les-boucles-avec-r.html#les-boucles"><i class="fa fa-check"></i><b>6.2.1</b> Les boucles</a></li>
<li class="chapter" data-level="6.2.2" data-path="les-boucles-avec-r.html"><a href="les-boucles-avec-r.html#alternatives-aux-boucles"><i class="fa fa-check"></i><b>6.2.2</b> Alternatives aux boucles</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="autoévaluation-4.html"><a href="autoévaluation-4.html"><i class="fa fa-check"></i><b>6.3</b> Autoévaluation</a>
<ul>
<li class="chapter" data-level="" data-path="autoévaluation-4.html"><a href="autoévaluation-4.html#question-1-6"><i class="fa fa-check"></i>Question 1</a></li>
<li class="chapter" data-level="" data-path="autoévaluation-4.html"><a href="autoévaluation-4.html#question-2-6"><i class="fa fa-check"></i>Question 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="analyse-de-variance-à-deux-critères.html"><a href="analyse-de-variance-à-deux-critères.html"><i class="fa fa-check"></i><b>7</b> Analyse de variance à deux critères</a>
<ul>
<li class="chapter" data-level="7.1" data-path="leçon-6.html"><a href="leçon-6.html"><i class="fa fa-check"></i><b>7.1</b> Leçon</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="leçon-6.html"><a href="leçon-6.html#anova-à-deux-critères"><i class="fa fa-check"></i><b>7.1.1</b> ANOVA à deux critères</a></li>
<li class="chapter" data-level="7.1.2" data-path="leçon-6.html"><a href="leçon-6.html#suppositions-et-dispositif-expérimental"><i class="fa fa-check"></i><b>7.1.2</b> Suppositions et dispositif expérimental</a></li>
<li class="chapter" data-level="7.1.3" data-path="leçon-6.html"><a href="leçon-6.html#hypothèses-statistiques-1"><i class="fa fa-check"></i><b>7.1.3</b> Hypothèses statistiques</a></li>
<li class="chapter" data-level="7.1.4" data-path="leçon-6.html"><a href="leçon-6.html#sommes-des-carrés-1"><i class="fa fa-check"></i><b>7.1.4</b> Sommes des carrés</a></li>
<li class="chapter" data-level="7.1.5" data-path="leçon-6.html"><a href="leçon-6.html#effets-additifs"><i class="fa fa-check"></i><b>7.1.5</b> Effets additifs</a></li>
<li class="chapter" data-level="7.1.6" data-path="leçon-6.html"><a href="leçon-6.html#conclusion-6"><i class="fa fa-check"></i><b>7.1.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="laboratoire-1.html"><a href="laboratoire-1.html"><i class="fa fa-check"></i><b>7.2</b> Laboratoire</a>
<ul>
<li class="chapter" data-level="" data-path="laboratoire-1.html"><a href="laboratoire-1.html#question-1-7"><i class="fa fa-check"></i>Question 1</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="blocs-complets-aléatoires.html"><a href="blocs-complets-aléatoires.html"><i class="fa fa-check"></i><b>8</b> Blocs complets aléatoires</a>
<ul>
<li class="chapter" data-level="8.1" data-path="leçon-7.html"><a href="leçon-7.html"><i class="fa fa-check"></i><b>8.1</b> Leçon</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="leçon-7.html"><a href="leçon-7.html#effets-fixes-et-effets-aléatoires"><i class="fa fa-check"></i><b>8.1.1</b> Effets fixes et effets aléatoires</a></li>
<li class="chapter" data-level="8.1.2" data-path="leçon-7.html"><a href="leçon-7.html#blocs-complets-aléatoires-1"><i class="fa fa-check"></i><b>8.1.2</b> Blocs complets aléatoires</a></li>
<li class="chapter" data-level="8.1.3" data-path="leçon-7.html"><a href="leçon-7.html#conclusion-7"><i class="fa fa-check"></i><b>8.1.3</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="autoévaluation-5.html"><a href="autoévaluation-5.html"><i class="fa fa-check"></i><b>8.2</b> Autoévaluation</a>
<ul>
<li class="chapter" data-level="" data-path="autoévaluation-5.html"><a href="autoévaluation-5.html#question-1-8"><i class="fa fa-check"></i>Question 1</a></li>
<li class="chapter" data-level="" data-path="autoévaluation-5.html"><a href="autoévaluation-5.html#question-2-7"><i class="fa fa-check"></i>Question 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="élaboration-et-optimisation-de-plans-déchantillonnage.html"><a href="élaboration-et-optimisation-de-plans-déchantillonnage.html"><i class="fa fa-check"></i><b>9</b> Élaboration et optimisation de plans d’échantillonnage</a>
<ul>
<li class="chapter" data-level="9.1" data-path="leçon-8.html"><a href="leçon-8.html"><i class="fa fa-check"></i><b>9.1</b> Leçon</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="leçon-8.html"><a href="leçon-8.html#plans-déchantillonnage"><i class="fa fa-check"></i><b>9.1.1</b> Plans d’échantillonnage</a></li>
<li class="chapter" data-level="9.1.2" data-path="leçon-8.html"><a href="leçon-8.html#nos-meilleurs-alliés-dans-lélaboration-dun-plan-déchantillonnage"><i class="fa fa-check"></i><b>9.1.2</b> Nos meilleurs alliés dans l’élaboration d’un plan d’échantillonnage</a></li>
<li class="chapter" data-level="9.1.3" data-path="leçon-8.html"><a href="leçon-8.html#problèmes-associés-à-certains-plan-déchantillonnage"><i class="fa fa-check"></i><b>9.1.3</b> Problèmes associés à certains plan d’échantillonnage</a></li>
<li class="chapter" data-level="9.1.4" data-path="leçon-8.html"><a href="leçon-8.html#conclusion-8"><i class="fa fa-check"></i><b>9.1.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="laboratoire-2.html"><a href="laboratoire-2.html"><i class="fa fa-check"></i><b>9.2</b> Laboratoire</a>
<ul>
<li class="chapter" data-level="" data-path="laboratoire-2.html"><a href="laboratoire-2.html#instructions"><i class="fa fa-check"></i>Instructions</a></li>
<li class="chapter" data-level="" data-path="laboratoire-2.html"><a href="laboratoire-2.html#suggestions-de-thèmes-à-étudier"><i class="fa fa-check"></i>Suggestions de thèmes à étudier</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="régression-linéaire-simple-et-corrélation.html"><a href="régression-linéaire-simple-et-corrélation.html"><i class="fa fa-check"></i><b>10</b> Régression linéaire simple et corrélation</a>
<ul>
<li class="chapter" data-level="10.1" data-path="leçon-9.html"><a href="leçon-9.html"><i class="fa fa-check"></i><b>10.1</b> Leçon</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="leçon-9.html"><a href="leçon-9.html#la-régression-linéaire"><i class="fa fa-check"></i><b>10.1.1</b> La régression linéaire</a></li>
<li class="chapter" data-level="10.1.2" data-path="leçon-9.html"><a href="leçon-9.html#corrélation"><i class="fa fa-check"></i><b>10.1.2</b> Corrélation</a></li>
<li class="chapter" data-level="10.1.3" data-path="leçon-9.html"><a href="leçon-9.html#corrélation-vs-régression"><i class="fa fa-check"></i><b>10.1.3</b> Corrélation vs régression</a></li>
<li class="chapter" data-level="10.1.4" data-path="leçon-9.html"><a href="leçon-9.html#conclusion-9"><i class="fa fa-check"></i><b>10.1.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="autoévaluation-6.html"><a href="autoévaluation-6.html"><i class="fa fa-check"></i><b>10.2</b> Autoévaluation</a>
<ul>
<li class="chapter" data-level="" data-path="autoévaluation-6.html"><a href="autoévaluation-6.html#question-1-9"><i class="fa fa-check"></i>Question 1</a></li>
<li class="chapter" data-level="" data-path="autoévaluation-6.html"><a href="autoévaluation-6.html#question-2-8"><i class="fa fa-check"></i>Question 2</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistiques avec R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="leçon" class="section level2 hasAnchor" number="1.1">
<h2><span class="header-section-number">1.1</span> Leçon<a href="leçon.html#leçon" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="paramètre-vs-statistique" class="section level3 hasAnchor" number="1.1.1">
<h3><span class="header-section-number">1.1.1</span> Paramètre vs statistique<a href="leçon.html#paramètre-vs-statistique" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Le <strong>paramètre</strong> est un concept important. Il désigne une valeur numérique inconnue qui caractérise une population d’intérêt. Par exemple, la taille moyenne en cm des résidents de l’île de Montréal est une valeur inconnue (mais qui existe). C’est-à-dire qu’il serait possible de calculer cette valeur si on mesurait chaque individu de cette région. Un paramètre est habituellement représenté par une lettre grecque (<span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma\)</span>). Si la taille moyenne des résidents était de 1.91 m, on écrirait <span class="math inline">\(\mu\)</span> = 1.91 m.</p>
<p>À l’opposé, une <strong>statistique</strong> est une quantité qui peut être calculée à partir des données d’un échantillon. Par exemple, si nous désirons calculer la taille moyenne des résidents de l’île de Montréal, nous pourrions le faire en mesurant la taille de 100 résidents de l’île. Une statistique est normalement désignée par une lettre romaine (s, sd, <span class="math inline">\(\bar{x}\)</span>).</p>
<p>La <strong>population statistique</strong> est l’ensemble des éléments sur lesquels on veut baser nos conclusions (taille des résidents de Montréal). On ne connaît pas la taille moyenne des gens de cette population. Il existe deux options afin d’obtenir de l’information sur cette moyenne:</p>
<ul>
<li>mesurer la taille de chaque résident de Montréal (peu pratique et logistiquement difficile);</li>
<li>utiliser un <strong>échantillon</strong> construit à partir de tailles d’individus sélectionnés aléatoirement dans la population de Montréal.</li>
</ul>
<p>Pour faire une analogie, l’échantillon est à la population, ce que la statistique est au paramètre. Si nous poursuivons avec notre exemple d’échantillon de 100 résidents de Montréal (100 observations), la valeur numérique obtenue constituera une estimation de la taille moyenne (<span class="math inline">\(\mu\)</span>) des résidents de Montréal. L’estimation est une valeur possible que peut prendre un paramètre. Pour récapituler, on infère sur la population à partir d’un échantillon. Si la moyenne de l’échantillon est de 1.7 m (<span class="math inline">\(\bar{x}\)</span> = 1.7 m), on peut dire que 1.7 est une estimation de la moyenne de la population <span class="math inline">\(\mu\)</span>. Bref, on peut tirer des conclusions sur la population à partir d’un échantillon qui provient de cette même population.</p>
<p>Afin de faire une bonne estimation, l’échantillon doit être aléatoire et représentatif de la population. Dans un échantillon aléatoire, chaque élément de la population a une chance égale d’être inclus dans l’échantillon. Si on sélectionne aléatoirement 100 résidents de Montréal pour estimer la taille moyenne des individus dans la population et que, par malchance, tous les résidents sélectionnés proviennent du même quartier, l’échantillon ne sera pas représentatif de la population.</p>
</div>
<div id="mesures-de-la-tendance-centrale" class="section level3 hasAnchor" number="1.1.2">
<h3><span class="header-section-number">1.1.2</span> Mesures de la tendance centrale<a href="leçon.html#mesures-de-la-tendance-centrale" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Certaines mesures décrivent la valeur autour de laquelle se concentrent la plupart des observations d’un échantillon ou d’une population. On parle alors de <strong>tendance centrale</strong> ou de <strong>paramètres de position</strong>. On peut estimer ces paramètres à partir d’un échantillon. La <strong>moyenne arithmétique</strong> est un exemple de ce genre de mesure:</p>
<p><span class="math display">\[
\bar{x} = \frac{\sum\limits_{i=1}^nx_i}{n}
\]</span></p>
<p>où <span class="math inline">\(x_i\)</span> correspond à la valeur <span class="math inline">\(i\)</span> de la variable <span class="math inline">\(x\)</span> et <span class="math inline">\(n\)</span> correspond au nombre d’observations. À noter que <span class="math inline">\(\Sigma\)</span> (la lettre grecque <em>sigma</em>) indique la somme de toutes les observations de <span class="math inline">\(i = 1\)</span> jusqu’à <span class="math inline">\(n\)</span>. De façon plus générale, on appelle <strong>estimateur</strong> une formule ou équation utilisée pour estimer une certaine valeur, alors que l’estimation est le résultat de l’estimateur.</p>
<div class="exemple" section="1">
<p>Lors d’une expérience sur la hauteur de semis sur un sol argileux après une saison de croissance, on obtient les valeurs suivantes en cm: 12.3, 4.2, 5.9, 9.1, 3.3, 5.1, 7.3, 3.8, 8.0, 6.1. Le calcul de la moyenne arithmétique se fait comme suit:</p>
<p><span class="math display">\[
\bar{x} = \frac{\sum\limits_{i=1}^nx_i}{n} = \frac{12.3 + 4.2 + 5.9 +  \ldots + 8.0 + 6.1}{10} \\
\bar{x} = 6.51
\]</span>
<!-- je n'arrive pas à mettre les calculs dans les équations ci-dessus comme dans le texte ci-dessous pour afficher le résultat 6.51 -->
Ainsi, la moyenne arithmétique de cet échantillon est de 6.51 cm.</p>
</div>
<p>L’estimateur de <span class="math inline">\(\bar{x}\)</span> est un estimateur non-biaisé de <span class="math inline">\(\mu\)</span> si:</p>
<ul>
<li>les observations sont effectuées sur des individus sélectionnés aléatoirement;</li>
<li>les observations sont indépendantes;</li>
<li>les observations de la variable décrivant la population suivent une distribution normale.</li>
</ul>
<p>La <strong>moyenne géométrique</strong> est une autre mesure de tendance centrale, particulièrement appropriée pour décrire des processus multiplicatifs<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>. Un processus multiplicatif est un effet qui ou en présence de valeurs extrêmes:</p>
<p><span class="math display">\[
\bar{x}_{g\acute{e}om} = \sqrt[n]{\prod_{i=1}^n x_i} \\
\bar{x}_{g\acute{e}om} = e^\frac{{\sum\limits_{i=1}^n \log(x_i)}}{n}
\]</span></p>
<div class="exemple" section="1">
<p>Disons qu’après un décompte d’insectes sur 5 quadrats<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> dans un champ agricole, on observe les abondances suivantes: 10, 1, 1000, 1, 10.</p>
<p><span class="math display">\[
\bar{x}_{g\acute{e}om} = \sqrt[5]{10 \cdot 1 \cdot 1000 \cdot 1 \cdot 10} \\
\bar{x}_{g\acute{e}om} = 10
\]</span>
La moyenne géométrique de ces valeurs nous donne 10, alors que la moyenne arithmétique nous donne 204.4. La valeur 1000 se démarque nettement des autres et exerce une influence démesurée sur la moyenne arithmétique, et dans ce cas, la moyenne géométrique est un meilleur estimateur de la tendance centrale.</p>
</div>
<p>La <strong>moyenne harmonique</strong> peut s’appliquer à des taux (p. ex., vitesses):</p>
<p><span class="math display">\[
\bar{x}_{harm} = \frac{n}{\sum\limits_{i=1}^n \frac{1}{x_i}}
\]</span></p>
<div class="exemple" section="1">
<p>Par exemple, disons que nous avons suivi un ours noir par télémétrie. L’ours a parcouru un segment de 2 km à une vitesse de 1 km/h, un deuxième segment de 2 km à une vitesse de 2 km/h, un troisième segment de 2 km à une vitesse de 4 km/h et un dernier segment de 2 km à une vitesse de 1 km/h. Quelle est la vitesse moyenne de l’ours?</p>
<p>On pourrait utiliser la moyenne harmonique pour résoudre le problème. Sachant que <span class="math inline">\(vitesse = distance/temps\)</span>, nous pouvons déterminer la distance totale parcourue: <span class="math inline">\(4 * 2 \: \mathrm{km} = 8 \:\mathrm{km}\)</span>. On peut ensuite évaluer le temps mis à parcourir ces 8 km:</p>
<ul>
<li>1<span class="math inline">\(^{\mathrm{er}}\)</span> segment: 2 km * 1h/km = 2 h</li>
<li>2<span class="math inline">\(^{\mathrm{e}}\)</span> segment: 2 km * 1h/2 km = 1 h</li>
<li>3<span class="math inline">\(^{\mathrm{e}}\)</span> segment: 2 km * 1h/4 km = 0.5 h</li>
<li>4<span class="math inline">\(^{\mathrm{e}}\)</span> segment: 2 km * 1h/1 km = 2 h</li>
</ul>
<p>Le temps total est 5.5 h. Nous pouvons calculer la vitesse moyenne:</p>
<p><span class="math display">\[
\mathrm{vitesse \:moyenne} = 8 \:\mathrm{km}/5.5 \:\mathrm{h} \\
\mathrm{vitesse \:moyenne} = 1.45 \:\mathrm{km/h}
\]</span>
C’est exactement ce que nous donne la moyenne harmonique:</p>
<p><span class="math display">\[
\bar{x}_{harm} = \frac{4}{1/1 + 1/2 + 1/4 + 1/1} \\
\bar{x}_{harm} = 1.45
\]</span></p>
</div>
<p>À noter que la moyenne harmonique s’applique à des vitesses si elles sont mesurées sur une même distance. Si les distances diffèrent, nous devrons utiliser une version pondérée de la moyenne harmonique.</p>
<p>Les trois types de moyennes sont reliées par la relation suivante:</p>
<p><span class="math display">\[
\bar{x}_{harmonique} &lt; \bar{x}_{g\acute{e}om} &lt; \bar{x}
\]</span></p>
<p>Si les observations sont égales (<span class="math inline">\(x_1 = x_2 = x_3 \ldots = x_n\)</span>), nous obtenons:</p>
<p><span class="math display">\[
\bar{x}_{harmonique} = \bar{x}_{g\acute{e}om} = \bar{x}
\]</span></p>
<p>Il existe d’autres mesures de tendance centrale, notamment la <strong>médiane</strong> qui se définit comme étant la valeur qui sépare les observations en deux groupes égaux (50 % des valeurs &lt; médiane, 50 % des valeurs &gt; médiane). En présence de données normales, la médiane et la moyenne sont proches. La médiane est peu influencée par la présence de valeurs extrêmes (valeurs très grandes ou très faibles), alors que la moyenne est très sensible à la présence de valeurs extrêmes.</p>
<div class="exemple" section="1">
<p>Dans une expérience sur le temps de survie d’insectes exposés à un insecticide, on obtient les valeurs (en secondes) 1.1, 1.2, 1.3, 1.6, 3.2, 2.4, 5.2. La moyenne arithmétique de cet échantillon est de 2.29 secondes et la médiane est de 1.6 secondes. Si l’on ajoute une dernière observation dont la valeur extrême est 40 secondes, la moyenne arithmétique sera alors de 7 secondes et la médiane de 2 secondes. On constate que la médiane est beaucoup moins sensible à l’ajout de la valeur extrême, ce qui n’est pas le cas de la moyenne arithmétique.</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:histomode"></span>
<img src="Cours_Stats_R_files/figure-html/histomode-1.png" alt="Histogramme illustrant une distribution unimodale (a) et bimodale (b)." width="672" />
<p class="caption">
Figure 1.1: Histogramme illustrant une distribution unimodale (a) et bimodale (b).
</p>
</div>
<p>Le <strong>mode</strong> permet aussi de caractériser la tendance centrale, car il donne la ou les valeurs qui reviennent le plus souvent dans l’échantillon (Figure <a href="leçon.html#fig:histomode">1.1</a>). Par exemple, si, dans un échantillon, on obtient les valeurs 12, 12, 12, 12, 12, 3, 3, 3, 3, 3, 3, 1, 2, 14, 15, 16, 21, 32, on dira qu’il y a deux modes (12 et 3).</p>
</div>
<div id="mesures-de-dispersion" class="section level3 hasAnchor" number="1.1.3">
<h3><span class="header-section-number">1.1.3</span> Mesures de dispersion<a href="leçon.html#mesures-de-dispersion" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Certaines mesures décrivent plutôt l’étendue de la variabilité des données. On parle alors de <strong>mesures de dispersion</strong> ou de <strong>paramètres de variabilité</strong>. Plus la variabilité augmente, plus l’incertitude quant à la valeur des paramètres estimés à partir de données d’un échantillon augmente. Un niveau d’incertitude plus élevé augmente la difficulté de trouver des différences et de tester des hypothèses. L’<strong>étendue</strong> (<em>range</em>) est la mesure de dispersion la plus simple. Il s’agit de la différence entre la valeur minimale et la valeur maximale des observations.</p>
<div id="somme-des-carrés-des-erreurs" class="section level4 hasAnchor" number="1.1.3.1">
<h4><span class="header-section-number">1.1.3.1</span> Somme des carrés des erreurs<a href="leçon.html#somme-des-carrés-des-erreurs" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>La <strong>somme des carrés des erreurs</strong> (<em>sum of squared errors, SSE</em>) donne le carré de la différence entre chaque observation et la moyenne de l’échantillon:</p>
<p><span class="math display">\[
SSE = \sum_{i=1}^n (x_i - \bar{x})^2
\]</span></p>
<p>Cette mesure de variabilité est l’une des plus communes, et peut prendre des valeurs ≥≥ 0 (le carré assure des valeurs positives). Plus cette valeur est grande, plus il y a de variabilité dans les données (i.e., les observations sont plus éloignées de la moyenne).</p>
<div class="exemple" section="1">
<p>Un échantillon de 6 longueurs de tige d’une plante ligneuse donne 1.3 m, 4.5 m, 4.1 m, 2.1 m, 5.0 m, et 1.9 m, il s’ensuivra que <span class="math inline">\(\bar{x}\)</span> = 3.15 m et que <span class="math inline">\(SSE=(1.3−3.15)2+(4.5−3.15)2+…+(1.9−3.15)2=12.24m^2\)</span>. Une propriété importante de la SSE est qu’à chaque nouvelle observation ajoutée, elle augmente (pourvu que <span class="math inline">\(x_{nouvelle}\neq \bar{x}\)</span>). Si on ajoute une septième valeur de 2.6 à notre échantillon de longueurs de tige présenté ci-haut, la moyenne arithmétique devient 3.07 et la SSE s’élèvera à 12.49 <span class="math inline">\(m^2\)</span>.</p>
</div>
<p>Une meilleure mesure de dispersion devrait tenir compte de la taille de l’échantillon. Mais avant d’aller plus loin, allons visiter le concept de degrés de liberté (<em>degrees of freedom, df</em>), un concept souvent nébuleux que nous tenterons d’éclaircir ici. On peut voir les degrés de liberté comme étant la taille de l’échantillon corrigée pour le nombre de paramètres estimés.On peut obtenir cette valeur en soustrayant le nombre de paramètres estimés p de la taille d’échantillon n (<em>i.e., n − p</em>). Clarifions avec un exemple.</p>
<div class="exemple" section="1">
<p>Imaginez qu’on ait un échantillon de 5 observations dont on ne connait rien. Ces 5 observations pourraient prendre n’importe quelle valeur. Le degré de liberté est donc 5 (<em>df</em> = 5). Imaginez maintenant qu’on connaisse un paramètre de cet échantillon (p. ex., <span class="math inline">\(\bar{x}\)</span> = 7). On réduit la liberté des valeurs que peuvent prendre ces 5 observations. En effet, disons que les valeurs aient été ndéterminées pour 4 des observations et que la moyenne est connue, la dernière observation est obligée de prendre une valeur en particulier. Avec un paramètre connu, le degré de liberté est donc 4 (<em>df</em> = 5 − 1 = 4).</p>
</div>
</div>
<div id="carré-moyen-variance" class="section level4 hasAnchor" number="1.1.3.2">
<h4><span class="header-section-number">1.1.3.2</span> Carré moyen (variance)<a href="leçon.html#carré-moyen-variance" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Comme nous l’avons mentionné plus tôt, la somme des carrés des erreurs (<span class="math inline">\(SSE\)</span>) augmente avec la taille de l’échantillon. Une meilleure mesure devrait tenir compte de la taille d’échantillon. Le <strong>carré moyen</strong>(<em>mean square, mean squared error, MSE</em>) est une telle mesure de dispersion :</p>
<p><span class="math display">\[
MSE = \frac{SSE}{df} = \frac{\sum\limits_{i=1}^n (x_i - \bar{x})^2}{n - 1}
\]</span>
À noter que le dénominateur correspond aux degrés de liberté, ici <span class="math inline">\(n - 1\)</span>, puisque nous avons estimé la moyenne arithmétique <span class="math inline">\(\mu\)</span> à l’aide de <span class="math inline">\(\bar{x}\)</span> pour trouver la <span class="math inline">\(SSE\)</span>. Ce carré moyen est en fait la <strong>variance</strong> de l’échantillon, <span class="math inline">\(s^2 = MSE\)</span>. Cette relation est importante et nous reviendrons sur cette notion lors de la leçon sur l’analyse de variance. On peut donc estimer la variance de la population à partir d’un échantillon en utilisant l’équation :</p>
<p><span class="math display">\[
s^2 = MSE = \frac{SSE}{df} \\
s^2 = \frac{\sum\limits_{i=1}^n (x_i - \bar{x})^2}{n - 1}
\]</span>
Parfois, on utilise aussi la formule alternative (mais totalement équivalente):</p>
<p><span class="math display">\[
s^2 = \frac{\sum\limits_{i=1}^n x_i^2 - \frac{\left (\sum\limits_{i=1}^n x_i\right )^2}{n}}{n - 1}
\]</span>
L’<strong>écart-type</strong> (<span class="math inline">\(s\)</span>) est simplement la racine carrée de la variance, et il indique la variabilité dans les données. La variance dépend énormément de la taille de l’échantillon. L’estimation devient difficile lorsqu’on a peu d’observations dans l’échantillon. Illustrons avec un exemple.</p>
<div class="exemple" section="1">
<p>Utilisons une petite simulation à l’aide de <strong>R</strong> pour générer des données provenant d’une population avec des caractéristiques connues, soit une population normale avec une moyenne de 10.1 (<span class="math inline">\(\mu = 10.1\)</span>) et une variance de 4 (<span class="math inline">\(\sigma^2 = 4\)</span>). Nous allons sélectionner aléatoirement trois observations provenant de cette population afin de constituer un échantillon de <span class="math inline">\(n = 3\)</span>.</p>
<p>À partir de cet échantillon, nous pouvons calculer une variance qui sera une estimation de la vraie valeur. Nous estimerons <span class="math inline">\(\sigma\)</span> à l’aide de l’estimateur de la variance (<span class="math inline">\(s\)</span>) d’un échantillon. Afin d’obtenir une meilleure idée de la performance de l’estimation de la variance, nous allons ensuite répéter l’exercice pour 29 autres échantillons de <span class="math inline">\(n = 3\)</span> tirés de la même population, et calculer la variance de chaque échantillon de taille 3. Par la suite, nous ferons de même pour 30 échantillons constitués de 4 observations, 30 échantillons de 5 observations, …, 30 échantillons de 49 observations et 30 échantillons de 50 observations (Figure <a href="leçon.html#fig:variance">1.2</a>).</p>
<p>On remarque que l’estimation de la variance est parfois très loin de la vraie valeur de 4, particulièrement pour les très petits échantillons (<span class="math inline">\(n \leq 10\)</span>). On obtient de meilleures estimations pour de plus grands échantillons, particulièrement au-delà de 30. C’est une des raisons pour laquelle on considère un échantillon de 30 observations comme ayant une taille suffisante – il permet de bien estimer la variance. On comprend rapidement que l’utilisation d’un petit échantillon peut nous amener loin de la vraie valeur de la variance. Mais pourquoi s’intéresser autant à la variance?</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:variance"></span>
<img src="Cours_Stats_R_files/figure-html/variance-1.png" alt="Effet du nombre d'observations sur l'estimation de la variance. À noter que la ligne pointillée représente la vraie valeur de la population ($\sigma^2 = 4$) à partir de laquelle les observations ont été sélectionnées aléatoirement" width="672" />
<p class="caption">
Figure 1.2: Effet du nombre d’observations sur l’estimation de la variance. À noter que la ligne pointillée représente la vraie valeur de la population (<span class="math inline">\(\sigma^2 = 4\)</span>) à partir de laquelle les observations ont été sélectionnées aléatoirement
</p>
</div>
</div>
<p>La variance est une quantité importante en statistiques, puisqu’elle est requise pour construire des mesures de précision (p. ex., intervalles de confiance) et pour tester des hypothèses (p. ex., test t). Un petit échantillon peut produire une estimation très loin de la vraie valeur de la variance et invalider les conclusions d’une analyse statistique. Tel qu’illustré dans l’exemple 1.7, l’estimation de la variance s’améliore avec la taille de l’échantillon. Ce qui nous mène à visiter les concepts de <strong>précision</strong> et d’<strong>exactitude</strong>.</p>
</div>
<div id="précision-vs-exactitude" class="section level4 hasAnchor" number="1.1.3.3">
<h4><span class="header-section-number">1.1.3.3</span> Précision vs exactitude<a href="leçon.html#précision-vs-exactitude" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>La réalisation d’une expérience, impliquant l’échantillonnage des observations et l’estimation des quantités, s’apparente à un archer qui lance une flèche sur une cible, où la flèche correspond à une expérience et le point sur la cible correspond à une estimation. On veut que la flèche se rende le plus près du centre de la cible (c.-à-d., une bonne estimation), mais on veut que les flèches ne soient pas trop éloignées les unes des autres (c.-à-d., une bonne précision). En d’autres termes, un archer est précis si toutes ses flèches tombent très près du même point sur la cible (Figure <a href="leçon.html#fig:accuracy">1.3</a>a, c), ou encore il peut manquer d’exactitude lorsque ses flèches sont loin du centre de la cible (Figure <a href="leçon.html#fig:accuracy">1.3</a>c, d). Le meilleur des scénarios est un tir précis et exact (Figure <a href="leçon.html#fig:accuracy">1.3</a>a), et le pire est un tir ni précis, ni exact (Figure <a href="leçon.html#fig:accuracy">1.3</a>d). Le tir exact mais peu précis implique que l’estimation varie beaucoup d’un échantillon à l’autre (Figure <a href="leçon.html#fig:accuracy">1.3</a>b), et cette variation n’est pas souhaitable.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:accuracy"></span>
<a href="images/Target3.png" target="_blank"><img src="Module_1/images/Target3.png" alt="Utilisation de cibles pour expliquer le concept de précision et d'exactitude avec quatre archers dans une compétition. Si tous les points se trouvent au centre et très près les uns des autres, l'archer est précis et exact (a), alors que si les points sont dans la région centrale mais éloignés les uns des autres, l'archer est exact mais peu précis (b). À l'opposé, si les points sont très près les uns des autres et loin du centre, l'archer est précis mais manque d'exactitude (c), tandis que dans le dernier scénario l'archer n'est ni précis ni exact (d)." width="379" /></a>
<p class="caption">
Figure 1.3: Utilisation de cibles pour expliquer le concept de précision et d’exactitude avec quatre archers dans une compétition. Si tous les points se trouvent au centre et très près les uns des autres, l’archer est précis et exact (a), alors que si les points sont dans la région centrale mais éloignés les uns des autres, l’archer est exact mais peu précis (b). À l’opposé, si les points sont très près les uns des autres et loin du centre, l’archer est précis mais manque d’exactitude (c), tandis que dans le dernier scénario l’archer n’est ni précis ni exact (d).
</p>
</div>
<p>L’exactitude peut être vue comme un terme qualitatif. La valeur qui quantifie la déviation entre les estimations et la valeur réelle du paramètre s’appelle biais. Plus formellement, on appelle <strong>biais</strong> la différence entre la *8{valeur attendue<strong> d’une estimation et la </strong>valeur réelle** qu’on désire estimer :</p>
<p><span class="math display">\[
biais = E(\hat{\theta}) - \theta
\]</span>
où <span class="math inline">\(\theta\)</span> est la valeur réelle du paramètre de la population, <span class="math inline">\(\hat{\theta}\)</span> correspond à l’estimation d’un paramètre obtenu avec un seul jeu de données, et <span class="math inline">\(E(\hat{\theta})\)</span> est la valeur attendue des estimations du paramètre. La valeur attendue est en fait la moyenne d’une série d’estimations <span class="math inline">\(\hat{\theta}\)</span> obtenues à partir de plusieurs échantillons de taille égale provenant de la même population. Pour poursuivre notre analogie des archers, la valeur attendue correspond à la moyenne des positions des flèches sur la cible. Le biais exprime la tendance des différences entre les valeurs estimées d’un paramètre et la vraie valeur de ce paramètre. Lorsque le biais est de 0, on dit que l’estimateur est non biaisé (p. ex., l’estimateur de la moyenne arithmétique, <span class="math inline">\(\bar{x}\)</span>, sous certaines conditions).</p>
<p>Si on développait une mesure d’imprécision (<span class="math inline">\(1/pr\acute{e}cision\)</span>), on s’attendrait à ce qu’elle augmente proportionellement (<span class="math inline">\(\propto\)</span><a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a>) avec la variance :</p>
<p><span class="math display">\[
impr\acute{e}cision \propto s^2
\]</span></p>
<p>Par contre, on s’attendrait à ce que l’imprécision diminue avec la taille de l’échantillon :</p>
<p><span class="math display">\[
impr\acute{e}cision \propto \frac{s^2}{n}
\]</span>
Une mesure idéale s’exprimerait dans les mêmes unités que les observations :</p>
<p><span class="math display">\[
impr\acute{e}cision \propto \sqrt{\frac{s^2}{n}}
\]</span></p>
<p>Une telle mesure existe déjà, c’est l’erreur-type de la moyenne (<span class="math inline">\(SE\)</span>) :</p>
<p><span class="math display">\[
SE = s_{\bar{x}} = \sqrt{\frac{s^2}{n}}
\]</span>
L’<strong>erreur-type de la moyenne</strong> d’un échantillon (<span class="math inline">\(s_{\bar{x}}\)</span> ou <span class="math inline">\(SE\)</span>) représente l’écart-type de la distribution des moyennes calculées à partir d’échantillons de taille identique à celle de notre échantillon. Ainsi, l’erreur-type de la moyenne nous donne une indication sur la variabilité de l’estimation de ce paramètre si on répétait l’échantillonnage. Pour clarifier, l’écart-type nous informe sur la variabilité d’un échantillon alors que l’erreur-type de la moyenne nous indique la précision avec laquelle nous avons estimé ce paramètre. Nous revisiterons ce concept lors des deux dernières leçons consacrées aux modèles de régression.</p>
<p>L’erreur-type nous permet de calculer des <strong>intervalles de confiance</strong> autour de la moyenne ou d’autres paramètres. L’intervalle de confiance est justement une autre mesure de précision autour d’une estimation. L’intervalle de confiance (<span class="math inline">\(IC\)</span>) se définit comme étant l’intervalle à l’intérieur duquel se trouvera la moyenne de la population <span class="math inline">\(\mu\)</span> si l’on répète l’expérience un grand nombre de fois. Pour un <span class="math inline">\(IC\)</span> à 95 %,</p>
<p><span class="math display">\[
P(\bar{x} - 1.96 \cdot SE \leq \mu \leq \bar{x} + 1.96 \cdot SE) = 0.95
\]</span>
Un <span class="math inline">\(IC\)</span> à 95 % indique que la moyenne de la population (<span class="math inline">\(\mu\)</span>) devrait se trouver 95 % du temps (c.-à-d., la probabilité est de 0.95) à l’intérieur de l’intervalle si on répète l’échantillonnage à plusieurs reprises avec le même nombre d’observations. Pour un <span class="math inline">\(IC\)</span> donné, la moyenne de la population <span class="math inline">\(\mu\)</span> est incluse ou non <a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a>. L’<span class="math inline">\(IC\)</span> est construit à partir d’un échantillon, mais concerne la moyenne <span class="math inline">\(\mu\)</span> de la population. Nous expliquerons en détail la construction et l’interprétation d’intervalles de confiance à la prochaine leçon(voir aussi la section 7 de la présente leçon pour comprendre l’origine du facteur 1.96). Pour l’instant, il suffit de réaliser qu’on peut utiliser cette intervalle pour en indiquer la précision.</p>
<!-- La phrase "voir aussi la section 7 de la présente leçon pour comprendre l'origine du facteur 1.96" se trouve dans le PDF mais pas dans le latex -->
</div>
<div id="autres-mesures-de-dispersion" class="section level4 hasAnchor" number="1.1.3.4">
<h4><span class="header-section-number">1.1.3.4</span> Autres mesures de dispersion<a href="leçon.html#autres-mesures-de-dispersion" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Le **coefficient de variation*}** (<em>coefficient of variation, CV</em>) est parfois utilisé pour représenter la variabilité:
<span class="math display">\[
CV = \frac{s}{\bar{x}} \cdot 100 \: \%
\]</span>
où <span class="math inline">\(s\)</span> représente l’écart-type de l’échantillon et <span class="math inline">\(\bar{x}\)</span> correspond à la moyenne arithmétique de l’échantillon. On remarque que le <span class="math inline">\(CV\)</span> est le ratio entre l’écart-type et la moyenne arithmétique. Un échantillon avec un CV de 14 % varie moins qu’un autre avec un <span class="math inline">\(CV\)</span> de {30~%}.</p>
<p>Les <strong>quantiles</strong> peuvent également nous aider à représenter à quel point les données varient. Le mot “quantile” est un terme générique qui désigne une quantité qui divise les données en compartiments après qu’elles ont été mises en ordre croissant. Les <strong>quartiles</strong> divisent les données en quatre compartiments, les <strong>déciles</strong> en 10 compartiments, et les <strong>percentiles</strong> en 100 compartiments. Par exemple, un 90<span class="math inline">\(^{\mathrm{e}}\)</span> percentile de 120 g signifie que 90 % des valeurs sont inférieures à 120 g et que 10 % des valeurs sont supérieures à 120 g.</p>
</div>
</div>
<div id="variables-aléatoires" class="section level3 hasAnchor" number="1.1.4">
<h3><span class="header-section-number">1.1.4</span> Variables aléatoires<a href="leçon.html#variables-aléatoires" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>On désigne <strong>variable aléatoire</strong> une variable dont les valeurs observées sont considérées comme résultant d’un processus aléatoire (c.-à-d., expérience aléatoire). Autrement dit, les valeurs exactes d’une variable aléatoire dans un échantillon ne peuvent être anticipées avec certitude avant de recueillir l’échantillon que nous utiliserons pour tirer des conclusions à propos de la population (p. ex., estimer un paramètre). Le tout implique une composante aléatoire. Par exemple, si on mesure la pression artérielle, le niveau de cholestérol, et le niveau d’activité (trois variables aléatoires) chez un groupe de gens sélectionnés aléatoirement, on ne peut prédire la valeur de ces trois variables chez un individu avant de les avoir mesurées.</p>
<p>Les variables aléatoires peuvent être <strong>discrètes</strong>ou <strong>continues</strong>. Par discrètes, on entend des variables binaires (p. ex., présence-absence, mort-vivant), catégoriques ordonnées ou non (p. ex., petit, moyen, grand; poisson, invertébré, mammifère) ou encore des variables apparaissant sous forme d’entiers (le nombre d’interruption de courant dans 5 municipalités depuis le dernier mois: 0, 1, 12, 4). Le cas échéant, la valeur peut uniquement prendre des valeurs entières – on ne peut avoir dénombré 2.4 individus dans un quadrat ou avoir un individu au 3/4 mort.</p>
<p>Les variables continues sont celles qui peuvent prendre une infinité de valeurs sur un intervalle donné. La distance, la masse, le temps, la température, la longueur sont des variables pouvant être mesurées avec différentes résolutions, selon l’instrument utilisé pour effectuer la mesure. Par exemple, mesurons un serpent avec trois différents instruments – un pied à coulisse au mm près, une règle graduée au cm près et un ruban à mesurer au dm près. Le serpent a une longueur finie, mais chacun de nos instruments donnera une mesure différente. Le serpent ne changera pas de longueur entre les trois mesures, mais chaque instrument exprimera un certain nombre de chiffres significatifs.</p>
<p>La présentation des valeurs d’une variable peut aussi varier selon le type de variable. Nous utilisons habituellement un diagramme à bâtons pour une variable discrète, alors qu’un histogramme illustre mieux les données d’une variable continue (Figure <a href="leçon.html#fig:randomvar">1.4</a>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:randomvar"></span>
<img src="Cours_Stats_R_files/figure-html/randomvar-1.png" alt="Présentation des longueurs de 100 serpents (variable continue, a) et du nombre de pucerons dans 100 sites (variable discrète, b)" width="672" />
<p class="caption">
Figure 1.4: Présentation des longueurs de 100 serpents (variable continue, a) et du nombre de pucerons dans 100 sites (variable discrète, b)
</p>
</div>
</div>
<div id="loi-des-grands-nombres-et-théorème-de-la-limite-centrale" class="section level3 hasAnchor" number="1.1.5">
<h3><span class="header-section-number">1.1.5</span> Loi des grands nombres et théorème de la limite centrale<a href="leçon.html#loi-des-grands-nombres-et-théorème-de-la-limite-centrale" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Deux principes importants agissent sur l’échantillonnage (et les échantillons) et nous permettent d’analyser les données. La <strong>loi des grands nombres</strong> stipule que la moyenne de l’échantillon (<span class="math inline">\(\bar{x}\)</span>) tend vers la moyenne de la population (<span class="math inline">\(\mu\)</span>) au fur et à mesure que la taille de l’échantillon augmente. D’où l’importance d’une bonne taille d’échantillon.</p>
<p>Le <strong>théorème de la limite centrale</strong>, quant à lui, indique que, si on prend plusieurs échantillons indépendants d’une même population, et que l’on calcule la moyenne (ou somme) de chacun, ces moyennes (ou sommes) auront une distribution normale (voir prochaine section). Grace à ce théorème, on peut effectuer des analyses à partir d’un échantillon, même si on ne connaît pas les propriétés de la population originale. On ne peut pas généralement déterminer la normalité d’une population sans l’avoir recensée au complet. Toutefois, on peut le faire pour un échantillon qui provient de cette même population.</p>
<!-- DANS LE LATEX MAIS PAS DANS LE PDF : %Standardiser ou centrer-réduire est une opération qui consiste à soustraire la moyenne de chaque valeurs et de diviser le résultat par l'écart-type}. -->
</div>
<div id="distribution-normale" class="section level3 hasAnchor" number="1.1.6">
<h3><span class="header-section-number">1.1.6</span> Distribution normale<a href="leçon.html#distribution-normale" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La <strong>distribution normale</strong> (ou loi normale) est une distribution théorique centrale en statistique à la base de nombreux traitements statistiques. Découverte initialement par le mathématicien Abraham De Moivre au 17<span class="math inline">\(^{\mathrm{e}}\)</span> siècle et redécouverte par Karl Friedrich Gauss 100 ans plus tard, elle a été longtemps désignée sous le nom de <strong>distribution gaussienne</strong>.</p>
<p>On connaît bien les propriétés de la distribution normale et plusieurs approches utilisent cette distribution :</p>
<ul>
<li>les tests d’hypothèses ;</li>
<li>l’estimation de paramètres par maximum de vraisemblance ;</li>
<li>la construction d’intervalles de confiance.</li>
</ul>
<p>La distribution normale se définit par la <strong>fonction de densité de probabilité</strong> (<em>probability density function, pdf</em>) suivante:</p>
<p>$$
f(x , ) = e<sup>{-()</sup>2} = </p>
<p>$$
où <span class="math inline">\(x\)</span> correspond à la valeur numérique d’intérêt, <span class="math inline">\(\mu\)</span> représente la moyenne de la population, <span class="math inline">\(\sigma\)</span> est l’écart-type de la population, <span class="math inline">\(\pi\)</span> est la constante 3.14159… et <span class="math inline">\(e\)</span> est la constante 2.71828…. Cette distribution comporte deux paramètres, <span class="math inline">\(\mu\)</span> et <span class="math inline">\(\sigma\)</span> et on représente parfois cette distribution avec la notation N(<span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma\)</span>).</p>
<p>En mots, l’équation nous donne la densité de probabilité d’une variable qui prend la valeur <span class="math inline">\(x\)</span> et qui provient d’une distribution normale avec une moyenne <span class="math inline">\(\mu\)</span> et un écart-type <span class="math inline">\(\sigma\)</span>. On peut interpréter la densité de probabilité comme on le ferait pour une fréquence relative d’un histogramme. La densité de probabilité de la distribution normale ne correspond pas à la probabilité d’observer <span class="math inline">\(X = x\)</span>. La raison de cette interprétation plus complexe provient du fait que la probabilité d’observer une valeur spécifique (p. ex., comme la masse ou la longueur) dans une distribution continue est de 0. La valeur mesurée d’une variable continue est en réalité un intervalle qui dépend de la précision de l’instrument de mesure au mg près, au g près, ou au kg près. Pour un serpent dont la mesure obtenue est de 102.54 cm, on obtient :</p>
<p><span class="math display">\[
P(x = 102.54) = P(102.54 \leq x \leq 102.54) = \int_{102.54}^{102.54} f(x) dx = 0
\]</span></p>
<p>Si la règle utilisée pour mesurer le serpent donne une précision de <span class="math inline">\(\pm\)</span> 0.01 cm, notre mesure est en fait un intervalle défini par les bornes suivantes :</p>
<p><span class="math display">\[
\mathrm{borne \: inf\acute{e}rieure} = 102.54 \: \mathrm{cm} - 0.01 \: \mathrm{cm} = 102.53 \: \mathrm{cm}\\
\mathrm{borne \: sup\acute{e}rieure} = 102.54 \: \mathrm{cm} + 0.01 \: \mathrm{cm} = 102.55 \: \mathrm{cm}
\]</span>
La fonction de densité nous donne la densité de la distribution correspondant à la valeur <span class="math inline">\(x\)</span>. On peut obtenir la courbe de distribution normale pour une moyenne et écart-type donnés en substituant une série de valeurs dans l’équation.</p>
<div class="exemple" section="1">
<p>On veut connaître la densité de probabilité associée à une masse de souris de 3.4 g dans une population de souris suivant une distribution normale ayant une moyenne de 4.1 g et un écart-type de 1.5 g (c.-à-d., N(4.1, 1.5)). Nous avons donc :</p>
<p><span class="math display">\[
\begin{aligned}
  x &amp;= 3.4 \: \mathrm{g} &amp; f(x = 3.4 \mid 4.1, 1.5) &amp;= \frac{1}{1.5 \cdot \sqrt{2\pi}}e^{-\frac{1}{2}\left(\frac{3.4 - 4.1}{1.5}\right)^2} = 0.2385 \\
  \mu &amp;= 4.1 \: \mathrm{g} &amp; &amp; \\
  \sigma &amp;= 1.5 \: \mathrm{g} &amp; \: .
\end{aligned}
\]</span></p>
<p>On pourrait aussi déterminer la densité de probabilité associée à des souris de 8.9~g et de 10.2 g dans la même population :
Souris de 8.9 g:</p>
<p><span class="math display">\[
f(x = 8.9 \vert 4.1, 1.5) = \frac{1}{1.5 \cdot \sqrt{2\pi}}e^{-\frac{1}{2}(\frac{8.9 - 4.1}{1.5})^2} = 0.0016
\]</span></p>
<p>Souris de 10.2 g:</p>
<p><span class="math display">\[
f(x = 10.2 \vert 4.1, 1.5) = \frac{1}{1.5 \cdot \sqrt{2\pi}}e^{-\frac{1}{2}(\frac{10.2 - 4.1}{1.5})^2} = 0.00007
\]</span>
On peut ensuite représenter ces valeurs sur une distribution normale avec <span class="math inline">\(\mu = 4.1\)</span> et <span class="math inline">\(\sigma = 1.5\)</span>. La figure <a href="leçon.html#fig:normdensity">1.5</a> illustre la densité de probabilité pour les trois souris. La courbe a été obtenue en utilisant l’équation de la densité pour une moyenne de 4.1 et un écart-type de 1.5 et en faisant varier <span class="math inline">\(x\)</span> dans l’intervalle de 0 à 12. On remarque que la distribution est plus “dense” dans la région de 2 à 6 g. Par conséquent, on constate que les valeurs dans cet intervalle sont plus probables que des valeurs à l’extérieur de cet intervalle. Nous avons donc plus de chance d’observer une valeur de 3.4 g dans cette population que des valeurs de 8.9 ou 10 g.
<!-- Pas vraiment le même texte pdf et latex --></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:normdensity"></span>
<img src="Cours_Stats_R_files/figure-html/normdensity-1.png" alt="Distribution normale d'une population de masses de souris où la moyenne est de 4.1 g et l'écart-type est de 1.5 g. À noter qu'on peut tracer la courbe de la distribution en substituant une série de valeurs de $x$ dans la fonction de densité de probabilité pour un $\mu = 4.1$ et $\sigma = 1.5$, c.-à-d., N(4.1, 1.5)." width="672" />
<p class="caption">
Figure 1.5: Distribution normale d’une population de masses de souris où la moyenne est de 4.1 g et l’écart-type est de 1.5 g. À noter qu’on peut tracer la courbe de la distribution en substituant une série de valeurs de <span class="math inline">\(x\)</span> dans la fonction de densité de probabilité pour un <span class="math inline">\(\mu = 4.1\)</span> et <span class="math inline">\(\sigma = 1.5\)</span>, c.-à-d., N(4.1, 1.5).
</p>
</div>
</div>
<p>La distribution normale comprend deux paramètres, <span class="math inline">\(\mu\)</span> et <span class="math inline">\(\sigma\)</span>, ce qui signifie que l’on peut tracer une courbe normale dès que nous connaissons ces deux valeurs. La moyenne (<span class="math inline">\(\mu\)</span>) détermine la position (fig. <a href="leçon.html#fig:shape">1.6</a>a) et la variance détermine la forme de la courbe (Figure <a href="leçon.html#fig:shape">1.6</a>b).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:shape"></span>
<img src="Cours_Stats_R_files/figure-html/shape-1.png" alt="Position de distributions normales avec même variance, mais différentes moyennes (a) et forme de distributions normales pour des variances différentes, mais une même moyenne (b)." width="672" />
<p class="caption">
Figure 1.6: Position de distributions normales avec même variance, mais différentes moyennes (a) et forme de distributions normales pour des variances différentes, mais une même moyenne (b).
</p>
</div>
<div id="caractéristiques-de-la-distribution-normale" class="section level4 hasAnchor" number="1.1.6.1">
<h4><span class="header-section-number">1.1.6.1</span> Caractéristiques de la distribution normale<a href="leçon.html#caractéristiques-de-la-distribution-normale" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>La distribution normale est une distribution continue dans l’intervalle <span class="math inline">\([-\infty, +\infty]\)</span>. La somme de l’aire sous la courbe est 1. La distribution est symétrique autour de la moyenne <span class="math inline">\(\mu\)</span>. On sait que:</p>
<ul>
<li>90 % des observations se trouvent à 1.64<span class="math inline">\(\sigma\)</span> de <span class="math inline">\(\mu\)</span>;</li>
<li>95 % des observations se trouvent à 1.96<span class="math inline">\(\sigma\)</span> de <span class="math inline">\(\mu\)</span>;</li>
<li>99 % des observations se trouvent à 2.58<span class="math inline">\(\sigma\)</span> de <span class="math inline">\(\mu\)</span>.</li>
</ul>
</div>
<div id="distribution-normale-centrée-réduite" class="section level4 hasAnchor" number="1.1.6.2">
<h4><span class="header-section-number">1.1.6.2</span> Distribution normale centrée réduite<a href="leçon.html#distribution-normale-centrée-réduite" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>La distribution normale centrée réduite (<em>standard normal distribution</em>) est un cas particulier de la distribution normale où <span class="math inline">\(\mu = 0\)</span> et <span class="math inline">\(\sigma = 1\)</span> (Figure <a href="leçon.html#fig:standardnormal">1.7</a>). <strong>Centrer</strong> consiste à soustraire la moyenne de chaque observation, <span class="math inline">\(x_{i \: centr\acute{e}e} = x_i - \mu\)</span>. L’opération n’influence pas la variance, mais les observations centrées ont une moyenne de 0. Centrer et <strong>réduire</strong>, parfois aussi connu sous le terme <strong>standardiser</strong>, consiste à diviser chaque observation centrée par l’écart-type de l’échantillon, <span class="math inline">\(x_{i \: centr\acute{e}e \: r\acute{e}duite} = \frac{x_i - \mu}{\sigma}\)</span>. Les observations centrées réduites ont une moyenne de 0 et une écart-type de 1. L’opération de centrer réduire est aussi appelée la transformation <span class="math inline">\(z\)</span> ou l’écart normal, <span class="math inline">\(z = \frac{x_i - \mu}{\sigma}\)</span>. Cette opération modifie l’échelle de la variable. La variable centrée réduite est exprimée en terme du nombre d’écart-types séparant chaque valeur de la moyenne.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:standardnormal"></span>
<img src="Cours_Stats_R_files/figure-html/standardnormal-1.png" alt="Distribution normale centrée réduite, c.-à-d., N(0, 1)." width="672" />
<p class="caption">
Figure 1.7: Distribution normale centrée réduite, c.-à-d., N(0, 1).
</p>
</div>
<div class="exemple" section="1">
<p>On s’intéresse à la longueur d’ailes de pucerons dans une population. Après un recensement exhaustif, on détermine que la moyenne (<span class="math inline">\(\mu\)</span>) des longueurs d’aile dans une population est de 14.2 mm et que l’écart-type (<span class="math inline">\(\sigma\)</span>) est de 5.05 mm. On veut ensuite déterminer à combien d’écart-types de la moyenne se trouve une longueur d’aile de 22.6 mm chez un puceron de cette population. Nous avons donc, <span class="math inline">\(z_i = \frac{x_i - \mu}{\sigma} = \frac{22.6 - 14.2}{5.05} = 1.66\)</span>. On conclut que <span class="math inline">\(x_i = 22\)</span> mm se trouve à <span class="math inline">\(1.66 \: \sigma\)</span> de <span class="math inline">\(\mu\)</span> (Figure <a href="leçon.html#fig:zex1">1.8</a>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:zex1"></span>
<img src="Cours_Stats_R_files/figure-html/zex1-1.png" alt="Écart normal associé à une longueur d'ailes de puceron de 22.6 mm." width="672" />
<p class="caption">
Figure 1.8: Écart normal associé à une longueur d’ailes de puceron de 22.6 mm.
</p>
</div>
</div>
</div>
<div id="probabilités-cumulatives" class="section level4 hasAnchor" number="1.1.6.3">
<h4><span class="header-section-number">1.1.6.3</span> Probabilités cumulatives<a href="leçon.html#probabilités-cumulatives" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Les probabilités cumulatives sont beaucoup utilisées en statistique. Par exemple, on peut vouloir déterminer la probabilité d’observer un diamètre &gt; 2.3 cm pour un arbre mesuré à une hauteur 1 m du sol dans une forêt avec N(4, 12), c’est-à-dire, <span class="math inline">\(P(\mathrm{diam\grave{e}tre} &gt; 2.3 \:\mathrm{cm})\)</span>, ou encore déterminer la probabilité d’observer une profondeur de litière forestière entre 3 et 10 cm dans une population de sites avec N(12.5, 3.01), <span class="math inline">\(P(\mathrm{profondeur} &gt; 2.3 \:\mathrm{cm})\)</span>.</p>
<p>On peut résoudre ce genre de problème à l’aide de la distribution normale ou de la distribution normale centrée réduite. La probabilité cumulative correspond à l’aire sous la courbe dans un intervalle défini par une intégrale. Par exemple, on sait que l’aire sous la courbe d’une distribution normale centrée réduite entre -1.96 et 1.96 est de 0.95 :</p>
<p><span class="math display">\[
\int\limits_{-1.96}^{1.96} f(x \: | \: \mu = 0, \sigma = 1) dx = 0.95
\]</span></p>
<p>À noter que les probabilités cumulatives étaient autrefois obtenues à partir de de tables situées en annexe de livres de statistiques. De nos jours, nous utiliserons typiquement un logiciel comme R pour obtenir la probabilité cumulative. Dans R, la fonction <code>pnorm( )</code> nous donne cette valeur et nous discuterons plus en détails de cette option dans les prochaines leçons.</p>
<div class="exemple" section="1">
<p>On a recensé tous les individus d’un édifice à bureaux d’une ville d’Amérique du Nord. La moyenne (<span class="math inline">\(\mu\)</span>) de la taille des individus dans cette population est de 170 cm avec un écart-type (<span class="math inline">\(\sigma\)</span>) de 8 cm. Quelle est la probabilité qu’un individu soit plus petit ou égal à 160 cm dans cette population? Pour résoudre le problème, on peut utiliser l’écart normal :</p>
<p><span class="math display">\[
z_i = \frac{x_i - \mu}{\sigma} = \frac{160 - 170}{8} \\
z_i = -1.25
\]</span>
On peut écrire :</p>
<p><span class="math display">\[
P(x_i \leq 160 \: \mathrm{cm}) = P(z \leq -1.25) = 0.1056
\]</span></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:zex2"></span>
<img src="Cours_Stats_R_files/figure-html/zex2-1.png" alt="Probabilité cumulative associée à une valeur $\leq$ 160 cm dans une population avec N(170, 8)." width="672" />
<p class="caption">
Figure 1.9: Probabilité cumulative associée à une valeur <span class="math inline">\(\leq\)</span> 160 cm dans une population avec N(170, 8).
</p>
</div>
<p>Ici, <span class="math inline">\(P\)</span> est une probabilité cumulative que l’on peut obtenir en calculant l’aire sous la courbe pour la portion de la courbe à gauche du point -1.25 (Figure <a href="leçon.html#fig:zex2">1.9</a>).</p>
</div>
<div class="exemple" section="1">
<p>Si on veut connaître la probabilité qu’un individu ait une taille supérieure à 185 cm dans la même population que celle de notre exemple précédent (édifice à bureaux), on pourrait encore une fois utiliser l’écart normal. Ainsi, on peut écrire :</p>
<p><span class="math display">\[
z_i = \frac{x_i - \mu}{\sigma} = \frac{185 - 170}{8} \\
z_i = 1.875
\]</span></p>
<p>La probabilité cumulative ici peut s’obtenir à l’aide de :</p>
<p><span class="math display">\[
P(x_i \leq 185 \: \mathrm{cm}) = P(z \leq 1.875) = 0.9696
\]</span></p>
<p>Toutefois, nous désirons <span class="math inline">\(P(x_i &gt; 185 \: \mathrm{cm})\)</span>, ce qui diffère des exemples précédents avec <span class="math inline">\(P(x_i \leq X)\)</span> (Figure <a href="leçon.html#fig:zex3">1.10</a>a). L’astuce ici consiste à calculer le complément de <span class="math inline">\(P(x_i \leq 185 \: \mathrm{cm})\)</span> (Figure <a href="leçon.html#fig:zex3">1.10</a>b). Puisque l’aire sous la courbe est de 1, on peut obtenir <span class="math inline">\(P(x_i &gt; 185 \: \mathrm{cm})\)</span> simplement avec:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:zex3"></span>
<img src="Cours_Stats_R_files/figure-html/zex3-1.png" alt="Probabilité cumulative associée à une valeur &gt; 185 cm dans une population avec N(170, 8)." width="672" />
<p class="caption">
Figure 1.10: Probabilité cumulative associée à une valeur &gt; 185 cm dans une population avec N(170, 8).
</p>
</div>
</div>
<div class="exemple" section="1">
<p>Il est possible de déterminer la probabilité d’observer une valeur entre 165 cm et 180 cm dans la même population. Pour ce faire, il faut calculer la probabilité cumulative associée à chacune des bornes, comme suit :</p>
<p><span class="math display">\[
z_1 = \frac{180 - 170}{8} = 1.25\\
z_2 = \frac{165 - 170}{8} = -0.625
\]</span>
On obtient les probabilités cumulatives de chaque <span class="math inline">\(z_i\)</span> comme d’habitude:</p>
<p><span class="math display">\[
P(x_1 \leq 180 \: \mathrm{cm}) = P(z_1 \leq 1.25) = 0.8944\\
P(x_2 \leq 165 \: \mathrm{cm}) = P(z_2 \leq -0.625) = 0.2660
\]</span>
La différence entre les deux probabilités cumulatives nous donnera la probabilité cumulative pour l’intervalle désiré (Figure <a href="leçon.html#fig:zex4">1.11</a>):</p>
<p><span class="math display">\[
P(165 \: \mathrm{cm} \leq x_i \leq 180 \: \mathrm{cm}) = 0.8944 - 0.2660 = 0.6284
\]</span></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:zex4"></span>
<img src="Cours_Stats_R_files/figure-html/zex4-1.png" alt="Probabilité cumulative associée à 165 cm $\leq$ $\ x_i$ $\leq$ 180 cm dans une population avec N(170, 8)." width="672" />
<p class="caption">
Figure 1.11: Probabilité cumulative associée à 165 cm <span class="math inline">\(\leq\)</span> <span class="math inline">\(\ x_i\)</span> <span class="math inline">\(\leq\)</span> 180 cm dans une population avec N(170, 8).
</p>
</div>
<!-- Des différences entre le pdf et le latex -->
</div>
</div>
<div id="applications-de-la-statistique-z-à-un-échantillon" class="section level4 hasAnchor" number="1.1.6.4">
<h4><span class="header-section-number">1.1.6.4</span> Applications de la statistique z à un échantillon<a href="leçon.html#applications-de-la-statistique-z-à-un-échantillon" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Comme nous venons de le voir, la statistique <span class="math inline">\(z\)</span> peut s’appliquer aux observations d’une population dont on connaît les réelles valeurs de la moyenne et de l’écart-type. On utilise la distribution normale pour trouver la probabilité d’observer <span class="math inline">\(x_i\)</span> (une valeur d’une observation) dans un intervalle donné d’une population avec une moyenne <span class="math inline">\(\mu\)</span> et un écart-type <span class="math inline">\(\sigma\)</span> connus. Toutefois, on peut aussi appliquer la même approche au niveau d’un paramètre d’une population. En d’autres mots, on peut déterminer l’écart normal (<span class="math inline">\(z\)</span>) associé à la valeur de l’estimation d’un paramètre à partir d’un échantillon (p. ex., une moyenne, une médiane) d’une population avec <span class="math inline">\(\mu\)</span> et <span class="math inline">\(\sigma\)</span> connus.</p>
<p>Ainsi, l’équation originale <span class="math inline">\(z = \frac{x_i - \mu}{\sigma}\)</span> qui dépendait de la normalité des observations devient <span class="math inline">\(z = \frac{\bar{x} - \mu}{\sigma_{\bar{x}}}\)</span> et s’intéresse à un paramètre d’une population, où <span class="math inline">\(\bar{x}\)</span> correspond à la moyenne arithmétique de l’échantillon, et <span class="math inline">\(\sigma_{\bar{x}}\)</span> est l’erreur-type de la population. Autrement dit, au lieu de s’intéresser à des valeurs individuelles dans la population, nous ciblons plutôt la moyenne d’un échantillon tiré d’une population avec <span class="math inline">\(\mu\)</span> et <span class="math inline">\(\sigma_{\bar{x}}\)</span> connus. Cette transition est possible en supposant que la moyenne provient d’une distribution normale des moyennes (grâce au théorème de la limite centrale). C’est le genre de traitement typique que nous faisons la plupart du temps avec les données d’un échantillon que nous récoltons à partir d’une population statistique.</p>
<div class="exemple" section="1">
<p>Nous voulons déterminer la probabilité d’obtenir un échantillon aléatoire de 9 longueurs de becs d’oiseaux, lequel a une moyenne &gt; 50.0 mm dans une population avec <span class="math inline">\(\mu = 47.5 \: \mathrm{mm}\)</span> et <span class="math inline">\(\sigma = 12.89 \: \mathrm{mm}\)</span>. On obtient:</p>
<p><span class="math display">\[
\sigma_{\bar{x}} = \frac{\sigma}{\sqrt{n}} = \frac{12.89}{\sqrt{9}} = 4.30 \\
z = \frac{\bar{x} - \mu}{\sigma_{\bar{x}}} = \frac{50 - 47.5}{4.30} = 0.58 \\
P(\bar{x} &gt; 50 \: \mathrm{mm}) = P(z &gt; 0.58) = 0.2803
\]</span></p>
<p>On constate qu’il est assez probable (<span class="math inline">\(P(z &gt; 0.58) = 0.2803\)</span>) de tirer un échantillon de 9 longueurs de becs d’oiseaux avec des propriétés similaires à celles de l’échantillon original de la population d’intérêt. Par convention, on considère qu’une probabilité <span class="math inline">\(P \leq 0.05\)</span> est faible, bien que ce seuil soit arbitraire et qu’il existe de nouvelles approches qui mettent de côté la subjectivité du choix d’un tel seuil. Nous discuterons plus en détail des implications du choix de tels seuils ainsi que de méthodes alternatives dans des prochaines leçons.</p>
</div>
<p>Malheureusement, on connaît rarement <span class="math inline">\(\sigma\)</span> dans la vraie vie et on doit utiliser une estimation obtenue à partir de l’échantillon. Comme nous l’avons souligné plus tôt, l’estimation de la variance est difficile dans les échantillons de petite taille. Comme le test <span class="math inline">\(z\)</span> nécessite une estimation de la variance, ce dernier est peu utilisé pour tester des valeurs d’un échantillon de petite taille. Lorsque <span class="math inline">\(\sigma\)</span> est inconnu et doit être estimé à partir d’un échantillon, nous utiliserons plutôt la distribution du <span class="math inline">\(t\)</span> de Student. C’est ce que nous verrons dans les prochaines leçons.</p>
</div>
</div>
<div id="conclusion" class="section level3 hasAnchor" number="1.1.7">
<h3><span class="header-section-number">1.1.7</span> Conclusion<a href="leçon.html#conclusion" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Dans cette leçon, nous avons brièvement présenté les concepts de base importants en statistique, notamment les caractéristiques d’une population et d’un échantillon, les variables aléatoires, les mesures de tendance centrale et de dispersion. La distribution normale a été présentée, ainsi que le théorème de la limite centrale et la loi des grands nombres.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="4">
<li id="fn4"><p>Dans un processus multiplicatif, une variable a un effet multiplicatif sur une variable réponse. Parexemple, si on remarque que la croissance de semis à concentration modérée d’engrais est 2.5 fois plus élevée qu’à concentration faible, la concentration a un effet multiplicatif sur la croissance.<a href="leçon.html#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>Un quadrat est une unité spatiale de dimension donnée (1 m × 1 m, 10 m × 10 m), disposée dans un site d’étude sur laquelle on fait des mesures en écologie, ici un décompte d’insectes.<a href="leçon.html#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>Le symbole <span class="math inline">\(\propto\)</span> indique la proportionnalité entre deux variables. En d’autres mots, on peut passer des valeurs d’une variable en multipliant ou divisant par une constante non nulle pour obtenir les valeurs de l’autre.<a href="leçon.html#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>Les gens ont souvent une interprétation bayésienne de l’intervalle de confiance en affirmant que c’est la probabilité que la moyenne soit comprise dans l’intervalle de confiance construit à partir d’un seul échantillon. Dans le cours, nous ferons uniquement appel aux statistiques classiques aussi appelées fréquentistes et nous utiliserons la définition classique de l’intervalle de confiance.<a href="leçon.html#fnref7" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="statistiques-descriptives.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="statistiques-de-base-avec-r.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
},
"info": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
